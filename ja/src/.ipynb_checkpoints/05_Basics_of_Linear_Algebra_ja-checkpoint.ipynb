{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Lja-H3pv7q74"
   },
   "source": [
    "# 線形代数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KiD1JHDa7q75"
   },
   "source": [
    "線形代数を学ぶと、複数の値や変数をうまく扱うことができるようになります。\n",
    "機械学習の理論を勉強する際は線形代数で用いられる概念が頻出します。\n",
    "本節では、その中からベクトル、行列、逆行列などの重要な概念を順番に紹介していきます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VSsvisJf7q76"
   },
   "source": [
    "## スカラー・ベクトル・行列・テンソル\n",
    "\n",
    "まず始めに、スカラー、ベクトル、行列、テンソルという 4 つの言葉を解説します。\n",
    "\n",
    "**スカラー (scalar)** は、1 つの値もしくは変数のことです。例えば、\n",
    "\n",
    "$$\n",
    "x, \\ y,\\  M,\\  N\n",
    "$$\n",
    "\n",
    "のように表します。一般的に、太字や斜体にされていない文字はスカラーを表すのに使われます。\n",
    "スカラーは例えば温度や身長といった単一の数量を表します。\n",
    "\n",
    "**ベクトル (vector)** は、複数のスカラーを集めて一方向に並べたものであり、\n",
    "\n",
    "$$\n",
    "{\\bf x}=\\begin{bmatrix}\n",
    "x_{1} \\\\\n",
    "x_{2} \\\\\n",
    "x_{3}\n",
    "\\end{bmatrix}, \\\n",
    "{\\bf y}=\\begin{bmatrix}\n",
    "y_{1} \\\\\n",
    "y_{2} \\\\\n",
    "\\vdots \\\\\n",
    "y_{N}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "のように表します。\n",
    "ベクトルを表すのに用いられる文字は、スカラーと区別しやすいよう太字とするのが一般的です。\n",
    "ベクトルを定義する際、上の 2 つの例のように、その要素を**縦方向に並べたものは列ベクトル**と呼ばれます。\n",
    "一方、**横方向に並べたものは行ベクトル**と呼ばれます。\n",
    "この資料では、特に明示しない限り、単にベクトルと表現した場合には列ベクトルを指すこととします。\n",
    "\n",
    "**行列 (matrix)** は複数の同じサイズのベクトルを並べたものであり、\n",
    "\n",
    "$$\n",
    "{\\bf X} =\n",
    "\\begin{bmatrix}\n",
    "x_{11} & x_{12} \\\\\n",
    "x_{21} & x_{22} \\\\\n",
    "x_{31} & x_{32}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "のようなものを表します。行列の形は行数と列数で表現します。例えば、この ${\\bf X}$ は3行2列なので、サイズが $(3, 2)$ である行列、と言います。\n",
    "また、その要素が**実数 (real number)** であることと、$3 \\times 2$ という行列のサイズを同時に表す表記として ${\\bf X} \\in \\mathbb{R}^{3 \\times 2}$ と書かれることがあります。\n",
    "「$\\in$」は**属する**という意味で、これは「${\\bf X}$ は実数を要素として持つ $(3, 2)$ の行列である」ということを表します。\n",
    "しばしば行列は大文字、または大文字の太文字で表記することで区別されます。\n",
    "\n",
    "**テンソル** はベクトルや行列を一般化した概念であり、ベクトルは 1 階のテンソル、行列は 2 階のテンソルと言うことができます。\n",
    "また、図のように行列を奥行き方向にさらに並べたものは3階のテンソルと呼ばれます。例えば、カラー画像をデジタル表現する場合、１ 枚の画像は RGB (Red Green Blue) などの複数のチャンネルを持つのが一般的です。\n",
    "各チャンネルは行列となっていて、それが ３ 枚重なったものとして １ 枚の画像が取り扱われます。\n",
    "つまり、行列がチャンネル方向に複数積み重なっているため、画像は 3 階テンソルとして捉えられます。\n",
    "本資料では、単に「テンソル」と言った場合は３階以上のテンソルを指します。\n",
    "\n",
    "![テンソル](images/03/03_07.png)\n",
    "\n",
    "線形代数では ${\\bf y}$ や ${\\bf X}$ 、 $a$ や $K$ といった様々な字体の文字が含まれる式を扱います。その際、これはベクトル、これは行列、などを常に意識しながら式を追いかけていくのがおすすめです。以下に文字のスタイルと、その意味を簡単に表でまとめておきます。\n",
    "\n",
    "|  字体  | 小文字         | 大文字         |\n",
    "|:------:|:--------------:|:--------------:|\n",
    "| 細字   | スカラーの変数 ($a, b$ など) | スカラーの定数 ($A, B$ など) |\n",
    "| 太字   | ベクトル (${\\bf x}, {\\bf y}$ など)       | 行列、テンソル (${\\bf A}, {\\bf B}$ など) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WQ0tHkac7q77"
   },
   "source": [
    "### 加算・減算\n",
    "\n",
    "行列やベクトル同士の演算について学んでいきます。\n",
    "加算及び減算は同じサイズの行列またはベクトルの間だけで成立します。\n",
    "以下に、行列およびベクトル同士の加算を具体例で示します。\n",
    "\n",
    "**ベクトル同士の加算**\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "1 \\\\\n",
    "2 \\\\\n",
    "3\n",
    "\\end{bmatrix}+\\begin{bmatrix}\n",
    "4 \\\\\n",
    "5 \\\\\n",
    "6\n",
    "\\end{bmatrix}=\\begin{bmatrix}\n",
    "1 + 4 \\\\\n",
    "2 + 5 \\\\\n",
    "3 + 6\n",
    "\\end{bmatrix}=\\begin{bmatrix}\n",
    "5 \\\\\n",
    "7 \\\\\n",
    "9\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "**行列同士の加算**\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "1 & 2 & 3 \\\\\n",
    "4 & 5 & 6\n",
    "\\end{bmatrix}+\\begin{bmatrix}\n",
    "7 & 8 & 9 \\\\\n",
    "10 & 11 & 12 \n",
    "\\end{bmatrix}=\\begin{bmatrix}\n",
    "1+7 & 2+8 & 3+9 \\\\\n",
    "4+10 & 5+11 & 6+12\n",
    "\\end{bmatrix}=\\begin{bmatrix}\n",
    "8 & 10 & 12 \\\\\n",
    "14 & 16 & 18\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "行列やベクトルの中の要素を、それぞれ対応する位置にある要素と足し合わせています。\n",
    "このような計算は、**要素ごとの (element-wise)** 計算とも呼ばれ、**互いに同じサイズのベクトル間もしくは行列間でないと計算が成立しない**ことを覚えておきましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YAj8RCXV7q78"
   },
   "source": [
    "### 内積\n",
    "\n",
    "同じサイズのベクトル間では**内積 (inner product)** が定義できます。\n",
    "内積は、 $\\cdot$ で表され、同じ位置の対応する要素同士を掛けていき、それらを足し合わせる計算です。\n",
    "\n",
    "$$\n",
    "\\begin{aligned}& \\begin{bmatrix}\n",
    "1 & 2 & 3\n",
    "\\end{bmatrix} \\cdot \\begin{bmatrix}\n",
    "4 \\\\ \n",
    "5 \\\\ \n",
    "6\n",
    " \\end{bmatrix} = 1 \\times 4 + 2 \\times 5  + 3 \\times 6 = 32 \\end{aligned}\n",
    "$$\n",
    "\n",
    "内積の $\\cdot$ は省略することもできます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T5znTS-c7q79"
   },
   "source": [
    "### 行列積\n",
    "\n",
    "行列の乗算には、　**行列積**、**外積**、**要素積（アダマール積）**など複数種類の演算方法があります。\n",
    "ここではそのうち最もよく使われる**行列積**について説明します。\n",
    "以降では明示しない限り、行列を掛け合わせる、などと言ったときには行列積を指すこととします。\n",
    "\n",
    "行列 ${\\bf A}$ と行列 ${\\bf B}$ の行列積は、${\\bf A}$ の各行と ${\\bf B}$ の各列の内積を並べたものとして定義されます。\n",
    "例えば、行列 ${\\bf A}$ の 1 行目の行ベクトルと、行列 ${\\bf B}$ の 1 列目の列ベクトルの内積の結果は、${\\bf A}$ と ${\\bf B}$ の行列積の結果を表す行列 ${\\bf C}$ の 1 行 1 列目に対応します。\n",
    "\n",
    "![行列積](images/03/03_08.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "そして、内積が定義される条件はベクトルのサイズが等しいということでしたが、ここでもそれが成り立つために、${\\bf A} \\in \\mathbb{R}^{N \\times M}$, ${\\bf B} \\in \\mathbb{R}^{O \\times  P}$ のとき、${\\bf A} {\\bf B}={\\bf C}$ の行列積が成り立つために、${\\bf  A}$ の**列数** $M$ と ${\\bf B}$ の**行数**  $O$ が一致する必要があります[<sup>*5</sup>](#fn5)。\n",
    "つまり、\n",
    "\n",
    "$$\n",
    "M = O\n",
    "$$\n",
    "\n",
    "となります。\n",
    "そして、結果の行列 ${\\bf C}$ の行数と列数は ${\\bf A}$ の行数 $N$ と ${\\bf B}$ の列数 $P$ とそれぞれ等しくなります。\n",
    "したがって、${\\bf C} \\in \\mathbb{R}^{N \\times P}$ となります。\n",
    "\n",
    "![matrix_product](images/03/matrix_product.jpg)\n",
    "\n",
    "また、行列積がスカラー積と大きく異なる性質のひとつとして、${\\bf AB}$ と ${\\bf BA}$ が等しいとは限らないということが挙げられます。この違いを明示的に表現する場合、行列 ${\\bf A}$ に行列 ${\\bf B}$ を左から掛けること（ ${\\bf BA}$ の計算）を行列 ${\\bf B}$ を行列 ${\\bf A}$ に**左乗**すると言い、右から掛ける場合は**右乗**すると言います。\n",
    "\n",
    "行列積は線形代数や機械学習の多くの問題で使われます。また、行列同士の演算には割り算（例えば ${\\bf A} / {\\bf B}$ ）に相当するものはありませんが、後述する**逆行列**を使った ${\\bf A} {\\bf B}^{-1}$ のような計算は存在します。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "それでは、行列の計算条件も確認しながら、下記の 3 つの練習問題の計算を行ってください。\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "&\\left( 1\\right) \n",
    "\\begin{bmatrix}\n",
    "1 & 2\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "3 \\\\ \n",
    "4\n",
    "\\end{bmatrix}\\\\ \n",
    "&\\left( 2\\right) \n",
    "\\begin{bmatrix}\n",
    "1 & 2 \\\\ \n",
    "3 & 4 \n",
    "\\end{bmatrix}\\begin{bmatrix}\n",
    "5 \\\\ \n",
    "6 \n",
    "\\end{bmatrix}\\\\ \n",
    "&\\left( 3\\right) \n",
    "\\begin{bmatrix} \n",
    "1 & 2 \n",
    "\\end{bmatrix}\\begin{bmatrix} \n",
    "3 & 4 \\\\ \n",
    "5 & 6 \n",
    "\\end{bmatrix}\\begin{bmatrix} \n",
    "3 \\\\ \n",
    "1\n",
    "\\end{bmatrix} \n",
    "\\end{aligned} \n",
    "$$ \n",
    "\n",
    "こちらが解答です。\n",
    "\n",
    "$$\n",
    "\\begin{aligned} \n",
    "&\\left( 1\\right) \n",
    "\\begin{bmatrix} \n",
    "1 & 2 \n",
    "\\end{bmatrix}\\begin{bmatrix} \n",
    "3 \\\\ \n",
    "4 \n",
    "\\end{bmatrix} = 1\\times 3 + 2 \\times 4 = 11\\\\ \n",
    "&\\left( 2\\right) \n",
    "\\begin{bmatrix} \n",
    "1 & 2 \\\\ \n",
    "3 & 4\n",
    "\\end{bmatrix}\\begin{bmatrix} \n",
    "5 \\\\ \n",
    "6\n",
    "\\end{bmatrix} = \\begin{bmatrix} \n",
    "1 \\times 5 + 2 \\times 6 \\\\ \n",
    "3 \\times 5 + 4 \\times 6 \n",
    "\\end{bmatrix} = \\begin{bmatrix} \n",
    "17 \\\\ \n",
    "39 \n",
    "\\end{bmatrix}\\\\ \n",
    "&\\left( 3\\right) \n",
    "\\begin{bmatrix} \n",
    "1 & 2 \n",
    "\\end{bmatrix}\\begin{bmatrix} \n",
    "3 & 4 \\\\ \n",
    "5 & 6 \n",
    "\\end{bmatrix}\\begin{bmatrix} \n",
    "3 \\\\ \n",
    "1 \n",
    "\\end{bmatrix} \n",
    "=\\begin{bmatrix} \n",
    "1 & 2 \n",
    "\\end{bmatrix}\\begin{bmatrix} \n",
    "3 \\times 3 + 4 \\times 1 \\\\ \n",
    "5 \\times 3 + 6 \\times 1 \n",
    "\\end{bmatrix} = \\begin{bmatrix} \n",
    "1 & 2 \n",
    "\\end{bmatrix}\\begin{bmatrix} \n",
    "13 \\\\ \n",
    "21 \n",
    "\\end{bmatrix}\n",
    "= 1 \\times 13 + 2 \\times 21 \n",
    "=55\n",
    "\\end{aligned} \n",
    "$$\n",
    "\n",
    "このような計算は、機械学習の基礎を学習していく過程でよく登場します。行列積では、演算前と後の行数・列数の変化に注意しましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mFA54KR47q7-"
   },
   "source": [
    "### 転置\n",
    "\n",
    "ベクトルは縦方向に要素が並んだ列ベクトルを基本としていましたが、横方向に要素が並んだ行ベクトルを使いたい場合もあります。そこで列ベクトルを行ベクトルに、行ベクトルを列ベクトルに変換する操作を**転置 (transpose)** とよび、ベクトルを表す文字の右肩に ${\\rm T}$ と書くことでこの操作が行われることを表します。例えば、\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "{\\bf x}\n",
    "&=\\begin{bmatrix}\n",
    "1 \\\\\n",
    "2 \\\\\n",
    "3\n",
    "\\end{bmatrix}, \\ \n",
    "{\\bf x}^{\\rm T} = \\begin{bmatrix} 1 & 2 & 3 \\end{bmatrix} \\\\\n",
    "{\\bf X}\n",
    "&=\\begin{bmatrix}\n",
    "1 & 4 \\\\\n",
    "2 & 5 \\\\\n",
    "3 & 6\n",
    "\\end{bmatrix}, \\\n",
    "{\\bf X}^{\\rm T}=\\begin{bmatrix}\n",
    "1 & 2 & 3 \\\\\n",
    "4 & 5 & 6\n",
    "\\end{bmatrix}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "のようになります。行列に対する転置では、行列の形が $(N, M)$ だったものは行と列が入れ替わるため形が $(M, N)$ の行列となります。つまり、 $i$ 行 $j$ 列目の値が転置後には $j$ 行 $i$ 列目の値になります。転置の公式として次を覚えておきましょう。\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "&\\left( 1\\right) \\ \\left( {\\bf A}^{\\rm T} \\right)^{\\rm T} = {\\bf A} \\\\\n",
    "&\\left( 2\\right) \\ \\left( {\\bf A}{\\bf B} \\right)^{\\rm T} = {\\bf B}^{\\rm T}{\\bf A}^{\\rm T}\\\\\n",
    "&\\left( 3\\right) \\ \\left( {\\bf A}{\\bf B}{\\bf C} \\right)^{\\rm T} = {\\bf C}^{\\rm T}{\\bf B}^{\\rm T}{\\bf A}^{\\rm T}\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ukRIBXJL7q7_"
   },
   "source": [
    "### ベクトル・行列の形\n",
    "\n",
    "行列積を行った後は行列の形が変化します。\n",
    "形が $(L, M)$ の行列と $(M, N)$ の行列の行列積の結果は $(L, N)$ となります。\n",
    "先ほどの 3 つの練習問題では、行列やベクトルの形・サイズがどのように変化していたかを確認してみましょう。\n",
    "\n",
    "![演算後の行列](images/03/03_09.png)\n",
    "\n",
    "特に (3) では、一番左端のベクトルと、真ん中の行列の乗算結果が、行ベクトルであるため、サイズの変化が (1) と同じケースに帰着することに注意してください。\n",
    "また、ある次元のサイズが 1 となった場合（例えば $(3, 1)$ の行列など）その次元を削除しベクトルをスカラーとして、行列をベクトルとして扱う場合があります。このようにサイズが 1 になった一部の次元をつぶす操作を `squeeze` と呼ぶ場合があります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PGh56iiO7q8A"
   },
   "source": [
    "### 単位行列\n",
    "\n",
    "スカラー値の $1$ は、 $10 \\times 1 = 10$ のように、任意の数を $1$ に乗じても値が変化しないという性質を持ちます。行列の演算において、これと同様の働きをする行列が**単位行列 (unit matrix)** です。\n",
    "\n",
    "$$\n",
    "{\\bf I} =\n",
    "\\begin{bmatrix}\n",
    "1 & 0 & \\cdots  & 0 \\\\\n",
    "0 & 1 & \\cdots  & 0 \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots  \\\\\n",
    "0 & 0 & \\cdots  & 1\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "単位行列は上記のような形をしており、記号 ${\\bf I}$ で表されるのが一般的です。行列の斜めの要素を**対角要素**とよび、それ以外の要素を非対角要素とよびます。単位行列は、対角要素が全て $1$ で、非対角要素が全て $0$ であるような **正方行列**（行数と列数が等しい行列）です。例えば、$2 \\times 2$ の単位行列は、\n",
    "\n",
    "$$\n",
    "{\\bf I} =\n",
    "\\begin{bmatrix}\n",
    "1 & 0 \\\\\n",
    "0 & 1\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "であり、$3 \\times 3$の単位行列は、\n",
    "\n",
    "$$\n",
    "{\\bf I} =\n",
    "\\begin{bmatrix}\n",
    "1 & 0 & 0 \\\\\n",
    "0 & 1 & 0 \\\\\n",
    "0 & 0 & 1\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "です。行列のサイズを明示したい場合に、 $I_n$ （ $n \\times n$ の単位行列の意味）と添字でサイズを表記することがあります。\n",
    "\n",
    "単位行列はサイズが等しい任意の正方行列 ${\\bf A}$ に対して以下の計算が成立します。\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "{\\bf A}{\\bf I} &= {\\bf A} \\\\\n",
    "{\\bf I}{\\bf A} &= {\\bf A}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "適当な値を持つ行列を用意して、単位行列を掛け、元の行列と値が変わらないことを確認してみましょう。\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\begin{bmatrix}\n",
    "1 & 2 \\\\\n",
    "3 & 4\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "1 & 0 \\\\\n",
    "0 & 1\n",
    "\\end{bmatrix}\n",
    "&=\n",
    "\\begin{bmatrix}\n",
    "1 \\times 1 + 2 \\times 0 & 1 \\times 0 + 2 \\times 1 \\\\\n",
    "3 \\times 1 + 4 \\times 0 & 3 \\times 0 + 4 \\times 1\n",
    "\\end{bmatrix} \\\\\n",
    "&=\n",
    "\\begin{bmatrix}\n",
    "1 & 2 \\\\\n",
    "3 & 4\n",
    "\\end{bmatrix}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "計算結果から分かる通り、元の行列と全ての要素が一致しました。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "truuSeTL7q8G"
   },
   "source": [
    "### 逆行列\n",
    "\n",
    "行列 ${\\bf A}$ に対し、 ${\\bf AB} = {\\bf I}$ , ${\\bf BA} = {\\bf I}$ を満たす行列 ${\\bf B}$ のことを ${\\bf A}$ の**逆行列 (inverse matrix)** といい、このような条件を満たすものは存在すれば 1 つであることが知られています。\n",
    "行列 ${\\bf A}$ の逆行列は ${\\bf A}^{-1}$ と書きます。\n",
    "すなわち、定義から\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "{\\bf AA}^{-1} = {\\bf I} \\\\\n",
    "{\\bf A}^{-1}{\\bf A} = {\\bf I}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "が成立します。\n",
    "ここで、 ${\\bf I}$ は単位行列です。\n",
    "逆行列は、スカラーにおける逆数（ $2 \\times 2^{-1} = 1$ ）に対応するような行列です。\n",
    "\n",
    "サイズが $2 \\times 2$ や $3 \\times 3$ といった小さな行列の場合には、手計算でも可能な逆行列計算の方法が知られていますが、機械学習ではより大きなサイズの行列（ $1000 \\times 1000$ など）を扱うことがあり、そういった大きな行列の逆行列を効率的または近似的にコンピュータを使って計算する手法が研究されています。\n",
    "\n",
    "また、逆行列は常に存在するとは限りません。逆行列が存在するような行列のことを**正則行列**と呼びます。行列が正則であるための条件については話が複雑になるため、今回は説明しません。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "29LkWUqa7q8K"
   },
   "source": [
    "### 線形結合と二次形式\n",
    "\n",
    "機械学習の式によく出てくる形式として、 ${\\bf b}^{\\rm T}{\\bf x}$ と ${\\bf x}^{\\rm T}{\\bf A}{\\bf x}$ の 2 つがあります。\n",
    "前者は**線形結合**もしくは**一次結合**、後者は**二次形式**とよばれています。\n",
    "スカラーの一次式 ($ax + b$) や二次式 ($ax^2 + bx + c$) をベクトルに拡張したものと捉えると良いでしょう。\n",
    "\n",
    "線形結合の計算を要素ごとに見てみると、\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "{\\bf b}\n",
    "&=\n",
    "\\begin{bmatrix}\n",
    "1 \\\\\n",
    "2\n",
    "\\end{bmatrix},\\ \n",
    "{\\bf x} =\n",
    "\\begin{bmatrix}\n",
    "x_{1} \\\\\n",
    "x_{2}\n",
    "\\end{bmatrix}\\\\\n",
    "{\\bf b}^{\\rm T}{\\bf x}\n",
    "&=\n",
    "\\begin{bmatrix}\n",
    "1 & 2\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "x_1 \\\\\n",
    "x_2\n",
    "\\end{bmatrix}\n",
    "= x_1 + 2x_2\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "のように ${\\bf x}$ の要素である $x_1$ および $x_2$ に関して一次式となっています。\n",
    "\n",
    "また、二次形式も同様に要素ごとに確認してみると、\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "{\\bf A} &=\n",
    "\\begin{bmatrix}\n",
    "1 & 2 \\\\\n",
    "3 & 4\n",
    "\\end{bmatrix},\\ \n",
    "{\\bf x} =\n",
    "\\begin{bmatrix}\n",
    "x_{1} \\\\\n",
    "x_{2}\n",
    "\\end{bmatrix}\\\\\n",
    "{\\bf x}^{\\rm T}{\\bf A}{\\bf x}\n",
    "&=\n",
    "\\begin{bmatrix}\n",
    "x_1 & x_2\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "1 & 2 \\\\\n",
    "3 & 4\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "x_1 \\\\\n",
    "x_2\n",
    "\\end{bmatrix} \\\\\n",
    "&=\n",
    "\\begin{bmatrix}\n",
    "x_1 & x_2\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "x_1 + 2x_2 \\\\\n",
    "3x_1 + 4x_2\n",
    "\\end{bmatrix} \\\\\n",
    "&=\n",
    "x_1 \\left( x_1 + 2x_2 \\right) + x_2 \\left( 3x_1 + 4x_2 \\right) \\\\\n",
    "&=\n",
    "x^2_1 + 5x_1 x_2 + 4x_2^2\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "となり、各要素に関して二次式となっています。\n",
    "したがって、二次関数は\n",
    "\n",
    "$$\n",
    "{\\bf x}^{\\rm T}{\\bf A}{\\bf x} + {\\bf b}^{\\rm T}{\\bf x} + c\n",
    "$$\n",
    "\n",
    "と表記できます。ここで、 $c$ はスカラーの定数項です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a1hytPfx7q8M"
   },
   "source": [
    "### ベクトルによる微分と勾配\n",
    "\n",
    "微分は入力が変化した場合の関数値の変化量から求められました。\n",
    "これは関数の入力がベクトルである場合も同様です。\n",
    "ベクトルを入力にとる関数の微分を考えてみましょう。\n",
    "入力ベクトルの要素毎に出力に対する偏微分を計算し、それらを並べてベクトルにしたものが**勾配 (gradient)** です。\n",
    "\n",
    "まず勾配に関する計算の具体例を見てみましょう。\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "{\\bf b}\n",
    "&=\\begin{bmatrix}\n",
    "3 \\\\\n",
    "4\n",
    "\\end{bmatrix}, \\ \n",
    "{\\bf x} =\n",
    "\\begin{bmatrix}\n",
    "x_{1} \\\\\n",
    "x_{2}\n",
    "\\end{bmatrix}\\\\\n",
    "{\\bf b}^{\\rm T}{\\bf x} &=\n",
    "\\begin{bmatrix}\n",
    "3 & 4\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "x_1 \\\\\n",
    "x_2\n",
    "\\end{bmatrix}\n",
    "= 3x_1 + 4x_2\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "この ${\\bf b}^{\\rm T}{\\bf x}$ をベクトル ${\\bf x}$ で微分したものを、\n",
    "\n",
    "$$\n",
    "\\frac{\\partial}{\\partial {\\bf x}} \\left( {\\bf b}^{\\rm T}{\\bf x} \\right)\n",
    "$$\n",
    "\n",
    "と表します。\n",
    "「ベクトルで微分」とは、ベクトルの要素それぞれで対象を微分し、その結果を要素に対応する位置に並べたベクトルを作ることで、具体的には以下のような計算を指しています。\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\frac{\\partial}{\\partial {\\bf x}} \\left( {\\bf b}^{\\rm T} {\\bf x} \\right)\n",
    "&= \\frac{\\partial}{\\partial {\\bf x}} \\left( 3x_1 + 4x_2 \\right) \\\\\n",
    "&=\n",
    "\\begin{bmatrix}\n",
    "\\frac{\\partial}{\\partial x_1} \\left( 3x_1 + 4x_2 \\right) \\\\\n",
    "\\frac{\\partial}{\\partial x_2} \\left( 3x_1 + 4x_2 \\right)\n",
    "\\end{bmatrix}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "各要素の計算を進めると、以下のようになります。\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\frac{\\partial}{\\partial x_1} \\left( 3x_1 + 4x_2 \\right)\n",
    "&= \\frac{\\partial}{\\partial x_1} \\left( 3x_1 \\right)\n",
    "+ \\frac{\\partial}{\\partial x_1} \\left( 4x_2 \\right) \\\\\n",
    "&= 3 \\times \\frac{\\partial}{\\partial x_1} \\left( x_1 \\right)\n",
    "+ 4x_{2} \\times \\frac{\\partial}{\\partial x_1} (1) \\\\\n",
    "&= 3 \\times 1 + 4x_{2} \\times 0 \\\\\n",
    "&= 3\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\frac{\\partial}{\\partial x_2} \\left( 3x_1 + 4x_2 \\right)\n",
    "&= \\frac{\\partial}{\\partial x_2} \\left( 3x_1 \\right)\n",
    "+ \\frac{\\partial}{\\partial x_2} \\left( 4x_2 \\right) \\\\\n",
    "&= 3x_{1} \\times \\frac{\\partial}{\\partial x_2} (1)\n",
    "+ 4 \\times \\frac{\\partial}{\\partial ax_2} (x_{2}) \\\\\n",
    "&= 3x_{1} \\times 0 + 4 \\times 1 \\\\\n",
    "&= 4\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "計算結果を整理すると、以下のようになります。\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\frac{\\partial}{\\partial {\\bf x}} \\left( {\\bf b}^{\\rm T}{\\bf x} \\right)\n",
    "&=\n",
    "\\begin{bmatrix}\n",
    "\\frac{\\partial}{\\partial x_1} \\left( 3x_1 + 4x_2 \\right)  \\\\\n",
    "\\frac{\\partial}{\\partial x_2} \\left( 3x_1 + 4x_2\\right) \n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "3  \\\\\n",
    "4\n",
    "\\end{bmatrix}\n",
    "=\n",
    "{\\bf b}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "もう一つ別の例を考えてみましょう。\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "{\\bf b}\n",
    "&=\n",
    "\\begin{bmatrix}\n",
    "3 \\\\\n",
    "4\n",
    "\\end{bmatrix}, \\ \n",
    "{\\bf x}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "x_{1} \\\\\n",
    "x_{2}\n",
    "\\end{bmatrix} \\\\\n",
    "\\frac{\\partial}{\\partial {\\bf x}} \\left( {\\bf b} \\right)\n",
    "&=\n",
    "\\begin{bmatrix}\n",
    "\\frac{\\partial}{\\partial x_1} \\left( 3 \\right)  \\\\\n",
    "\\frac{\\partial}{\\partial x_2} \\left( 4 \\right) \n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "0 \\\\\n",
    "0\n",
    "\\end{bmatrix}\n",
    "=\n",
    "{\\bf 0}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "偏微分を行う対象に変数が含まれていない場合、その偏微分は $0$ となります。要素が $0$ のみで構成されたベクトルを**ゼロベクトル**と言い、数字の $0$ を太字にした ${\\bf 0}$ で表します。\n",
    "\n",
    "これらを踏まえて、いくつかよく現れるベクトルによる微分の計算結果をまとめて覚えておきましょう。\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "&\\left( 1 \\right) \\ \\frac{\\partial}{\\partial {\\bf x}} \\left( {\\bf c} \\right) = {\\bf 0} \\\\\n",
    "&\\left( 2 \\right) \\ \\frac{\\partial}{\\partial {\\bf x}} \\left( {\\bf b}^{\\rm T}{\\bf x} \\right) = {\\bf b} \\\\\n",
    "&\\left( 3 \\right) \\ \\frac{\\partial}{\\partial {\\bf x}} \\left( {\\bf x}^{\\rm T}{\\bf A}{\\bf x} \\right) = \\left( {\\bf A} + {\\bf A}^{\\rm T} \\right) {\\bf x}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "(1)　と　(2) はすでに導出済みです。(3) は導出が少し複雑なので省略しますが、数値を代入して確認してみてください。\n",
    "この　3　つの計算は機械学習を学んでいく上でよく登場します。\n",
    "\n",
    "こういった行列やベクトルの計算で用いられる公式は他にもたくさんあり、知っておくと便利なものが [The Matrix Cookbook](https://www.math.uwaterloo.ca/~hwolkowi/matrixcookbook.pdf) などにまとまっています。\n",
    "論文等を読む際などにも参照すると便利かもしれません。\n",
    "\n",
    "本章では多変数を入力にとり、単一の出力を返す関数の微分を考えました。しかし、多変数の入力をとり多変数の出力を返す関数の微分を考える必要もでてきます。そのような微分結果はヤコビ行列（ヤコビアン）と呼ばれ、ニューラルネットワークの学習方法を理解するために必要となります。\n",
    "計算方法が [The Matrix Calculus You Need For Deep Learning](https://arxiv.org/abs/1802.01528) に分かりやすくまとまっています。ぜひ参考にしてください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr />\n",
    "<span id=\"fn1\"><sup>*1</sup>: <small>*特徴量変換を施した場合、**特徴量** と呼ぶこともありますが、本チュートリアルでは特徴量も含め、入力変数という呼び名で統一することとします。</small></span>\n",
    "\n",
    "<span id=\"fn2\"><sup>*2</sup>: <small>*厳密には **目標値 (target value)** として観測されたデータを教師データと呼びますが、説明をシンプルにするために、すべて教師データで統一して紹介しています。$t$ は target value から由来しています。また、教師データが必要となるケースは機械学習の中でも教師あり学習に限られますが、本チュートリアルでは教師あり学習を中心に扱うため、機械学習の一般的な考え方を教師あり学習を中心に紹介しています。</small></span>\n",
    "\n",
    "<span id=\"fn3\"><sup>\\*3</sup> : <small> 間違えた度合いを測る関数を、特に**損失関数 (loss function)** と呼ぶ場合があります。 </small></span>\n",
    "\n",
    "<span id=\"fn4\"><sup>*4</sup>: <small>入力変数が他の入力変数と独立でない場合は定数と考えることはできません。しかし本資料ではそのようなケースは出てきません。</small></span>\n",
    "\n",
    "<span id=\"fn5\"><sup>*5</sup> : <small> $N \\times M$ 行列、などと言われたときに、$N$ と $M$ のどちらが行で、どちらが列だろう？と迷ったときは、「行列」という言葉を再度思い浮かべて、「行→列」つまり先にくる $N$ が行数で、$M$ が列数だ、と思い出すのがおすすめです。</small></span>\n",
    "\n",
    "<span id=\"fn6\"><sup>*6</sup>: <small>ここでは概念の説明を簡単にするため、この例のように離散的な値を取る確率変数を考え、特に明示しない限り連続値の確率変数は考えないことにします。</small></span>\n",
    "\n",
    "<span id=\"fn7\"><sup>*7</sup>: <small> $x$ は $1, 2, 3, 4, 5, 6$ のいずれか。すなわち $x \\in \\{1, 2, 3, 4, 5, 6\\}$</small></span>\n",
    "\n",
    "<span id=\"fn8\"><sup>*8</sup>: <small> $y$ は 2 つ目のコインが取りうる状態で、この場合、「表」と「裏」という値のいずれか。</small></span>\n",
    "\n",
    "<span id=\"fn9\"><sup>*9</sup>: <small> $x$ は 1 つ目のコインが取りうる状態で、この場合、「表」と「裏」という値のいずれか。</small></span>\n",
    "\n",
    "<span id=\"fn10\"><sup>\\*10</sup>: <small>以降、このことを「データの分布を推定する」と言うことがあります。また、観測されたデータのみから各データの発生確率（頻度とも捉えられる）を求めたものは**経験分布（empirical distribution）**とも呼ばれ、本節で説明しているのは正確にはこの経験分布を確率モデルで近似する方法です。</small></span>\n",
    "\n",
    "<span id=\"fn11\"><sup>\\*11</sup>: <small>この関数には、ベルヌーイ分布いう名前がついています。</small></span>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "03_Basics_of_Math_for_Machine_Learning_ja.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
