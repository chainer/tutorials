{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "colab_type": "text",
                "id": "m1Ky8C_M7q8N"
            },
            "source": [
                "# 確率・統計の基礎"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "colab_type": "text",
                "id": "6ePOq9mw7q8O"
            },
            "source": [
                "## 確率や統計は何に使えるのか\n",
                "\n",
                "機械学習にも色々な手法があり、微分と線形代数の知識があれば理解できるアルゴリズムも多く存在します。しかし、「統計的機械学習」と呼ばれる分野の手法を理解するためには、確率・統計の知識が必須となります。\n",
                "\n",
                "また、機械学習の目的のひとつは、興味のある事象の個別の観測結果を集めたデータ集合（データセット）から、対象の事象の背後にある普遍性や法則性などを見つけ出すことです。確率は、どのようなデータがより頻繁に発生しやすいのか、を表現する確率分布という概念や、不確実性といった概念を取り扱うために利用することができます。また、対象のデータ集合に対して平均や分散などに代表される様々な統計量を計算し、機械学習のアルゴリズムにとって扱いやすいようにデータを正規化する、訓練したいモデルが適当なものなのか判断する、各データ点が外れ値かどうか判断する、といったことがよく行われます。"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "colab_type": "text",
                "id": "Op9IZ6pz7q8P"
            },
            "source": [
                "## 確率変数と確率分布\n",
                "\n",
                "この資料では、「確率」という言葉を数学的に厳密には定義しません。代わりに次のように考えます。ある対象としている現象の中で、様々な事象があり得るとき、それぞれの事象ごとに、それが「どの程度起きそうか」という度合いを考えます。確率とはその度合いのこととします。そして、その確率に従って、色々な値を取りうる**確率変数（random variable）**を考えます。確率変数は、名前に「変数」とついていますが、**「事象」を「数値」に変換する関数**と考えると理解しやすくなります。例えば、「コインを投げて表が出る」という「事象」を、「1」という「数値」に変換し、「コインを投げて裏が出る」という「事象」を、「0」という「数値」に変換する関数を考えると、これは「1」か「0」という値のどちらかを取りうる確率変数だ[<sup>*6</sup>](#fn6)ということになります。\n",
                "\n",
                "それでは、確率的現象の具体例を考えてみます。ある歪んだサイコロがあり、「サイコロを投げて $x$ という目が出た」という事象[<sup>*7</sup>](#fn7)を、$x$ という数値に対応させる確率変数 $X$ があるとします。そして、この確率変数が取りうる全ての値が、それぞれどのような確率で出現するかを表した以下のような表があります。\n",
                "\n",
                "| 確率変数 $X$ の値 | その値をとる確率 |\n",
                "|:-----------------:|:----------------:|\n",
                "| 1                 | $0.3$            |\n",
                "| 2                 | $0.1$            |\n",
                "| 3                 | $0.1$            |\n",
                "| 4                 | $0.2$            |\n",
                "| 5                 | $0.1$            |\n",
                "| 6                 | $0.2$            |\n",
                "\n",
                "このような表のことを**確率分布 (probability distribution)** と呼びます。確率分布には重要な制約があり、「確率変数が取りうるあらゆる値の確率をすべて足すと和が必ず $1$ になること」及び「全ての確率は $0$ 以上の値であること」の両者を常に満たします。上の表の左の列に並ぶ数値を**実現値**と呼び、小文字の $x$ で表します。そして、右の列に並ぶそれぞれの $x$ に対応する確率を $p(x)$ と書きます。すなわち、上の表から $p(1) = 0.3$ , $p(2) = 0.1$ , ...といった式が成り立ちます。このような表記を用いると、確率分布が持つ2つの制約は、以下のように表せます。\n",
                "\n",
                "$$\n",
                "\\begin{align}\n",
                "\\sum_x p(x) &= 1 \\\\\n",
                "\\forall x, \\ p(x) & \\geq  0\n",
                "\\end{align}\n",
                "$$\n",
                "\n",
                "ここで、 $\\sum_x$ は全てのありうる $x$ の値にわたる和を表し、例えば上のサイコロの例では、 $\\sum_{x=1}^6$ と同じことを意味します。 $\\forall x$ は、あり得る $x$ の値すべてにおいて、右の条件（ $p(x) \\geq 0$ ）が成り立つ、ということを意味しています。\n",
                "\n",
                "また、 $p(1) = 0.3$ というのは、確率変数 $X$ が $1$ という値をとる確率ということですが、これを $p(X = 1) = 0.3$ とも書きます。また、$p(x)$ という表記も登場しますが、これは $p(X = x)$ を簡単に表記したもので、 $X$ という確率変数がある値 $x$ を取る確率という意味です。一方、 $p(X)$ と確率変数だけを引数に取る場合、これは上の表のような確率分布を意味します。"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "colab_type": "text",
                "id": "BLiWD0sm7q8R"
            },
            "source": [
                "## 同時分布・周辺確率\n",
                "\n",
                "前節では、1 つの確率変数について、その分布（確率分布のこと）とはなにかと、分布が持つ制約について說明しました。この節では、複数の確率変数が登場する場合について考えます。\n",
                "\n",
                "まず具体例を用いて考えてみます。ここに 2 つのサイコロがあり、それぞれのサイコロの出目を 2 つの確率変数 $X, Y$ で表します。この 2 つのサイコロを同時に振って、1 つ目のサイコロが $x$ という値をとり、2 つ目のサイコロが $y$ という値をとったという事象の確率は、以下のように書き表します。\n",
                "\n",
                "$$\n",
                "p(X = x, Y = y)\n",
                "$$\n",
                "\n",
                " $x, y$ はいずれも $1, 2, 3, 4, 5, 6$ の6つの数字のどれかです。例えば、「3」と「5」の目が出る、という事象が起こる確率は\n",
                "\n",
                "$$\n",
                "p(X = 3, Y = 5)\n",
                "$$\n",
                "\n",
                "と表されます。このように、 $X = 3$ となる**かつ** $Y = 5$ となる、といった複数の条件を指定したときに、それらが全て同時に成り立つ確率のことを、**同時確率（joint probability）**と呼びます。\n",
                "\n",
                "では次に、この 2 つのサイコロを別々に見てみましょう。例えば、「1 つ目のサイコロが $3$ の目を出した」という事象が起こる確率 $p(X = 3)$ は、2 つ目のサイコロが何の目を出していようが関係ないので、1つ目のサイコロが $3$ **かつ** 2 つ目のサイコロが $1$ のとき／ $2$ のとき／ $3$ のとき／…／ $6$ のとき、の確率を全て足したものになります。つまり、\n",
                "\n",
                "$$\n",
                "p(X = 3) = \\sum_y p(X = 3, Y = y)\n",
                "$$\n",
                "\n",
                "と書けます。このとき、 $\\sum_y$ は「 $Y$ のとり得るあらゆる値 $y$ についての和」という意味です。これを、**「（2 つ目のサイコロの目がなんであれ） 1 つ目のサイコロの目が** $x$ **である確率」**と一般化すると、以下のようになります。\n",
                "\n",
                "$$\n",
                "p(X = x) = \\sum_y p(X = x, Y = y)\n",
                "$$\n",
                "\n",
                "同様に、「（1つ目のサイコロの目がなんであれ）2 つ目のサイコロの目が $y$ である確率」は、1つ目のサイコロについてあり得る値すべての確率の和を取れば良いので、\n",
                "\n",
                "$$\n",
                "p(Y = y) = \\sum_x p(X = x, Y = y)\n",
                "$$\n",
                "\n",
                "となります。このように、同時確率が与えられたとき、**着目していない方の確率変数がとり得る全ての値について同時確率を計算しその和をとる**ことを**周辺化 (marginalization)** と呼び、結果として得られる確率を**周辺確率 (marginal probability)** と呼びます。\n",
                "また、周辺確率をその着目している確率変数がとり得る全ての値について並べて一覧にしたものが**周辺確率分布 (marginal probability distribution)** です。\n",
                "さらに、上の例のように2つの確率変数の同時確率を考えるとき、とり得る全ての組み合わせの確率を一覧にしたものが、**同時分布 (joint distribution)** です。\n",
                "\n",
                "ここで、2 つのサイコロの同時分布の表は大きくなってしまうので、より簡単な例として、表が出る確率と裏が出る確率が異なる 2 つのコインを考えてみましょう。この 2 つのコインを同時に投げたときの表裏の組み合わせについての同時分布が、以下のようになったとします。\n",
                "\n",
                "\n",
                "| $\\ $   | Y = 表 | Y = 裏 |\n",
                "|:------:|:------:|:------:|\n",
                "| X = 表 | 1 / 5  | 2 / 5  |\n",
                "| X = 裏 | 1 / 5  | 1 / 5  |\n",
                "\n",
                "ここで、1 つ目のコインの表裏を表す確率変数を $X$ 、2 つ目のコインの表裏を表す確率変数を $Y$ としています。表の中身がどういう意味を持っているか確認してください。2 つのコインが両方表になる確率は $p(X = 表, Y = 表) = 1 / 5$ となっています。他のマスに書かれている同時確率の値の意味も確認してください。\n",
                "\n",
                "では、この表の中の数字を、行ごとに合計してみましょう。1 行目は、\n",
                "\n",
                "$$\n",
                "p(X = 表, Y = 表) + p(X = 表, Y = 裏) = 1 / 5 + 2 / 5 = 3 / 5\n",
                "$$\n",
                "\n",
                "です。\n",
                "これは、 $\\sum_y p(X = 表, Y = y)$ [<sup>*8</sup>](#fn8)を計算していることになるので、**周辺化によって** $p(X = 表)$ **という周辺確率を求めていることに相当します。**\n",
                "\n",
                "同様に、1 列目の値を合計してみると、今度は $\\sum_x p(X = x, Y = 表)$ [<sup>*9</sup>](#fn9) を計算することに相当し、これは周辺化によって $P(Y = 表)$ という周辺確率を計算していることになります。\n",
                "\n",
                "こうして計算される周辺確率を、**上の同時分布の表の周辺に書き入れてみます。**\n",
                "\n",
                "| $\\ $   | Y = 表 | Y = 裏 | p(X)  |\n",
                "|:------:|:------:|:------:|:-----:|\n",
                "| X = 表 | 1 / 5  | 2 / 5  | 3 / 5 |\n",
                "| X = 裏 | 1 / 5  | 1 / 5  | 2 / 5 |\n",
                "| p(Y)   | 2 / 5  | 3 / 5  |       |\n",
                "\n",
                "このように、周辺確率はしばしば同時分布表の周辺に記述されます。"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "colab_type": "text",
                "id": "JxM3Xjpl7q8S"
            },
            "source": [
                "## 条件付き確率\n",
                "\n",
                "前節では、複数の確率変数を同時に考える方法として同時確率および同時分布という概念と、同時確率と一つ一つの確率変数のみに着目した際の確率（周辺確率）のあいだの関係を、周辺化という計算で説明しました。\n",
                "本節では、「とある条件下での着目事象の確率」を考える**条件付き確率 (conditional probability)** という概念を説明します。\n",
                "これまでの節で扱っていた確率では、まず対象とする現象について、考えうる全ての事象を考え、そのうち対象とする事象が起きる確率はいくらか、を考えていました。\n",
                "一方、条件付き確率は、それらの考えうる事象のうち、特定の条件を満たした事象のみをまず抜き出し、その中で、さらに着目する特定の事象が起きる確率を考えるためのものです。\n",
                "\n",
                "例えば、あるお店にやってきた人（以下、客）が傘を持っているときに $1$ 、持っていなかったときに $0$ をとる確率変数 $X$ を考えます。\n",
                "また、ある客がやってきたときに外で雨が降っていたときに $1$ 、降っていなかったときに $0$ をとる確率変数 $Y$ を考えます。\n",
                "客が傘を持っていたかと、その瞬間に雨が降っていたかどうか、という 2 つの情報が組となったデータが 16 個あるとします。\n",
                "16 人の客を観測してデータを集めた、ということです。\n",
                "それは以下の様なものでした。\n",
                "\n",
                "| 傘 ( $X$ ) | 雨 ( $Y$ ) |\n",
                "|:--------:|:-------:|\n",
                "| 1 | 1 |\n",
                "| 1 | 1 |\n",
                "| 1 | 1 |\n",
                "| 1 | 1 |\n",
                "| 1 | 1 |\n",
                "| 1 | 1 |\n",
                "| 0 | 1 |\n",
                "| 0 | 1 |\n",
                "| 0 | 1 |\n",
                "| 1 | 0 |\n",
                "| 0 | 0 |\n",
                "| 0 | 0 |\n",
                "| 0 | 0 |\n",
                "| 0 | 0 |\n",
                "| 0 | 0 |\n",
                "| 0 | 0 |\n",
                "\n",
                "これらのデータから、確率変数 $X, Y$ の同時分布表を作成すると、以下のようになります。この表の作り方は、例えば表の左上のマスは $X = 0$ かつ $Y = 0$ となっているデータが　16 個中何個あるかを数えて、その割合を記入すればよく、他のマスについても同様となります。\n",
                "\n",
                "| $\\ $  | Y = 0  | Y = 1  |\n",
                "|:-----:|:------:|:------:|\n",
                "| X = 0 | 6 / 16 | 3 / 16 |\n",
                "| X = 1 | 1 / 16 | 6 / 16 |\n",
                "\n",
                "では、「客が傘を持っていた（ $X = 1$ ）」という**条件の下で**、「そのとき雨が降っていなかった（ $Y = 0$ ）」という確率は、どのようになるでしょうか？\n",
                "\n",
                "まず、「客が傘を持っていた（ $X = 1$ ）」という状況下のデータだけを、上の同時分布表から抜き出してきましょう。\n",
                "\n",
                "| 傘 ($X$) | 雨 ($Y$) |\n",
                "|:--------:|:-------:|\n",
                "| 1 | 1 |\n",
                "| 1 | 1 |\n",
                "| 1 | 1 |\n",
                "| 1 | 1 |\n",
                "| 1 | 1 |\n",
                "| 1 | 1 |\n",
                "| 1 | 0 |\n",
                "\n",
                "全部で 7 個のデータがあり、この中で「雨が降っていなかった（ $Y = 0$ ）」となっているデータは 1 個です。すなわち、「客が傘を持っていたという**条件の下で**、そのとき雨が降っていなかった確率」は $1 / 7$ となります。これを、以下のように書きます。\n",
                "\n",
                "$$\n",
                "p(Y = 0 | X = 1) = \\frac{1}{7}\n",
                "$$\n",
                "\n",
                "これが**条件付き確率**と呼ばれるもので、条件となる事象を縦棒 $|$ の後に書き、その条件下で注目している事象を縦棒 $|$ の前に書きます。同様に、「客が傘を持っていたという**条件の下で**、そのとき雨が降っていた確率」は、上の表から $6 / 7$ なので、以下が成り立ちます。\n",
                "\n",
                "$$\n",
                "p(Y = 1 | X = 1) = \\frac{6}{7}\n",
                "$$\n",
                "\n",
                "これらの 2 つの確率が、それぞれ $p(Y = 0, X = 1) = 1 / 16$ , $p(Y = 1, X = 1) = 6 / 16$ という同時確率とは異なっていることを、上の同時分布表と見比べて確認してみましょう。\n",
                "「客が傘を持っていて**かつ**外で雨が降っている」という同時確率は $6 / 16$ となっていますが、「客が傘を持っているという**条件の下で**外で雨が降っている」という条件付き確率は $6 / 7$ でした。\n",
                "前者は「客が傘を持っておらず外で雨が降っていた」「客が傘を持っておらず外で雨が降っていなかった」「客が傘を持っていたが外で雨が降っていなかった」を含むあり得る全ての事象を考えた上で、その中で対象としている事象「客が傘を持っていて外で雨が降っている」が起こる確率を意味しています。一方で、後者の条件付き確率は、今条件となっている事象「客が傘を持っている」が成り立っている事象だけをまず対象とし、その中で着目している事象「外で雨が降っている」が起こる確率を考えます。それぞれの確率の値を計算する際の分母が異なっていることに注目してください。\n",
                "\n",
                "また、上記の 2 つの条件付き確率を足すと、 $1$ になります。「ある条件下で」という制約された世界で、対象とする確率変数がとり得る値全ての確率を並べて一覧したものは**条件付き分布（conditional distribution）**と呼ばれ、それらの確率を全て足すと必ず $1$ になります。上の例では、以下の計算で確かめられます。\n",
                "\n",
                "$$\n",
                "p(Y = 0 | X = 1) + p(Y = 1 | X = 1) = \\frac{1}{7} + \\frac{6}{7} = 1\n",
                "$$\n",
                "\n",
                "ここで、確率変数 $X$ が取りうる実際の値のうちいずれかを表す文字として $x$ を、確率変数 $Y$ が取りうる実際の値のうちいずれかを表す文字として $y$ を用いると、一般的に、条件付き確率は以下のように定義されます。\n",
                "\n",
                "$$\n",
                "p(Y = y | X = x)\n",
                "= \\frac{p(X = x, Y = y)}{p(X = x)}\n",
                "$$\n",
                "\n",
                "このとき、条件付き分布が満たす条件は以下のように表せます。\n",
                "\n",
                "$$\n",
                "\\sum_y p(Y = y | X = x) = 1\n",
                "$$\n",
                "\n",
                "ここで、 $\\sum_x P(Y = y | X = x)$ は必ずしも1にならないということに注意してください。\n",
                "\n",
                "では、上の条件付き確率の定義を用いて、同時確率と周辺確率から条件付き確率を、再度計算してみましょう。\n",
                "\n",
                "$$\n",
                "\\begin{align}\n",
                "p(Y = 0 | X = 1)\n",
                "&= \\frac{p(X = 1, Y = 0)}{p(X = 1)} \\\\\n",
                "&= \\frac{\\frac{1}{16}}{\\frac{7}{16}} \\\\\n",
                "&= \\frac{1}{7}\n",
                "\\end{align}\n",
                "$$\n",
                "\n",
                "確かに、上で別の方法で求めた条件付き確率と一致しました。\n",
                "\n",
                "さて、上で触れた、同時確率と条件付き確率の関係について再度考えてみましょう。前述の「条件付き確率の定義」の式を変形すると、以下のようになります。以降では、簡単のために、確率変数の記述を省き、 $p(X = x)$ を $p(x)$ と表記します。確率変数 $X$ によって $x$ という値に対応付けられている事象が生じる確率、という意味です。同様に、 $p(Y = y)$ を $p(y)$ と表記します。\n",
                "\n",
                "$$\n",
                "p(x, y) = p(y | x) p(x)\n",
                "$$\n",
                "\n",
                "同時確率は、条件付き確率に、その条件となっている事象が生じる確率（周辺確率）を掛け合わせることで得られることが分かります。\n",
                "\n",
                "今回の例では、「雨が降っているかどうか」によって「客が傘を持っていたかどうか」は影響を受けるため、2つの確率変数 $Y, X$ は**従属**、と言います。一方、例えば「客が来たとき雨が降っていたかどうか」と「私が今お腹が空いているかどうか」が全く関係していないとします。後者について、お腹が空いているという事象を $1$ に、お腹が空いていないという事象を $0$ に対応付ける確率変数 $Z$ を導入すると、$Y$ と $Z$ が今**独立**であるという状況です。このとき、$Z$ の実現値を $z$ として、条件付き確率 $p(y | z)$ は、$Y$ がどうなるかが $Z$ がどうなるかに全く関係がないことから、 $p(y)$ と等しくなります。条件付けたとしても、条件付けなかったとしても、結果が変わらないためです。これを用いると、 $y$ と $z$ の同時確率は以下のように変形できます。\n",
                "\n",
                "$$\n",
                "\\begin{align}\n",
                "p(y, z) &= p(y | z) p(z) \\\\\n",
                "p(y, z) &= p(y) p(z)\n",
                "\\end{align}\n",
                "$$\n",
                "\n",
                " $Y$ と $Z$ が独立であることから、 $p(y | z) = p(y)$ となることを用いました。この式から、**2つの確率変数が独立であるとき、同時確率はそれぞれの周辺確率の積で書ける**ということが言えます。"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "colab_type": "text",
                "id": "Uv8wbpBs7q8T"
            },
            "source": [
                "## ベイズの定理\n",
                "\n",
                "前節で説明した条件付き確率は、ある前提が成り立っている状況下で着目する事象が生じる確率を記述するためのものでした。これは、**「ある\"原因\"が生じたという条件の下で、ある\"結果\"が生じる確率」**を考えていると捉えることができます。では、逆に**「ある\"結果\"が観測されたというとき、ある事象が\"原因\"である確率」**を考えるにはどうしたら良いでしょうか。今、原因となり得る事象が確率変数 $X$ で表され、結果となり得る事象が確率変数 $Y$ で表されるとします。このとき、原因として実際に $x$ が観測されたもとで結果が $y$ となる確率が条件付き確率\n",
                "\n",
                "$$\n",
                "p(Y = y | X = x)\n",
                "$$\n",
                "\n",
                "で表されました。前節の定義から、これに原因 $x$ がそもそも発生する確率 $p(X = x)$ を掛け合わせると、同時確率 $p(Y = y, X = x)$ になります。すなわち、\n",
                "\n",
                "$$\n",
                "p(Y = y | X = x) p(X = x) = p(Y = y, X = x) \\hspace{2em} \\cdots (1)\n",
                "$$\n",
                "\n",
                "です。では、結果が $y$ であったという観測の下で、原因が $x$ である確率はどのように表されるでしょうか。これは上の「条件の事象」と「着目する事象」を入れ替えた条件付き確率として、\n",
                "\n",
                "$$\n",
                "p(X = x | Y = y)\n",
                "$$\n",
                "\n",
                "と書くことができます。 $y$ という結果が観測されたもとで、原因が $x$ であった確率という意味です。これに結果 $y$ がそもそも発生する確率 $p(Y = y)$ をかけ合わせると、条件付き確率の定義から\n",
                "\n",
                "$$\n",
                "p(X = x| Y = y) p(Y = y) = p(X = x, Y = y) \\hspace{2em} \\cdots (2)\n",
                "$$\n",
                "\n",
                "が導かれます。ここで、式(1)と式(2)の右辺が同じになっていることに着目します。すると、式(1)と式(2)の左辺同士を等号で結ぶことができ、\n",
                "\n",
                "$$\n",
                "p(Y = y | X = x) p(X = x) = p(X = x | Y = y) p(Y = y)\n",
                "$$\n",
                "\n",
                "が成り立つことが分かります。この式を変形して、求めたい「結果 $y$ が生じたという**条件の下で**原因が $x$ である確率」を左辺に残すと、\n",
                "\n",
                "$$\n",
                "p(X = x | Y = y) = \\frac{p(Y = y | X = x) p(X = x)}{p(Y = y)}\n",
                "$$\n",
                "\n",
                "が導かれます。これを**ベイズの定理（Bayes' theorem）**と言います。これによって、ある結果が観測されたときに、ある事象が原因である確率を、\n",
                "\n",
                "- 原因として考えている事象が（結果と関係なく）そもそも生じる確率（ $p(X = x)$ ）\n",
                "- 結果として観測した事象が（原因に関係なく）そもそも生じる確率（ $p(Y = y)$ ）\n",
                "- 考えている原因が実際に生じたという下で観測された結果が生じる確率（ $p(Y = y | X = x)$ ）\n",
                "\n",
                "の3つから、求めることができます。ベイズの定理に登場する左辺の条件付き確率と右辺の分子にある周辺確率には、特別な呼び方があります。まず右辺の分子にある周辺確率（上式では $p(X = x)$ ）は、「結果」が観測する前（事前）に、原因 $x$ がそもそも生じる確率を表すので、**事前確率（prior probability)**と呼ばれます。一方、左辺の条件付き確率（上式では $p(X = x | Y = y)$ ）は、ある「結果 $y$」が観測されたという条件の下で（事後に）、原因 $x$ が生じていたという確率を表すので、**事後確率（posterior probability）**と呼ばれます。\n",
                "\n",
                "ベイズの定理の応用事例として、スパムメールフィルターがあります。まず、 $N$ 個の着目する単語 $w_i (i=1, \\dots, N)$ を決めます（\"sale\", \"buy\", \"free\", ...など）。そして、メールにある単語 $w_i$ が含まれるとき $1$ となり、含まれないとき $0$ となる確率変数を $W_i$ とし、「メールにある単語 $w_i$ が含まれる確率」を $p(W_i = 1)$ とします。 次に、メールがスパムメールであるとき $1$ となり、スパムメールでないとき $0$ となる確率変数を $Y$ とし、「スパムメールの存在確率」を $p(Y = 1)$ とします。このとき、「あるメールがスパムメールであったという**状況の下で**単語 $w_i$ が含まれていた」という確率は $p(W_i = 1 | Y = 1)$ となります。すると、例えば $w_i$ と $w_j$ が両方含まれていた場合は、同時確率 $p(W_i = 1, W_j = 1 | Y = 1)$ を考えることになりますが、各単語が独立に現れると仮定すると、これは $p(W_i = 1 | Y = 1) p(W_j = 1 | Y = 1)$ と分解できます。ここで、世の中にある大量のメールを集めて、各単語がどのくらいの確率で現れるかを調べると、 $p(W_i = 1) \\ (i=1,\\dots,N)$ が求まります。また、集めたメールからスパムメールだけを抜き出します。すると、メールがスパムメールである確率 $p(Y = 1)$ が求まります。さらに、それらのスパムメール中に含まれる単語を調べ、どの単語がどういう確率で出現しているかを、着目している全単語について求めると、 $p(W_i = 1 | Y = 1) \\ (i=1, \\dots, N)$ が全て求まります。これらを用いると、「あるメールに単語 $w_i, w_j, w_k, \\dots$ らが含まれているとき、そのメールがスパムメールである確率」を以下のように計算できます。\n",
                "\n",
                "$$\n",
                "p(Y = 1 | W_i = 1, W_j = 1, W_k = 1, \\dots ) = \\frac{p(W_i = 1, W_j = 1, W_k = 1, \\dots | Y = 1) p(Y = 1)}{p(W_i = 1, W_j = 1, W_k = 1, \\dots )}\n",
                "$$"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "colab_type": "text",
                "id": "N_ri8geU7q8U"
            },
            "source": [
                "## 尤度と最尤推定\n",
                "\n",
                "これまでの節では、「**確率変数が取りうる様々な値に確率を対応させる**」確率分布は、表の形で表されていました。ここで、確率変数 $X$ が $x$ という値をとる確率 $p(X = x)$ を、表の代わりに、あるパラメータ $\\theta$ で特徴づけられた関数 $f(x; \\theta)$ によって表してみます。この関数は、「**確率変数** $X$ **が取りうる様々な値** $x$ **に確率を対応させる**」ので、 $X$ の確率分布を表しています。このような関数は**確率モデル（probabilistic model）**とも呼ばれ、特にパラメータによって形状が決定される関数を用いる場合は**パラメトリックモデル（parametric model）**と呼ばれます。\n",
                "\n",
                "このような確率モデルのパラメータをうまく決定することで、データの分布を表現できれば、未知のデータに対してもそれがどのくらいの確率で発生するのかといった予測が可能となったり、便利です。推定方法には様々なものがあり、どうやって推定するかは推定する人の自由ですが、本節では最も一般的な方法の一つである最尤推定を説明します。最尤推定は確率論から正当化できるという長所があります。\n",
                "\n",
                "さて、確率モデルがどのくらい実際の観測データに即しているかを**尤度（ゆうど）（likelihood）**と言い、観測されたデータをモデルに入力し、その出力をかけ合わせたもので定義されます。\n",
                "\n",
                "例えば、 $N$ 個のデータ $x_i \\ (i=1,\\dots,N)$ が独立に観測されたとき、この観測データの下での確率モデル $f(x; \\theta)$ の**尤度**は\n",
                "\n",
                "$$\n",
                "L(\\theta) = \\prod_{i=1}^N f(x_i; \\theta)\n",
                "$$\n",
                "\n",
                "と計算されます。与えられたデータから、「どのようなデータがどのくらいよく観測されるか」を表す確率分布を推定[<sup>*10</sup>](#fn10)するために、予め用意した確率モデルのパラメータを、それらの観測データの下での**尤度が最大**になるように決定する方法を、**最尤（さいゆう）推定（maximum likelihood estimation）**と言います。\n",
                "\n",
                "上式の $\\prod$ という記号は、 $\\sum$ の掛け算版で、全ての値を掛け合わせるという意味です。複数データに対する尤度は、 $1$ より小さな値の積となるため、結果は非常に小さな数になり、コンピュータでこの計算を行う際にはアンダーフローという問題が発生しやすくなります。また尤度を最大化したい場合、積の形の式の最大化は難しいことが知られています。そこで尤度の対数をとった**対数尤度（log likelihood）**を考えます。 $y = \\log(x)$ は単調増加であるため、対数をとる前後で大小関係は変わりません。そのため対数尤度を最大にするときの $\\theta$ は、元の尤度も最大にします。\n",
                "\n",
                "$$\n",
                "\\log L(\\theta) = \\sum_{i=1}^N \\log f(x_i; \\theta)\n",
                "$$\n",
                "\n",
                "よって、この対数尤度を最大化するパラメータ $\\theta$ を求めることができれば、その値が観測データ $x_i (i=1,\\dots,N)$ の分布を最もよく表現する確率モデルのパラメータとなります。\n",
                "\n",
                "ここで、具体例として、コインの表・裏が出る確率を推定する問題を考えてみます。コインを投げて「表が出る」事象を $1$ に、「裏が出る」事象を $0$ に対応付ける確率変数を $X$ とします。このとき、 $p(X)$ をシンプルな確率モデル\n",
                "\n",
                "$$\n",
                "f(x; \\theta) = \\theta^x (1 - \\theta)^{1 - x}\n",
                "$$\n",
                "\n",
                "で表現することにします[<sup>*11</sup>](#fn11)。これは $x = 1$ のとき、すなわちコインが表であるとき $\\theta$ をそのまま返し、 $x = 0$ のとき、すなわちコインが裏であるとき $1 - \\theta$ を返すような関数となっています。ただし、 $0 \\leq \\theta \\leq 1$ を満たすこととします。今、コインを $10$ 回投げ、以下の観測結果が得られたとします。\n",
                "\n",
                "| $\\ $ | 1回目 | 2回目 | 3回目 | 4回目 | 5回目 | 6回目 | 7回目 | 8回目 | 9回目 | 10回目 |\n",
                "|:----:|:----:|:----:|:----:|:----:|:----:|:----:|:----:|:----:|:----:|:----:|\n",
                "| X | 1 | 0 | 1 | 1 | 1 | 0 | 0 | 1 | 0 | 0 |\n",
                "\n",
                "これらの観測データの下での確率モデルの尤度は\n",
                "\n",
                "$$\n",
                "\\begin{aligned}\n",
                "L(\\theta) &=\n",
                "\\theta \\cdot\n",
                "(1 - \\theta) \\cdot\n",
                "\\theta \\cdot\n",
                "\\theta \\cdot\n",
                "\\theta \\cdot\n",
                "(1 - \\theta) \\cdot\n",
                "(1 - \\theta) \\cdot\n",
                "\\theta \\cdot\n",
                "(1 - \\theta) \\cdot\n",
                "(1 - \\theta) \\\\\n",
                "&= \\theta^{5} \\cdot (1 - \\theta)^{5}\n",
                "\\end{aligned}\n",
                "$$\n",
                "\n",
                "です。対数尤度は、\n",
                "\n",
                "$$\n",
                "\\log L(\\theta) = 5 \\log \\theta + 5 \\log \\left( 1 - \\theta \\right)\n",
                "$$\n",
                "\n",
                "となります。これが最大となるときの $\\theta$ は、この式を $\\theta$ で微分した式を $0$ とおいて解析的に解けばよく、\n",
                "\n",
                "$$\n",
                "\\begin{align}\n",
                "\\frac{5}{\\theta} - \\frac{5}{\\left( 1 - \\theta \\right)} &= 0 \\\\\n",
                "\\therefore \\theta = \\frac{1}{2}\n",
                "\\end{align}\n",
                "$$\n",
                "\n",
                "と決定します。これが最尤推定です。"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "colab_type": "text",
                "id": "OubCzWBb7q8U"
            },
            "source": [
                "## 事後確率最大化推定（MAP推定）\n",
                "\n",
                "前節で解説した最尤推定は、多くの場合で有用ですが、求めるパラメータに何らかの**事前知識**がある場合、それを活かすことができません。そのため、少ないサンプル数からパラメータを推定するとき、実際にはほとんどあり得ない結果が求まる場合があります。具体例を見てみましょう。\n",
                "\n",
                "再び、コインの表・裏が出る確率を推定する例を考えます。コインを $5$ 回投げたところ、**たまたま** ${\\bf 5}$ **回とも表が出た**とします。この場合、前節と同じ確率モデルを用いて尤度を計算し、最尤推定でモデルのパラメータを決定すると、 $0 \\leq \\theta \\leq 1$ を満たしながら、今回の観測データの下での尤度 $\\theta^5$ を最大にする $\\theta$ は $1$ となります。これは「表が出る確率が $1$ 」すなわち**「裏面が出る確率は** $0$**」**という推定結果が得られてしまったことを意味します。このような場合「裏が出る確率も $0$ よりは大きいだろう」という事前知識を活用することができれば、より良い推定ができそうです。\n",
                "\n",
                "事前知識も考慮しながら、観測データに基づいて確率モデルのパラメータを推定する方法には、**最大事後確率（maximum a posteriori, MAP）推定**があります。MAP推定でも、対象のデータの確率分布を表す確率モデルのパラメータをデータを利用して決定しますが、データだけでなく**パラメータも確率変数だと考える**点が最尤推定とは異なっています。パラメータを確率変数 $\\Theta$ とすると、このパラメータがどのような値を取るかを表す分布 $p(\\Theta)$ が導入できます。これを**事前分布（prior distribution）**と呼び、ここに「求めたいパラメータに対する事前知識」を反映させることができます。ここで、 $\\Theta = \\theta$ となる確率 $p(\\Theta = \\theta)$（以降は $p(\\theta)$ と略記）をデータの確率モデル $f(x; \\theta)$ とは別の確率モデル $g(\\theta; \\beta)$ で表せば、 $\\beta$ を人為的に与えるか、なんらかの方法で決定しておくことで、「どのような $\\theta$ が起こりやすいか」という事前知識を表現することができます。\n",
                "\n",
                "MAP推定では、観測データ $x_i \\ (i=1,\\dots,N)$ が観測されたという**条件の下で**最も確率が大きくなる $\\theta$ を求めます。すなわち、 $p(\\theta | x_1, \\dots, x_N)$ を最大とする $\\theta$ を求めます。これは「 $x_i \\ (i=1,\\dots,N)$ が観測された」という**結果**のもとで「データの確率分布を表すモデルのパラメータが $\\theta$ であったことが**原因**である」確率を意味するので、**事後確率**です。ベイズの定理から、事後確率は\n",
                "\n",
                "$$\n",
                "p(\\theta | x_1,\\dots,x_N) = \\frac{p(x_1,\\dots,x_N | \\theta) p(\\theta)}{p(x_1,\\dots,x_N)}\n",
                "$$\n",
                "\n",
                "と書けました。右辺に着目してください。分子にある $p(x_1,\\dots,x_N | \\theta)$ を、確率モデル $f(x; \\theta)$ を用いて $\\prod_{i=1}^N f(x_i; \\theta)$ と表すと、これは観測データ $x_i \\ (i=1,\\dots,N)$ の下での確率モデル $f(x; \\theta)$ の**尤度**です。また、その右の $p(\\theta)$ は、パラメータが $\\theta$ という値になる**事前確率**でした。これが $g(\\theta; \\beta)$ という確率モデルで表されるとします。\n",
                "\n",
                "今、事後確率を最大にするパラメータ $\\theta$ を求めるために、右辺を最大化する $\\theta$ を考えます。このとき、パラメータと無関係に決まる $p(x_1,\\dots,x_N)$ を無視し\n",
                "\n",
                "$$\n",
                "p(x_1,\\dots,x_N | \\theta) p(\\theta)\n",
                "$$\n",
                "\n",
                "だけに注目してこれを最大化するようにパラメータ $\\theta$ を決定すると、その $\\theta$ は求めたい左辺の事後確率を最大にする $\\theta$ に一致します。上式は、尤度と事前分布の積になっています。このことから、**事後分布は尤度と事前分布の積に比例する**ということが分かります。\n",
                "\n",
                "MAP推定では、この尤度 $\\times$ 事前確率を最大化するような $\\theta$ を求めることで、「データを観測した」という事後においてもっとも可能性の高い $\\theta$ を決定します。本節では具体的に事後確率最大化の計算は行いませんが、最尤推定とは異なり、 $p(\\theta)$ が考慮された上でパラメータの決定が行われることに注意してください。"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "colab_type": "text",
                "id": "b7V7PCEx7q8V"
            },
            "source": [
                "## 統計量\n",
                "\n",
                "本節では、いくつかよく用いられる統計量を説明します。統計量とは、**観測されたデータの特徴を要約する数値**のことを指します。代表的な統計量として平均、分散、標準偏差を紹介します。\n",
                "\n",
                "### 平均\n",
                "\n",
                "**平均 (mean)** は、観測された数値を合計し、その数値の個数で割ったもののことを言います。たとえば、300 円、400 円、500 円の平均は、\n",
                "\n",
                "$$\n",
                "\\frac{300 + 400 + 500}{3} = 400\n",
                "$$\n",
                "\n",
                "です。一般に、 $N$ 個のデータ $x_i \\ (i=1,\\dots,N)$ が観測されたとき、その平均は\n",
                "\n",
                "$$\n",
                "\\begin{aligned}\n",
                "\\overline{x}\n",
                "= \\frac{x_1 + x_2 + \\dots + x_N}{N}\n",
                "= \\frac{1}{N} \\sum^{N}_{n=1} x_{n}\n",
                "\\end{aligned}\n",
                "$$\n",
                "\n",
                "と定義されます。\n",
                "平均を表す記号として、 $\\bar{x}$ や $\\mu$ がよく用いられます。\n",
                "データの分布において、平均はその重心に相当する値です。\n",
                "\n",
                "### 分散\n",
                "\n",
                "次に、**分散 (variance)** を紹介します。分散はよく $\\sigma^2$ と表され、\n",
                "\n",
                "$$\n",
                "\\sigma^2 = \\frac{1}{N} \\sum_{n=1}^N \\left( x_n - \\overline{x} \\right)^2\n",
                "$$\n",
                "\n",
                "と定義されます。各データ点 $x_i \\ (i=1,\\dots,N)$ の値から、それらの平均 $\\bar{x}$ を引き二乗した値（ $(x_i - \\bar{x})^2 \\ (i=1,\\dots,N)$ ）の平均を計算しています。これは、「データが自らの平均より平均的にどのくらいばらついているか」を表します。平均が同じデータでも、全てのデータが平均付近にある場合は分散は小さく、平均よりも極めて大きなデータ点や小さなデータ点が多数ある場合、分散は大きくなります。分散にはもう一種類あります。以下のようなものです。\n",
                "\n",
                "$$\n",
                "\\begin{aligned}\n",
                "s^2 = \\frac{1}{N - 1} \\sum_{n=1}^N \\left( x_n - \\overline{x} \\right)^2\n",
                "\\end{aligned}\n",
                "$$\n",
                "\n",
                "始めに登場した $\\sigma^2$ の定義では $\\frac{1}{N}$ となっていた部分が $\\frac{1}{N - 1}$ に変わっています。\n",
                "前者は**標本分散 (sample variance)** といい、後者は**不偏分散 (unbiased variance)** といいます。\n",
                "これらの式の導出は他の文献に譲るとして、ここではその使い分けについて説明します。\n",
                "\n",
                "![母集団と標本集団](images/03/03_10.png)\n",
                "\n",
                "例えば、全国の小学生の身長と体重の分散を調べたいとします。このとき、全国の小学生を一人の抜け漏れもなく調べたなら、集まったデータは**母集団 (population)** と呼ばれます。\n",
                "一方、各都道府県の小学生を100人ずつ調べた場合、そのデータは**標本集団 (sample population)** と言います。\n",
                "すなわち、母集団とは解析を行いたいデータ全ての集合を指し、標本集団とは母集団から抽出された一部のデータの集合を指します。一般に、標本集団のデータ数が少ないとき、標本分散は母集団の分散よりも小さくなることが知られています。**不偏分散**は、抽出するデータの数を増やしていったとき、いずれ母集団の分散に一致します。\n",
                "\n",
                "分散を利用すると、データのばらつきを定量評価することができるようになります。例えば、同じ現象を複数回観測する実験を行った際、結果のばらつきが大きければ、その観測方法には問題がある可能性があります。もしくは、同じだと思っていた現象は、実は観測のたびに異なる現象であった可能性があります。このように、多数の試行の結果がある値に集まっていることが望ましいような状況において、ばらつきの度合いを定量し評価することは重要です。\n",
                "\n",
                "### 標準偏差\n",
                "\n",
                "次に**標準偏差 (standard deviation)** を紹介します。\n",
                "分散はデータの平均からの差の**二乗**の平均でした。そのため単位は元の単位を二乗したものになります。例えばデータの単位が ${\\rm kg}$ であれば、分散の単位は ${\\rm kg}^2$ になります。そこで、分散 $\\sigma^2$ の平方根 $\\sigma$ を計算することで、データと単位が等しくなり、解釈が容易になります。この $\\sigma$ を標準偏差と呼びます。\n",
                "\n",
                "練習問題で具体的な計算手順の確認を行いましょう。以下の①と②のデータに対して、平均、分散、標準偏差を求めてください。ただし、今回は標本分散を使用することとします。\n",
                "\n",
                "![練習問題](images/03/03_11.png)\n",
                "\n",
                "①の解答は以下の通りです。\n",
                "\n",
                "$$\n",
                "\\begin{aligned}\n",
                "\\bar{x} &= \\frac{1}{5} \\left( -2 -1 + 0 + 1 + 2 \\right) = 0 \\\\\n",
                "\\sigma^{2} &= \\frac{1}{5} \\left\\{ \\left( -2 -0 \\right)^{2} + \\left( -1 -0 \\right)^{2} + (0 - 0)^{2} + (1 - 0)^{2} + (2 - 0)^{2} \\right \\} \\\\\n",
                "&= \\frac{1}{5} \\times 10 = 2 \\\\\n",
                "\\sigma &= \\sqrt{2}\n",
                "\\end{aligned}\n",
                "$$\n",
                "\n",
                "②の解答は以下の通りです。\n",
                "\n",
                "$$\n",
                "\\begin{aligned}\n",
                "\\overline{x} &= \\frac{1}{5} ( -4 -2 + 0 + 2 + 4 ) = 0 \\\\\n",
                "\\sigma^2 &= \\frac{1}{5}\n",
                "\\left\\{ (-4 -0)^2 + (-2 -0)^2 + (0 - 0)^2 + (2 - 0)^2 + (4 - 0)^2 \\right\\} \\\\\n",
                "&= \\frac{1}{5} \\times 40 = 8 \\\\\n",
                "\\sigma &= \\sqrt{8} = 2 \\sqrt{2}\n",
                "\\end{aligned}\n",
                "$$\n",
                "\n",
                "これより、②のケースの方が分散が大きく、データのばらつきが大きいことがわかります。"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "colab_type": "text",
                "id": "2-NPhY9V708Q"
            },
            "source": [
                "### 相関係数\n",
                "\n",
                "最後に**相関係数 (correlation coefficient)** を紹介します。\n",
                "\n",
                "2 つのデータの間の関係を調べる際、相関関係を調べるということをします。\n",
                "この 2 つのデータでどれくらいの相関があるかを見る際に相関係数が用いられます。\n",
                "\n",
                "2 つのデータ点をそれぞれ $x_n, y_n  \\ (n=1,\\dots,N)$ とした場合、相関係数の中でも良く用いられるピアソンの相関係数は以下のように定義されます。\n",
                "\n",
                "$$\n",
                "r = \\frac{\\sum_{n=1}^{N} (x_{n}-\\bar{x})(y_{n}-\\bar{y}) }{\\sqrt{\\left( \\displaystyle \\sum_{n=1}^N(x_{n}-\\bar{x})^2 \\right) \\left( \\displaystyle \\sum_{n=1}^N(y_{n}-\\bar{y})^2 \\right) }}\n",
                "$$\n",
                "\n",
                "相関係数を表す記号としては $r$ が良く用いられます。\n",
                "相関係数 $r$ は常に $ -1 \\leq r \\leq 1 $ になり、相関が認められるとき、 $r$の値が正の場合は**正の相関**があるといい、逆に負の値のときは**負の相関**があるといいます。\n",
                "\n",
                "相関係数は正負どちらの相関が認められるかや相関の強さを比較するのには便利ですが、相関係数の値だけで相関があるかどうかを判定するのは不適切です。\n",
                "実際に相関関係があるかどうかを判定する際は、無相関検定を行う必要があります。"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<hr />\n",
                "\n",
                "<span id=\"fn3\"><sup>\\*3</sup> : <small> 間違えた度合いを測る関数を、特に**損失関数 (loss function)** と呼ぶ場合があります。 </small></span>\n",
                "\n",
                "<span id=\"fn4\"><sup>*4</sup>: <small>入力変数が他の入力変数と独立でない場合は定数と考えることはできません。しかし本資料ではそのようなケースは出てきません。</small></span>\n",
                "\n",
                "<span id=\"fn5\"><sup>*5</sup> : <small> $N \\times M$ 行列、などと言われたときに、$N$ と $M$ のどちらが行で、どちらが列だろう？と迷ったときは、「行列」という言葉を再度思い浮かべて、「行→列」つまり先にくる $N$ が行数で、$M$ が列数だ、と思い出すのがおすすめです。</small></span>\n",
                "\n",
                "<span id=\"fn6\"><sup>*6</sup>: <small>ここでは概念の説明を簡単にするため、この例のように離散的な値を取る確率変数を考え、特に明示しない限り連続値の確率変数は考えないことにします。</small></span>\n",
                "\n",
                "<span id=\"fn7\"><sup>*7</sup>: <small> $x$ は $1, 2, 3, 4, 5, 6$ のいずれか。すなわち $x \\in \\{1, 2, 3, 4, 5, 6\\}$</small></span>\n",
                "\n",
                "<span id=\"fn8\"><sup>*8</sup>: <small> $y$ は 2 つ目のコインが取りうる状態で、この場合、「表」と「裏」という値のいずれか。</small></span>\n",
                "\n",
                "<span id=\"fn9\"><sup>*9</sup>: <small> $x$ は 1 つ目のコインが取りうる状態で、この場合、「表」と「裏」という値のいずれか。</small></span>\n",
                "\n",
                "<span id=\"fn10\"><sup>\\*10</sup>: <small>以降、このことを「データの分布を推定する」と言うことがあります。また、観測されたデータのみから各データの発生確率（頻度とも捉えられる）を求めたものは**経験分布（empirical distribution）**とも呼ばれ、本節で説明しているのは正確にはこの経験分布を確率モデルで近似する方法です。</small></span>\n",
                "\n",
                "<span id=\"fn11\"><sup>\\*11</sup>: <small>この関数には、ベルヌーイ分布いう名前がついています。</small></span>"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.6.8"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}