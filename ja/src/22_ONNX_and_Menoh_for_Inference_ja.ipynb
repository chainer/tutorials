{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n3uYk8aaZh8k"
   },
   "source": [
    "# 様々な環境での推論: ONNX と Menoh の活用\n",
    "\n",
    "これまでの章では、Chainer を用いた学習済みモデルの作成方法・推論の実行方法を解説しました。\n",
    "\n",
    "しかし、実務においては Chainer で作成した学習済みモデルをそのまま推論に用いることが難しい場面もあります。\n",
    "例えば、Ruby や Java など Python 以外の言語で実装された既存の Web アプリケーションに推論機能を組み込みたい場合や、モバイルデバイス上で推論を行いたい場合、Chainer（Python）で実装された学習済みモデルを直接実行するのは困難です。\n",
    "\n",
    "そこで本章では、Chainer の学習済みモデルを ONNX（オニキス）と呼ばれる形式に変換することで、異なるフレームワークを使用して推論を実行する方法について解説します。\n",
    "また、Menoh（メノウ）というフレームワークを使用して、ONNX 形式の学習済みモデルを様々なプログラミング言語で推論する方法もご紹介します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zTnwNprg0ZLP"
   },
   "source": [
    "## ONNX とは？\n",
    "\n",
    "ONNX は **Open Neural Network eXchange** の略で、ディープラーニングの学習済みモデルを様々なフレームワーク間で相互に交換するためのファイルフォーマット（形式）です。\n",
    "\n",
    "学習済みモデルを ONNX 形式に変換することで、あるフレームワークで訓練したモデルを別のフレームワークでの推論に使用できるようになります。また、代表的な手法の学習済みモデルは [ONNX Model Zoo](https://github.com/onnx/models) で公開されており、ダウンロードしてそのまま使用することも可能です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B06Z0MwRZh4C"
   },
   "source": [
    "### ONNX のサポート状況\n",
    "\n",
    "数多くのディープラーニングフレームワークが ONNX をサポートしています。\n",
    "最新の対応状況は [ONNX の GitHub ページ](https://github.com/onnx/tutorials) から確認することができます。\n",
    "2019年2月現在のサポート状況は下記の通りです。\n",
    "\n",
    "<!--\n",
    "表の作成手順:\n",
    "\n",
    "1. https://raw.githubusercontent.com/onnx/tutorials/989599017f3eb9846a4dd593b85427babf233eef/README.md からテーブルをコピー\n",
    "2. 本章で使用する Chainer, Menoh, Caffe2 を先頭に移動\n",
    "3. ヘッダ行を日本語化\n",
    "   (Framework / tool | Installation | Exporting to ONNX (frontend) | Importing ONNX models (backend))\n",
    "-->\n",
    "\n",
    "| フレームワーク/ツール | インストール方法 | エクスポート | インポート |\n",
    "| --- | --- | --- | --- |\n",
    "| [Chainer](https://chainer.org/) | [chainer/onnx-chainer](https://github.com/chainer/onnx-chainer) | [Exporting](tutorials/ChainerOnnxExport.ipynb) | coming soon |\n",
    "| [Menoh](https://github.com/pfnet-research/menoh) | [pfnet-research/menoh](https://github.com/pfnet-research/menoh) | n/a | [Importing](tutorials/OnnxMenohHaskellImport.ipynb) |\n",
    "| [Caffe2](http://caffe2.ai) | [part of caffe2 package](https://github.com/pytorch/pytorch/tree/master/caffe2/python/onnx) | [Exporting](tutorials/Caffe2OnnxExport.ipynb) | [Importing](tutorials/OnnxCaffe2Import.ipynb) |\n",
    "| [PyTorch](http://pytorch.org/) | [part of pytorch package](http://pytorch.org/docs/master/onnx.html) | [Exporting](tutorials/PytorchOnnxExport.ipynb), [Extending support](tutorials/PytorchAddExportSupport.md) | coming soon |\n",
    "| [Cognitive Toolkit (CNTK)](https://www.microsoft.com/en-us/cognitive-toolkit/) | [built-in](https://docs.microsoft.com/en-us/cognitive-toolkit/setup-cntk-on-your-machine) | [Exporting](tutorials/CntkOnnxExport.ipynb) | [Importing](tutorials/OnnxCntkImport.ipynb) |\n",
    "| [Apache MXNet](http://mxnet.incubator.apache.org/) | part of mxnet package [docs](http://mxnet.incubator.apache.org/api/python/contrib/onnx.html) [github](https://github.com/apache/incubator-mxnet/tree/master/python/mxnet/contrib/onnx) | [Exporting](tutorials/MXNetONNXExport.ipynb) | [Importing](tutorials/OnnxMxnetImport.ipynb) |\n",
    "| [TensorFlow](https://www.tensorflow.org/) | [onnx/onnx-tensorflow](https://github.com/onnx/onnx-tensorflow) and [onnx/tensorflow-onnx](https://github.com/onnx/tensorflow-onnx) | [Exporting](tutorials/OnnxTensorflowExport.ipynb) | [Importing](tutorials/OnnxTensorflowImport.ipynb) [experimental] |\n",
    "| [Apple CoreML](https://developer.apple.com/documentation/coreml) | [onnx/onnx-coreml](https://github.com/onnx/onnx-coreml) and [onnx/onnxmltools](https://github.com/onnx/onnxmltools) | [Exporting](https://github.com/onnx/onnxmltools) | [Importing](tutorials/OnnxCoremlImport.ipynb) |\n",
    "| [SciKit-Learn](http://scikit-learn.org/) | [onnx/onnxmltools](https://github.com/onnx/onnxmltools) | [Exporting](https://github.com/onnx/onnxmltools) | n/a |\n",
    "| [ML.NET](https://github.com/dotnet/machinelearning/) | [built-in](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.models.onnxconverter.convert?view=ml-dotnet#definition) | [Exporting](https://github.com/dotnet/machinelearning/blob/master/test/Microsoft.ML.Tests/OnnxTests.cs) | [Importing](https://github.com/dotnet/machinelearning/blob/master/test/Microsoft.ML.OnnxTransformTest/OnnxTransformTests.cs#L186) |\n",
    "| [MATLAB](https://www.mathworks.com/) | [onnx converter on matlab central file exchange](https://www.mathworks.com/matlabcentral/fileexchange/67296) | [Exporting](https://www.mathworks.com/help/deeplearning/ref/exportonnxnetwork.html) | [Importing](https://www.mathworks.com/help/deeplearning/ref/importonnxnetwork.html) |\n",
    "| [TensorRT](https://developer.nvidia.com/tensorrt) | [onnx/onnx-tensorrt](https://github.com/onnx/onnx-tensorrt) | n/a | [Importing](https://github.com/onnx/onnx-tensorrt/blob/master/README.md) |\n",
    "\n",
    "エクスポートとは、そのフレームワークで作成した学習済みモデルを ONNX 形式に変換できることを表します。\n",
    "また、インポートとは、そのフレームワークが ONNX 形式の学習済みモデルを読み込んで推論を実行できることを表します。\n",
    "\n",
    "Chainer は、現時点ではエクスポートのみに対応しています。\n",
    "インポートについても今後サポートが予定されています。\n",
    "\n",
    "なお、学習済みモデルで使用している関数が ONNX 形式でサポートされていない場合は、エクスポートすることができません。\n",
    "サポートされている関数の一覧は [ONNX の公式ドキュメント](https://github.com/onnx/onnx/blob/master/docs/Operators.md)で確認することができます。\n",
    "また、ONNX 形式でサポートされている関数であっても、フレームワークによってはエクスポート/インポートに制約がある場合があります。\n",
    "詳しくは各フレームワークの ONNX に関するドキュメント（例: [Chainer](https://github.com/chainer/onnx-chainer#supported-functions)、[PyTorch](https://pytorch.org/docs/stable/onnx.html#supported-operators)）を確認してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kTE1H_ED0IBE"
   },
   "source": [
    "## Chainer の学習済みモデルを ONNX 形式に変換する\n",
    "\n",
    "Chainer の学習済みモデルを ONNX 形式に変換する方法を解説します。\n",
    "\n",
    "今回は Chainer にデフォルトで用意されている、VGG16 の学習済みモデルを使用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eaJC6WzxeGeN"
   },
   "outputs": [],
   "source": [
    "import chainer\n",
    "import chainer.functions as F\n",
    "import chainer.links as L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 47282,
     "status": "ok",
     "timestamp": 1548311998706,
     "user": {
      "displayName": "西沢衛",
      "photoUrl": "",
      "userId": "12011220225445512117"
     },
     "user_tz": -540
    },
    "id": "yC9WUiiSeltC",
    "outputId": "af0c02b6-b1cc-40e8-c5ce-16306c998f11"
   },
   "outputs": [],
   "source": [
    "# VGG16 モデルの読み込み\n",
    "model = L.VGG16Layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 47256,
     "status": "ok",
     "timestamp": 1548311998706,
     "user": {
      "displayName": "西沢衛",
      "photoUrl": "",
      "userId": "12011220225445512117"
     },
     "user_tz": -540
    },
    "id": "wMd8QwycepcN",
    "outputId": "64eb1600-ffff-4a5f-b561-38334e35e335"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['conv1_1',\n",
       " 'conv1_2',\n",
       " 'pool1',\n",
       " 'conv2_1',\n",
       " 'conv2_2',\n",
       " 'pool2',\n",
       " 'conv3_1',\n",
       " 'conv3_2',\n",
       " 'conv3_3',\n",
       " 'pool3',\n",
       " 'conv4_1',\n",
       " 'conv4_2',\n",
       " 'conv4_3',\n",
       " 'pool4',\n",
       " 'conv5_1',\n",
       " 'conv5_2',\n",
       " 'conv5_3',\n",
       " 'pool5',\n",
       " 'fc6',\n",
       " 'fc7',\n",
       " 'fc8',\n",
       " 'prob']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# VGG16 のアーキテクチャーの確認\n",
    "model.available_layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LNRb5jV5WvP8"
   },
   "source": [
    "ONNX 形式への変換には `onnx-chainer` パッケージを使用します。  \n",
    "`onnx-chainer` は `pip` を使用してインストールすることができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 445
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 55618,
     "status": "ok",
     "timestamp": 1548312007078,
     "user": {
      "displayName": "西沢衛",
      "photoUrl": "",
      "userId": "12011220225445512117"
     },
     "user_tz": -540
    },
    "id": "sjeTaX3RXjyf",
    "outputId": "deb1ae02-fddc-4070-dbf2-aca042d71907"
   },
   "outputs": [],
   "source": [
    "!pip install onnx-chainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0ls46NvyWvVM"
   },
   "outputs": [],
   "source": [
    "import onnx_chainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qliA5FHxlM0h"
   },
   "source": [
    "Chainer は **Define-by-Run** というスタイルを採用しているため、ネットワーク構造は実際にデータを渡してフォワード（順伝播）計算を行うことで確定します。\n",
    "（Define-by-Run は Chainer のコアコンセプトの１つであり、ネットワーク構造をフォワード計算をしながら定義することを指します。\n",
    "このコンセプトによって、複雑なモデルをより少ないコード量で構築できる、デバックが容易になる、といったメリットがあります。）\n",
    "\n",
    "ONNX 形式へ変換するためにはネットワーク構造が確定している必要があるため、ダミーの入力データを用意してフォワード計算を行います。\n",
    "ダミーデータには、実際の推論に用いるデータと同じ `shape` の入力変数を使用します。\n",
    "VGG16 モデルは 224×224 の3チャンネルの画像を入力データとして想定しているため、以下のようにダミーデータを作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 55823,
     "status": "ok",
     "timestamp": 1548312007297,
     "user": {
      "displayName": "西沢衛",
      "photoUrl": "",
      "userId": "12011220225445512117"
     },
     "user_tz": -540
    },
    "id": "vmym_1HqiuPK",
    "outputId": "9fa27d15-8adb-4973-e074-999452ede276"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3, 224, 224)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ダミーデータの準備\n",
    "import numpy as np\n",
    "x = np.zeros((1, 3, 224, 224), dtype=np.float32)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chainer を推論モードに切り替え、学習済みモデル `model` に対してダミーデータ `x` を渡してネットワーク構造を確定させた後、ONNX 形式のファイルとして出力します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VJXz95jfWvaJ"
   },
   "outputs": [],
   "source": [
    "# 推論モードに切り替え\n",
    "chainer.config.train = False\n",
    "\n",
    "# ONNX 形式に変換する\n",
    "onnx_model = onnx_chainer.export(model, x, filename='convnet.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 66022,
     "status": "ok",
     "timestamp": 1548312017506,
     "user": {
      "displayName": "西沢衛",
      "photoUrl": "",
      "userId": "12011220225445512117"
     },
     "user_tz": -540
    },
    "id": "emlaV9PtWvkH",
    "outputId": "ccb32699-025d-4dcf-c21b-48d6dbe69fd2",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convnet.onnx\r\n"
     ]
    }
   ],
   "source": [
    "# 出力されたファイルの確認\n",
    "!ls convnet.onnx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oG7DLMBXQFJ7"
   },
   "source": [
    "これで、学習済みモデルを ONNX 形式のファイルに変換することができました。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oG7DLMBXQFJ8"
   },
   "source": [
    "## ONNX 形式のモデルを Caffe2 で推論する\n",
    "\n",
    "続けて、先ほど変換した ONNX 形式の学習済みモデルファイルを [Caffe2](https://caffe2.ai/) フレームワークで読み込み、推論を行います。\n",
    "\n",
    "まず、Caffe2 とその依存モジュールをインストールします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 377
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 165297,
     "status": "ok",
     "timestamp": 1548312116791,
     "user": {
      "displayName": "西沢衛",
      "photoUrl": "",
      "userId": "12011220225445512117"
     },
     "user_tz": -540
    },
    "id": "fAyfxVuyqGXq",
    "outputId": "5794c166-6e3f-4dd9-ba8a-63cd1fa3d494"
   },
   "outputs": [],
   "source": [
    "# Caffe2 (PyTorch の一部) のインストール\n",
    "!pip install torch\n",
    "\n",
    "# Caffe2 の依存モジュールのインストール\n",
    "!pip install onnx future"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Glbk0VW6wwDP"
   },
   "source": [
    "### Caffe2 に ONNX モデルを読み込む\n",
    "\n",
    "Caffe2 に ONNX モデルを読み込みます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kkSrkmm54zpy"
   },
   "outputs": [],
   "source": [
    "# 保存された ONNX モデルの読み込み\n",
    "import onnx\n",
    "onnx_model = onnx.load('convnet.onnx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1rq_9V_RwomQ"
   },
   "source": [
    "### 読み込んだ ONNX モデルを使用して推論する\n",
    "\n",
    "ここでは乱数データを入力にして推論を行います（実際には、入力として 224×224 の3チャンネル画像を使用します）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-OC5BCce40C9"
   },
   "outputs": [],
   "source": [
    "# 推論の準備を行う\n",
    "from caffe2.python.onnx import backend\n",
    "prepared_backend = backend.prepare(onnx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7ghONkv-lKbq"
   },
   "outputs": [],
   "source": [
    "# ダミーの入力データを用意\n",
    "x = np.random.randn(1, 3, 224, 224).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 165898,
     "status": "ok",
     "timestamp": 1548312117394,
     "user": {
      "displayName": "西沢衛",
      "photoUrl": "",
      "userId": "12011220225445512117"
     },
     "user_tz": -540
    },
    "id": "q80GZx31H92W",
    "outputId": "c5feffd1-1813-4c19-dfb5-79be8c484ea8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3, 224, 224)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hI3lfFzp5LM-"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Outputs(Softmax_0=array([[2.14816275e-04, 1.08164025e-03, 4.11246932e-04, 8.18778411e-04,\n",
       "        1.71566370e-03, 1.44439552e-03, 5.13035618e-03, 1.90243445e-04,\n",
       "        1.06249157e-04, 1.54615147e-04, 4.11179295e-04, 2.20485352e-04,\n",
       "        4.23722464e-04, 9.20125283e-04, 2.28955381e-04, 1.86870879e-04,\n",
       "        3.95452895e-04, 1.71444262e-04, 4.76445537e-04, 4.93705564e-04,\n",
       "        5.74271311e-04, 8.71971250e-04, 5.73325728e-04, 3.74813128e-04,\n",
       "        1.26666389e-04, 8.78053252e-05, 6.43608335e-04, 3.97719909e-04,\n",
       "        6.98198928e-05, 1.76480913e-03, 1.18460186e-04, 2.65453738e-04,\n",
       "        1.50202672e-04, 1.38622615e-03, 2.58962763e-03, 3.39274702e-04,\n",
       "        7.36668706e-04, 1.87365469e-04, 1.46729185e-03, 3.18095059e-04,\n",
       "        7.21398508e-04, 3.76959128e-04, 4.75917652e-04, 3.02988483e-04,\n",
       "        3.80057172e-04, 1.58852024e-03, 5.70400036e-04, 6.88131899e-04,\n",
       "        8.37533094e-04, 7.47749116e-04, 1.19529001e-03, 2.85340007e-04,\n",
       "        8.71164957e-04, 1.51232968e-03, 6.65602158e-04, 2.81423825e-04,\n",
       "        5.79039857e-04, 1.45970611e-04, 5.86787611e-03, 3.61611135e-04,\n",
       "        1.43792958e-03, 7.10567576e-04, 7.78600923e-04, 5.47229603e-04,\n",
       "        1.32967916e-03, 1.23114802e-03, 1.86032755e-03, 1.28275470e-03,\n",
       "        1.32651080e-03, 2.59720813e-03, 1.04598084e-03, 2.07768334e-03,\n",
       "        6.17296202e-04, 1.79666700e-03, 8.01361341e-04, 3.26533173e-03,\n",
       "        2.00592494e-03, 2.24487716e-03, 3.59052420e-03, 3.06862826e-03,\n",
       "        8.35053565e-04, 1.00972608e-03, 6.24692126e-04, 8.96983664e-04,\n",
       "        1.75330279e-04, 1.57310208e-03, 1.03183673e-03, 1.94269035e-03,\n",
       "        1.64769677e-04, 6.24805631e-04, 4.80240014e-05, 1.92994034e-04,\n",
       "        5.36365318e-04, 3.17703059e-04, 6.04177709e-04, 5.28337114e-05,\n",
       "        3.87105421e-04, 1.38645162e-04, 9.83703183e-04, 5.11445745e-04,\n",
       "        2.59576453e-04, 4.83172102e-04, 2.78937398e-04, 1.01427373e-03,\n",
       "        4.92590945e-04, 1.37420153e-04, 4.90972889e-04, 3.63669562e-04,\n",
       "        3.63063475e-04, 2.36490116e-04, 4.84008924e-05, 1.27091829e-03,\n",
       "        7.81077077e-04, 3.55530210e-04, 3.52347881e-04, 1.76401736e-05,\n",
       "        8.70111326e-05, 1.05786661e-03, 3.76932498e-04, 2.10816594e-04,\n",
       "        1.05515518e-03, 5.06510951e-05, 1.19413417e-04, 1.25749590e-04,\n",
       "        1.01732241e-03, 1.33490190e-03, 8.91477510e-04, 7.13645015e-04,\n",
       "        7.70700222e-04, 3.80892976e-04, 1.64688463e-04, 5.26275835e-04,\n",
       "        9.69035784e-04, 4.44398582e-04, 5.07477263e-04, 8.68993448e-05,\n",
       "        2.40759211e-04, 1.60738477e-03, 2.07179901e-03, 4.30585409e-04,\n",
       "        1.38523371e-03, 2.38477835e-03, 1.58889533e-03, 6.35211356e-04,\n",
       "        3.13778233e-04, 4.55656234e-04, 8.58216838e-04, 1.02839876e-04,\n",
       "        2.60519329e-04, 8.71828641e-04, 3.81170947e-04, 8.95630161e-04,\n",
       "        1.34385147e-04, 2.49051559e-03, 7.14911323e-04, 5.62168483e-04,\n",
       "        3.74261435e-04, 4.57183400e-04, 4.40864125e-04, 4.72339219e-04,\n",
       "        1.92229709e-04, 7.31121341e-04, 9.12459509e-04, 4.24294034e-04,\n",
       "        3.59804108e-04, 1.25566192e-04, 3.98291158e-04, 1.30377739e-04,\n",
       "        4.65802121e-04, 2.11863357e-04, 5.71802258e-04, 1.75155094e-03,\n",
       "        2.14496604e-03, 4.93748172e-04, 3.98617587e-04, 1.13371789e-04,\n",
       "        1.95347777e-04, 3.13030003e-04, 1.52678788e-03, 7.43641518e-04,\n",
       "        6.55228563e-04, 3.29224305e-04, 7.76938279e-04, 1.43901882e-04,\n",
       "        5.73503959e-04, 2.74890743e-04, 3.50347487e-04, 3.75469623e-04,\n",
       "        1.69159321e-04, 2.86146620e-04, 3.44399828e-04, 2.95936741e-04,\n",
       "        1.04402227e-03, 1.95252782e-04, 1.17750365e-04, 6.02545333e-04,\n",
       "        4.11416026e-04, 1.63129458e-04, 1.43568366e-04, 6.02396729e-04,\n",
       "        1.59146613e-04, 1.56067021e-04, 1.01558585e-03, 3.36071895e-03,\n",
       "        1.73949928e-03, 9.42767219e-05, 1.15901988e-04, 3.23744025e-04,\n",
       "        3.65389889e-04, 1.94013899e-03, 1.58222203e-04, 5.14693675e-04,\n",
       "        4.34540241e-04, 1.18452386e-04, 9.66589359e-05, 5.17826760e-04,\n",
       "        9.14476186e-05, 4.23179299e-04, 2.49373348e-04, 1.41778670e-04,\n",
       "        8.24966410e-05, 1.69498599e-04, 6.37774123e-04, 4.56058391e-04,\n",
       "        1.02445338e-04, 4.73120512e-04, 2.34172883e-04, 2.83013796e-04,\n",
       "        2.32994920e-04, 7.58262991e-04, 9.76182986e-04, 3.76830809e-04,\n",
       "        1.74031127e-04, 2.50658253e-04, 3.04691144e-04, 1.95782617e-04,\n",
       "        4.22688434e-04, 1.16875232e-03, 6.54741074e-04, 3.82447761e-04,\n",
       "        1.55051181e-04, 2.48426601e-04, 7.10512337e-04, 3.12341755e-04,\n",
       "        5.61625930e-05, 1.12351275e-03, 3.58099700e-04, 1.77550944e-04,\n",
       "        2.91620265e-04, 3.39094346e-04, 6.03158143e-04, 4.82092786e-04,\n",
       "        1.21044992e-04, 5.76492806e-04, 7.21119228e-04, 4.93631887e-05,\n",
       "        1.39100346e-04, 9.05711029e-04, 3.23746982e-03, 7.86908902e-04,\n",
       "        2.45201227e-04, 2.23271345e-04, 6.14232558e-05, 9.29901318e-04,\n",
       "        6.21424115e-04, 1.12974225e-03, 4.43216239e-04, 1.64352547e-04,\n",
       "        4.89648664e-04, 1.49313899e-04, 4.65759018e-04, 1.81807569e-04,\n",
       "        6.85841485e-04, 1.16714719e-03, 2.59147055e-04, 3.07785405e-04,\n",
       "        1.55997020e-03, 4.16582770e-04, 3.60322971e-04, 1.71888142e-03,\n",
       "        5.35062340e-04, 8.64531845e-04, 6.42197556e-04, 1.44681183e-03,\n",
       "        2.27450812e-03, 9.06150788e-04, 4.89010534e-04, 6.76374708e-04,\n",
       "        1.96544002e-04, 2.18993620e-04, 7.64983051e-05, 5.42179041e-04,\n",
       "        9.80383120e-05, 3.51342082e-04, 1.20028359e-04, 1.04827865e-04,\n",
       "        5.59179520e-04, 2.66739720e-04, 9.64292209e-04, 9.07048234e-04,\n",
       "        1.21633355e-04, 5.92368655e-04, 2.14218497e-04, 3.70102847e-04,\n",
       "        1.31539287e-04, 8.12694489e-04, 3.52554431e-04, 3.17755330e-04,\n",
       "        2.40641675e-04, 4.62216194e-05, 1.85671542e-03, 7.71202787e-04,\n",
       "        1.40598102e-03, 2.44777743e-03, 5.14258025e-03, 1.51319464e-03,\n",
       "        7.28428306e-04, 2.16137909e-04, 1.66851189e-03, 1.69851235e-03,\n",
       "        3.01834283e-04, 5.92037723e-05, 1.94124936e-04, 6.33022792e-05,\n",
       "        1.71044070e-04, 9.92752975e-05, 1.79632814e-04, 8.67696654e-04,\n",
       "        3.33962642e-04, 2.32003353e-04, 1.52532419e-03, 9.03096749e-04,\n",
       "        7.68092519e-04, 9.52813367e-04, 3.01622233e-04, 1.01739177e-04,\n",
       "        1.23303733e-04, 2.81877903e-04, 3.10424890e-04, 6.34679018e-05,\n",
       "        2.76521721e-04, 1.69010324e-04, 1.93986416e-04, 4.69783059e-04,\n",
       "        5.89127303e-04, 1.11783658e-04, 5.75544953e-04, 2.31128273e-04,\n",
       "        1.20918659e-04, 3.14404431e-04, 7.83406838e-04, 4.92400955e-04,\n",
       "        2.73513433e-04, 6.20787905e-04, 5.99549443e-04, 9.66482476e-05,\n",
       "        6.33823220e-04, 1.87732832e-04, 6.85165869e-04, 1.12881593e-03,\n",
       "        2.88129057e-04, 6.66295644e-04, 5.89113799e-04, 2.65039434e-03,\n",
       "        1.15639938e-04, 1.75158959e-04, 1.03989973e-04, 3.16526945e-04,\n",
       "        8.17829787e-05, 7.45510406e-05, 1.99282847e-04, 2.80932843e-04,\n",
       "        1.17065955e-03, 2.53520324e-04, 8.02753784e-04, 7.87837707e-05,\n",
       "        1.94579421e-04, 5.40436013e-04, 2.62923306e-04, 7.07062354e-05,\n",
       "        2.49809906e-04, 1.09487410e-04, 5.09168662e-04, 5.08956728e-04,\n",
       "        2.82328256e-05, 5.65855706e-04, 1.03020936e-03, 7.22854747e-05,\n",
       "        8.82065069e-05, 3.51417315e-04, 3.47668654e-04, 6.48530899e-04,\n",
       "        7.40404721e-05, 1.39809883e-04, 3.36707802e-04, 1.45108276e-03,\n",
       "        1.74430752e-04, 3.25324654e-04, 1.74211556e-04, 8.71967117e-04,\n",
       "        6.68642897e-05, 2.14647327e-04, 2.36367210e-04, 1.65075529e-04,\n",
       "        8.67298688e-04, 3.20445816e-03, 2.13643856e-04, 2.26501084e-04,\n",
       "        9.55965297e-05, 6.89457811e-04, 9.86886735e-05, 7.77898764e-04,\n",
       "        8.42808571e-04, 5.48048760e-04, 6.86327287e-04, 2.64903065e-04,\n",
       "        5.65994123e-04, 2.99426005e-03, 3.37559567e-03, 8.50456394e-03,\n",
       "        5.09355858e-04, 8.79385276e-04, 2.43351082e-04, 2.11725797e-04,\n",
       "        2.37848202e-04, 1.37367926e-04, 9.47506982e-04, 2.96043989e-04,\n",
       "        1.85224082e-04, 1.33332133e-03, 5.17203356e-04, 3.54236946e-03,\n",
       "        3.25871166e-04, 9.09648312e-04, 4.66863345e-03, 3.31079145e-03,\n",
       "        1.91280793e-04, 6.17106969e-04, 8.83053232e-04, 7.48594612e-05,\n",
       "        2.97945633e-04, 7.11703557e-04, 4.61660471e-04, 2.60237395e-03,\n",
       "        1.11682260e-04, 3.25524365e-04, 1.01043051e-02, 4.87664802e-04,\n",
       "        5.09860809e-04, 9.51822512e-05, 6.74258394e-04, 2.33359053e-04,\n",
       "        1.13012700e-03, 9.54323856e-04, 1.89842729e-04, 1.31313049e-03,\n",
       "        8.08267505e-04, 4.77273919e-04, 1.61424268e-03, 1.89425645e-03,\n",
       "        4.05765983e-04, 4.92028950e-04, 2.31156661e-03, 7.45097175e-04,\n",
       "        3.48539121e-04, 1.69106096e-03, 4.33547015e-04, 3.32134441e-05,\n",
       "        1.01391975e-04, 2.49777833e-04, 1.42642320e-03, 2.28584613e-04,\n",
       "        9.19478771e-05, 9.78062511e-04, 1.13434892e-03, 1.08971668e-03,\n",
       "        5.47202690e-05, 1.68997431e-04, 1.05372071e-02, 2.41512913e-04,\n",
       "        4.65651788e-03, 1.50254683e-03, 1.90008912e-04, 6.61419472e-05,\n",
       "        2.93859106e-04, 1.59929867e-03, 7.86286619e-05, 2.57003121e-03,\n",
       "        2.31531551e-04, 4.17501316e-04, 3.42199404e-04, 2.24219184e-04,\n",
       "        2.23490479e-03, 2.80975568e-04, 5.76247112e-04, 9.52336879e-04,\n",
       "        4.56292881e-04, 1.54438370e-04, 3.17474973e-04, 2.11440586e-03,\n",
       "        5.23917959e-04, 3.79327161e-04, 7.84998294e-04, 3.65843705e-04,\n",
       "        1.51790061e-03, 7.03990809e-04, 3.49263952e-04, 3.62231891e-04,\n",
       "        6.05989655e-04, 4.41717166e-05, 9.01905994e-04, 9.99491167e-05,\n",
       "        3.88920453e-04, 1.32742003e-04, 1.69827617e-04, 1.34122733e-03,\n",
       "        1.85900915e-03, 2.72066478e-04, 4.57226968e-04, 1.79466931e-03,\n",
       "        4.59739752e-03, 6.76050026e-04, 1.54776470e-04, 7.03768572e-04,\n",
       "        2.68624077e-04, 7.95167929e-04, 9.76887415e-04, 2.90399941e-04,\n",
       "        4.46880556e-04, 2.24352628e-03, 5.03932300e-04, 3.40159953e-04,\n",
       "        1.39658432e-03, 7.37652183e-04, 4.63205995e-03, 2.96016340e-04,\n",
       "        5.54245125e-05, 1.89512328e-04, 2.70949071e-03, 3.12369899e-03,\n",
       "        3.67459841e-04, 1.96531080e-04, 1.14474620e-03, 4.70440544e-04,\n",
       "        1.49846557e-04, 9.40424297e-03, 1.32793604e-04, 2.40175777e-05,\n",
       "        1.75355774e-04, 2.59218868e-02, 1.54480862e-04, 2.28076125e-03,\n",
       "        5.38718559e-05, 2.01688381e-03, 1.26911968e-03, 8.55158796e-05,\n",
       "        9.44718625e-03, 5.35433937e-04, 7.62003532e-04, 1.04343623e-03,\n",
       "        2.58358137e-04, 2.92713317e-04, 1.06617263e-04, 1.30076951e-03,\n",
       "        5.49311400e-04, 5.02015988e-04, 9.77975724e-05, 3.76891898e-04,\n",
       "        2.03226809e-04, 1.62917553e-04, 9.82078840e-04, 1.64896934e-04,\n",
       "        9.28154972e-04, 4.27107676e-04, 7.75376800e-04, 1.08859749e-04,\n",
       "        7.37171504e-05, 8.80609732e-04, 2.69645097e-04, 2.61795387e-04,\n",
       "        1.10577785e-04, 3.50612718e-05, 4.22174162e-05, 1.35543989e-03,\n",
       "        4.71886073e-04, 8.02901632e-04, 2.88372481e-04, 8.38251901e-04,\n",
       "        4.57394402e-03, 2.72675720e-03, 2.07882476e-04, 6.16972800e-03,\n",
       "        6.68637513e-04, 4.89025377e-04, 2.88972340e-04, 1.22800717e-04,\n",
       "        1.01862522e-03, 4.56738431e-04, 3.17133818e-04, 2.40173162e-04,\n",
       "        1.68389990e-03, 1.73523778e-03, 2.51651421e-04, 1.91114217e-04,\n",
       "        1.79738761e-03, 3.82843451e-03, 2.03609816e-03, 2.28335150e-04,\n",
       "        2.25016702e-04, 1.95240966e-04, 5.33248903e-03, 5.05947566e-04,\n",
       "        8.05918316e-05, 7.99975765e-04, 1.34038084e-04, 1.03072193e-03,\n",
       "        6.39802136e-04, 4.12544614e-04, 2.17934046e-03, 3.13642714e-03,\n",
       "        5.54495770e-03, 1.03200691e-04, 2.37394264e-03, 1.66409742e-03,\n",
       "        2.33853425e-04, 2.54020793e-04, 1.33809471e-03, 1.16605501e-04,\n",
       "        9.38270416e-04, 6.96782430e-04, 1.05498941e-03, 2.12147413e-03,\n",
       "        1.33556209e-03, 6.40805112e-04, 1.05517480e-04, 4.70841595e-04,\n",
       "        1.26203673e-03, 3.88371904e-04, 3.52130213e-04, 3.12019023e-04,\n",
       "        1.51869620e-03, 3.65674146e-04, 9.57881275e-05, 2.82527442e-04,\n",
       "        1.82955211e-03, 6.48388959e-05, 2.39461660e-03, 3.58054368e-03,\n",
       "        1.75958348e-03, 2.85079150e-04, 7.78243062e-04, 2.01250310e-03,\n",
       "        6.59287791e-04, 9.28709283e-04, 1.31174689e-04, 7.00485543e-04,\n",
       "        3.25100118e-04, 1.25126226e-03, 2.41314454e-04, 2.59176712e-03,\n",
       "        1.72605447e-04, 3.99880155e-05, 6.30655186e-03, 2.86059047e-04,\n",
       "        5.23957948e-04, 1.81454016e-04, 1.39201549e-03, 1.93793472e-04,\n",
       "        1.00208819e-03, 5.68458177e-02, 2.21734110e-04, 1.71587148e-04,\n",
       "        5.37344255e-04, 1.61761302e-03, 2.64955894e-03, 3.30031122e-04,\n",
       "        2.65255861e-04, 9.52629431e-04, 8.46717856e-04, 2.07887730e-04,\n",
       "        2.38739164e-03, 2.08104099e-03, 6.53768948e-04, 3.90413799e-04,\n",
       "        6.77371048e-04, 5.07983670e-04, 7.20085693e-04, 2.32756502e-04,\n",
       "        6.17353013e-04, 4.05340164e-04, 9.75458970e-05, 1.07624591e-03,\n",
       "        2.11533462e-03, 4.52652166e-04, 2.14148633e-04, 1.95762157e-04,\n",
       "        9.13940079e-04, 2.96474725e-04, 1.02398262e-04, 1.83269847e-04,\n",
       "        5.93708269e-03, 1.65959680e-03, 2.41882866e-04, 6.55932890e-05,\n",
       "        8.29725352e-04, 6.65604020e-05, 5.32142294e-04, 3.36098572e-04,\n",
       "        9.97936237e-04, 1.67972816e-03, 9.96339601e-04, 1.20338227e-03,\n",
       "        1.03848483e-02, 1.00171631e-02, 1.02906895e-03, 4.94893000e-04,\n",
       "        8.01724032e-04, 3.72124960e-05, 4.13038040e-04, 1.36432226e-03,\n",
       "        1.43871689e-03, 2.46792589e-03, 2.02242937e-03, 3.89350753e-04,\n",
       "        1.45368947e-04, 1.21815386e-03, 2.63304828e-04, 1.33860169e-03,\n",
       "        2.27413280e-03, 1.05433841e-03, 1.96631474e-04, 3.13204317e-03,\n",
       "        3.78054829e-04, 5.16090367e-04, 1.25131890e-04, 1.57897850e-03,\n",
       "        1.38232586e-04, 4.23182122e-04, 7.06224644e-04, 7.22948869e-04,\n",
       "        4.41018055e-04, 9.36989440e-04, 9.71797330e-04, 2.73629150e-04,\n",
       "        5.03415184e-04, 2.61850469e-03, 1.60022406e-03, 4.19995427e-04,\n",
       "        2.11239816e-03, 1.43698917e-03, 3.50457476e-03, 5.51029167e-04,\n",
       "        2.67499895e-03, 3.49418819e-03, 3.20708117e-04, 2.12598965e-03,\n",
       "        4.60392475e-04, 3.70941707e-04, 2.27192926e-04, 1.53328903e-04,\n",
       "        3.88772204e-03, 1.50511111e-03, 5.57112617e-05, 5.79306274e-04,\n",
       "        1.01827655e-03, 1.01541146e-03, 6.54077012e-05, 2.26267474e-03,\n",
       "        9.41183942e-04, 2.98461528e-03, 8.92565586e-04, 1.90930231e-03,\n",
       "        2.41923705e-03, 1.05419173e-03, 1.90393743e-03, 1.98735681e-04,\n",
       "        2.05273638e-04, 7.99031113e-04, 1.13510154e-03, 9.05224442e-05,\n",
       "        5.33208891e-04, 1.63612538e-04, 7.05424638e-04, 1.60631246e-03,\n",
       "        1.75805332e-03, 8.53639620e-04, 1.00225734e-03, 7.74376269e-04,\n",
       "        3.36833065e-04, 2.53674272e-03, 2.98243976e-04, 4.66056721e-04,\n",
       "        1.02103676e-03, 3.14234337e-03, 1.36874188e-02, 2.16628629e-04,\n",
       "        3.08968505e-04, 6.73270843e-04, 7.70853134e-04, 1.74234330e-03,\n",
       "        4.01375364e-05, 3.29241127e-04, 1.74137633e-04, 5.44199371e-04,\n",
       "        2.82886229e-03, 6.52745017e-04, 2.35938060e-04, 3.36886238e-04,\n",
       "        5.12107799e-04, 4.66753962e-04, 6.09937531e-04, 1.44324638e-03,\n",
       "        2.02567666e-03, 2.81799887e-03, 3.05070396e-04, 1.50417478e-03,\n",
       "        1.33967446e-03, 5.69641961e-05, 9.12415155e-04, 6.12527074e-05,\n",
       "        4.15769282e-05, 1.29568391e-04, 7.10480817e-05, 3.68243549e-04,\n",
       "        4.14259383e-04, 6.11893920e-05, 4.12837020e-04, 3.03211040e-04,\n",
       "        2.13580625e-03, 3.77164070e-05, 2.77470332e-04, 1.19053246e-03,\n",
       "        5.49450517e-04, 5.17037406e-04, 5.71882701e-04, 4.49239073e-04,\n",
       "        4.20599681e-04, 6.80830737e-04, 1.29818125e-03, 1.88739024e-04,\n",
       "        1.45626278e-03, 9.28370515e-04, 9.07409936e-04, 2.22824863e-04,\n",
       "        4.69702063e-03, 2.77900160e-03, 1.37076259e-03, 2.13174659e-04,\n",
       "        5.62861038e-04, 2.07874319e-03, 5.21397800e-04, 1.20574411e-03,\n",
       "        6.52210205e-04, 1.89708080e-04, 1.49322237e-04, 1.23539800e-03,\n",
       "        4.04357525e-05, 1.78355956e-04, 3.18920356e-04, 3.15998239e-03,\n",
       "        4.71762287e-05, 8.13260116e-03, 4.61962627e-04, 1.90600753e-04,\n",
       "        5.70315970e-05, 5.13935120e-05, 2.55209394e-04, 2.52917089e-04,\n",
       "        1.09679997e-02, 3.85843246e-04, 4.23857040e-04, 2.36470252e-04,\n",
       "        1.09124393e-03, 2.71152239e-04, 3.27000598e-05, 2.82443681e-04,\n",
       "        3.46886832e-03, 3.90921399e-04, 6.34904281e-05, 3.20987456e-04,\n",
       "        6.70035137e-04, 1.81723066e-04, 1.34564552e-03, 3.36707500e-03,\n",
       "        9.81146842e-03, 6.98141987e-04, 1.87429090e-04, 2.02963696e-04,\n",
       "        1.71242296e-04, 1.17814438e-04, 3.77878401e-04, 4.44683683e-04,\n",
       "        7.53342547e-03, 2.87887012e-03, 1.71743776e-03, 9.46901331e-04,\n",
       "        4.20331443e-03, 4.27456619e-03, 1.18784071e-03, 1.88802846e-03,\n",
       "        1.54456939e-03, 3.60542466e-03, 6.93561102e-04, 2.92098703e-04,\n",
       "        4.43232851e-03, 1.47996179e-03, 5.98433195e-04, 3.41425068e-04,\n",
       "        4.51280316e-03, 3.31008428e-04, 2.50790967e-03, 2.81208986e-03,\n",
       "        1.46770530e-04, 8.53380363e-04, 3.23709624e-04, 5.69380529e-04,\n",
       "        1.06412983e-04, 1.38782736e-04, 2.32607056e-03, 6.76852476e-04,\n",
       "        3.15377285e-04, 1.16295051e-02, 2.79390533e-03, 1.81433687e-04,\n",
       "        4.55630798e-05, 4.25954873e-04, 2.13802032e-05, 2.09299935e-04,\n",
       "        3.37263773e-04, 3.93146707e-04, 8.17437540e-05, 3.05567315e-04,\n",
       "        1.79687297e-04, 1.11627640e-04, 1.20815210e-04, 1.24485698e-04,\n",
       "        9.10652598e-05, 8.58012572e-05, 9.87179956e-05, 1.01323007e-04,\n",
       "        2.20108981e-04, 1.61448814e-04, 3.32607684e-04, 7.02712932e-05,\n",
       "        6.95205672e-05, 7.39425304e-05, 2.95391419e-05, 1.07868480e-04,\n",
       "        4.72691376e-04, 4.21110381e-05, 1.30277185e-04, 2.01610979e-04,\n",
       "        3.09892028e-04, 9.22772088e-05, 3.34206707e-04, 9.85710503e-05,\n",
       "        9.42963743e-05, 1.69678213e-04, 2.33319210e-04, 1.07884269e-04,\n",
       "        1.54778827e-04, 3.07124644e-03, 4.49575236e-05, 5.89085175e-05,\n",
       "        8.77828425e-05, 2.14784115e-04, 5.20019268e-04, 5.21923881e-04,\n",
       "        7.60558061e-04, 2.73707061e-04, 2.66448857e-04, 1.07699540e-03,\n",
       "        1.88703474e-04, 5.66835915e-05, 3.05671943e-04, 4.97582194e-04,\n",
       "        2.61588633e-04, 6.21295068e-03, 7.44056888e-04, 9.10402960e-05,\n",
       "        7.12998386e-04, 3.82972969e-04, 2.46325188e-04, 1.20614321e-04,\n",
       "        1.50384847e-04, 1.29202483e-04, 1.03674392e-04, 2.21076276e-04,\n",
       "        3.69326270e-04, 1.34613452e-04, 5.03405790e-05, 4.57294118e-05,\n",
       "        7.83778960e-05, 1.18863782e-05, 3.32679192e-05, 8.75391561e-05,\n",
       "        6.16038524e-05, 8.49567878e-05, 1.83294149e-04, 1.53452046e-02]],\n",
       "      dtype=float32))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 推論の実行\n",
    "prepared_backend.run(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n7-6as8LwOas"
   },
   "source": [
    "### ONNX 形式のモデルを Caffe2 形式に変換する\n",
    "\n",
    "前節では Chainer の学習済みモデルを ONNX 形式に変換し、Caffe2 を使用してそのモデルで推論を行いました。\n",
    "本節では、ONNX 形式のモデルを Caffe2 形式に変換する方法を説明します。\n",
    "Caffe2 はモバイル環境に対応しているため、Chainer で作成した学習済みモデルを ONNX 形式を経由して Caffe2 形式に変換することで、モバイルアプリへの組み込みが可能になります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cUGNW0SBwOiN"
   },
   "outputs": [],
   "source": [
    "# ONNX モデルを Caffe2 モデルに変換\n",
    "init_net, predict_net = backend.Caffe2Backend.onnx_graph_to_caffe2_net(onnx_model, device='CPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CToOjVjPwOoi"
   },
   "outputs": [],
   "source": [
    "# Caffe2 モデルの保存\n",
    "from caffe2.python.onnx.helper import save_caffe2_net\n",
    "save_caffe2_net(init_net , 'caffemodel_init.pb', output_txt=False)\n",
    "save_caffe2_net(predict_net , 'caffemodel_predict.pb', output_txt=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 228901,
     "status": "ok",
     "timestamp": 1548312180404,
     "user": {
      "displayName": "西沢衛",
      "photoUrl": "",
      "userId": "12011220225445512117"
     },
     "user_tz": -540
    },
    "id": "UIZA-7u8yVqc",
    "outputId": "9c160999-427a-4862-8e9f-52a8c3a93e2f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caffemodel_init.pb  caffemodel_predict.pb\r\n"
     ]
    }
   ],
   "source": [
    "# 出力されたファイルの確認\n",
    "!ls *.pb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nT5zUn43b-h1"
   },
   "source": [
    "## Menoh を使用した他言語での推論\n",
    "\n",
    "前節では、Chainer で学習したモデルを、ONNX を介して異なるフレームワークで推論する方法をお伝えしました。\n",
    "本節では ONNX 形式のモデルを読み込んで推論を行う [Menoh](https://github.com/pfnet-research/menoh)（メノウ）フレームワークの方法を解説します。\n",
    "\n",
    "Menoh は ONNX 形式で保存された学習済みモデルを読み込むことのできる、推論専用の深層学習フレームワークです。\n",
    "Menoh は、C/C++ で実装された Menoh 本体（コアライブラリ）と各言語向けのバインディングから構成されており、様々なプログラミング言語から呼び出せるように設計されていることが大きな特徴の一つです。\n",
    "2019年2月現在、C, C++, C#, Ruby, Java, Go, Node.js, Haskell, Rust から Menoh を利用することができます。\n",
    "\n",
    "ここでは、Ruby から Menoh を使用して推論を行う方法を紹介します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1iA7xKvXb-h2"
   },
   "source": [
    "### Menoh-Ruby の環境構築"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1iA7xKvXb-h3"
   },
   "source": [
    "#### Ruby のインストール"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!apt install ruby ruby-dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1iA7xKvXb-h4"
   },
   "source": [
    "#### Menoh のインストール\n",
    "\n",
    "[Menoh](https://github.com/pfnet-research/menoh) 本体のインストールを行います。\n",
    "なお、この環境構築の手順は Ubuntu 18.04（Google Colaboratory 環境）を想定しています。\n",
    "それ以外の環境でのセットアップ手順は [README](https://github.com/pfnet-research/menoh#installation-using-package-manager-or-binary-packages) を参照してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -LO \"https://github.com/pfnet-research/menoh/releases/download/v1.1.1/ubuntu1804_mkl-dnn_0.16-1_amd64.deb\"\n",
    "!curl -LO \"https://github.com/pfnet-research/menoh/releases/download/v1.1.1/ubuntu1804_menoh_1.1.1-1_amd64.deb\"\n",
    "!curl -LO \"https://github.com/pfnet-research/menoh/releases/download/v1.1.1/ubuntu1804_menoh-dev_1.1.1-1_amd64.deb\"\n",
    "!apt install ./ubuntu1804_*_amd64.deb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Menoh-Ruby のインストール\n",
    "\n",
    "Menoh の [Ruby バインディング](https://github.com/pfnet-research/menoh-ruby)のインストールを行います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gem install menoh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Ruby で推論を行う\n",
    "\n",
    "Menoh-Ruby の[サンプルスクリプト](https://github.com/pfnet-research/menoh-ruby/blob/3e0a972dcfcf3c4af7a681b6400ae47f85cbd383/example/example_vgg16.rb)を `example_vgg16.rb` という名前で保存して、実行してみましょう。\n",
    "ONNX 形式の学習済みモデルファイル（VGG16）とテスト用の画像2枚が `data` ディレクトリにダウンロードされた後、推論が実行されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# サンプルスクリプトで使用するライブラリのインストール\n",
    "!apt install libmagickwand-dev\n",
    "!gem install rmagick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# サンプルスクリプトのダウンロードと実行\n",
    "!curl -LO \"https://raw.githubusercontent.com/pfnet-research/menoh-ruby/3e0a972dcfcf3c4af7a681b6400ae47f85cbd383/example/example_vgg16.rb\"\n",
    "!mkdir -p data/\n",
    "!ruby \"example_vgg16.rb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1iA7xKvXb-h5"
   },
   "source": [
    "推論結果が以下のように表示されれば成功です。\n",
    "\n",
    "```\n",
    "=== Result for ./data/Light_sussex_hen.jpg ===\n",
    "n01514859 hen : 0.9339964389801025\n",
    "n01514668 cock : 0.05969797447323799\n",
    "n01807496 partridge : 0.002985152183100581\n",
    "n01797886 ruffed grouse, partridge, Bonasa umbellus : 0.0008867944125086069\n",
    "n01847000 drake : 0.0005284951184876263\n",
    "\n",
    "=== Result for ./data/honda_nsx.jpg ===\n",
    "n04285008 sports car, sport car : 0.6823536157608032\n",
    "n04037443 racer, race car, racing car : 0.1251951903104782\n",
    "n03100240 convertible : 0.11076415330171585\n",
    "n02974003 car wheel : 0.047828804701566696\n",
    "n03459775 grille, radiator grille : 0.009155559353530407\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1iA7xKvXb-h6"
   },
   "source": [
    "#### サンプルスクリプトの内容について"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1iA7xKvXb-h7"
   },
   "source": [
    "ここでは、[サンプルスクリプト](https://github.com/pfnet-research/menoh-ruby/blob/3e0a972dcfcf3c4af7a681b6400ae47f85cbd383/example/example_vgg16.rb)の概要について説明します。\n",
    "（モデルや画像のデータセットのダウンロードは省略します。）  \n",
    "\n",
    "最初に、サンプルスクリプトで使用する各ライブラリの読み込みを行います。\n",
    "Ruby で画像を扱うライブラリとして [RMagick](https://github.com/rmagick/rmagick) を使用しています。\n",
    "\n",
    "```ruby\n",
    "require 'open-uri'\n",
    "require 'rmagick'\n",
    "require 'menoh'\n",
    "```\n",
    "\n",
    "ONNX 形式のモデルデータと推論に使うサンプルデータをダウンロードします。\n",
    "\n",
    "```ruby\n",
    "# download dependencies\n",
    "...\n",
    "```\n",
    "\n",
    "推論に使うサンプルデータのファイル名と、学習モデル（VGG16）の入力データ形式を定義します。\n",
    "`rgb_offset` は学習済みの\n",
    "\n",
    "```ruby\n",
    "# load dataset\n",
    "image_list = [\n",
    "  './data/Light_sussex_hen.jpg',\n",
    "  './data/honda_nsx.jpg'\n",
    "]\n",
    "input_shape = {\n",
    "  channel_num: 3,\n",
    "  width: 224,\n",
    "  height: 224\n",
    "}\n",
    "rgb_offset = {\n",
    "  R: 123.68,\n",
    "  G: 116.779,\n",
    "  B: 103.939\n",
    "}\n",
    "```\n",
    "\n",
    "Menoh を使用して ONNX 形式のモデルデータを読み込みます。\n",
    "\n",
    "```ruby\n",
    "# load ONNX file\n",
    "onnx_obj = Menoh::Menoh.new './data/VGG16.onnx'\n",
    "```\n",
    "\n",
    "ONNX 形式のモデルでは、ニューラルネットワークの各部分（ノード）にユニークな ID が振られています。\n",
    "Menoh ではネットワークの任意の部分に対してデータを入出力することができるため、データの入出力対象となる ID を指定する必要があります。\n",
    "ネットワークの各部分に設定された ID は、モデルファイルを [Netron](https://github.com/lutzroeder/Netron) などの可視化ツールで読み込むことで確認できます。\n",
    "\n",
    "* `CONV1_1_IN_NAME` は入力層（最初の畳み込み層）の ID で、この層にデータを入力します。\n",
    "* `FC6_OUT_NAME` は全結合層（1番目）の ID です。本スクリプトでは、この層の出力結果は使用しません（複数の出力を指定するサンプルコードを示す目的で定義されています）。\n",
    "* `SOFTMAX_OUT_NAME` は出力層（最終層の出力に Softmax 関数を適用したもの）の ID で、推論の結果（各分類クラスに対するスコア）を得ることができます。\n",
    "\n",
    "```ruby\n",
    "# onnx variable name\n",
    "CONV1_1_IN_NAME = 'Input_0'.freeze\n",
    "FC6_OUT_NAME = 'Gemm_0'.freeze\n",
    "SOFTMAX_OUT_NAME = 'Softmax_0'.freeze\n",
    "```\n",
    "\n",
    "読み込んだ ONNX 形式のモデルをどのように実行するかを定義し、「Menoh モデル」を作成します。\n",
    "ここではバックエンドとして `mkldnn` （Intel CPU 向けのハードウェアアクセラレーション）を使用します。\n",
    "また、入力層の ID とそのデータ形式、出力層の ID を定義します。\n",
    "\n",
    "```ruby\n",
    "# model options for model\n",
    "model_opt = {\n",
    "  backend: 'mkldnn',\n",
    "  input_layers: [\n",
    "    {\n",
    "      name: CONV1_1_IN_NAME,\n",
    "      dims: [\n",
    "        image_list.length,\n",
    "        input_shape[:channel_num],\n",
    "        input_shape[:height],\n",
    "        input_shape[:width],\n",
    "      ]\n",
    "    }\n",
    "  ],\n",
    "  output_layers: [FC6_OUT_NAME, SOFTMAX_OUT_NAME]\n",
    "}\n",
    "\n",
    "# make model for inference under 'model_opt'\n",
    "model = onnx_obj.make_model model_opt\n",
    "```\n",
    "\n",
    "推論対象の画像を読み込み、データセットの準備を行います。\n",
    "\n",
    "1. `image_list` から順番に画像ファイルのパスを読み込み、`image_filepath` に格納します。\n",
    "2. RMagick で画像を読み込みます（画像の読み込み後に Array の形式となるため、`.first` で最初の要素を取得します）。\n",
    "3. 読み込んだ画像を VGG16 の入力サイズにあわせてリサイズします。\n",
    "4. RGB の各ピクセル値を 16-bit から 8-bit に変換（256 で割る）し、中間画像の offset の値を引く正規化を行います。\n",
    "\n",
    "```ruby\n",
    "# prepare dataset\n",
    "image_set = [\n",
    "  {\n",
    "    name: CONV1_1_IN_NAME,\n",
    "    data: image_list.map do |image_filepath|  # 1\n",
    "      image = Magick::Image.read(image_filepath).first  # 2\n",
    "      image = image.resize_to_fill(input_shape[:width], input_shape[:height])  # 3\n",
    "      'RGB'.split('').map do |color|\n",
    "        image.export_pixels(0, 0, image.columns, image.rows, color).map do |pix|\n",
    "          pix / 256 - rgb_offset[color.to_sym]  # 4\n",
    "        end\n",
    "      end.flatten\n",
    "    end.flatten\n",
    "  }\n",
    "]\n",
    "```\n",
    "\n",
    "推論を実行します。\n",
    "\n",
    "```ruby\n",
    "# execute inference\n",
    "inferenced_results = model.run image_set\n",
    "```\n",
    "\n",
    "推論結果を、対応するカテゴリ名と共に出力します。\n",
    "\n",
    "```ruby\n",
    "# load category definition\n",
    "categories = File.read('./data/synset_words.txt').split(\"\\n\")\n",
    "TOP_K = 5\n",
    "layer_result = inferenced_results.find { |x| x[:name] == SOFTMAX_OUT_NAME }\n",
    "layer_result[:data].zip(image_list).each do |image_result, image_filepath|\n",
    "  puts \"=== Result for #{image_filepath} ===\"\n",
    "\n",
    "  # sort by score\n",
    "  sorted_result = image_result.zip(categories).sort_by { |x| -x[0] }\n",
    "\n",
    "  # display result\n",
    "  sorted_result[0, TOP_K].each do |score, category|\n",
    "    puts \"#{category} : #{score}\"\n",
    "  end\n",
    "end\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RHUbc6Zeb-h3"
   },
   "source": [
    "本章では、Chainer で作成した学習済みモデルを、様々なフレームワークや言語で推論する方法を解説しました。\n",
    "これにより、学習済みモデルを様々な環境で使用したり、アプリケーションに組み込むことが可能となります。"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "様々な環境での推論: ONNX と Menoh の活用",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
