{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n3uYk8aaZh8k"
   },
   "source": [
    "# 様々な環境での推論：ONNX、Menohの活用\n",
    "\n",
    "前章まではChainerを用いての学習済みモデルの作成方法・推論の実行方法を解説しました。  \n",
    "推論時にも言語はPython、ディープラーニングのフレームワークはChainerという同じ環境を想定していました。  \n",
    "\n",
    "しかし、実務で推論を行う上ではそのような環境がない可能性もあります。  \n",
    "そこで本章では `ONNX` （オニキス）と呼ばれるパッケージを使用して、異なるフレームワークを使用して推論を実行する方法について解説していきます。  \n",
    "また、`Menoh`（メノウ）を使用して他言語での推論方法もお伝えします。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zTnwNprg0ZLP"
   },
   "source": [
    "## ONNXとは？\n",
    "\n",
    "`ONNX` とは **Open Neural Network eXchange** の略で、Deep Learningモデルを様々なフレームワーク間で交換するためのフォーマットです。  \n",
    "\n",
    "ONNXを使用することによって、Chainerで学習させたモデルを他のフレームワークでも利用することができます。  \n",
    "\n",
    "多様なフレームワークが用いられる実務では重要な仕組みになります。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B06Z0MwRZh4C"
   },
   "source": [
    "### ONNXフォーマットの対応状況  \n",
    "\n",
    "ONNXは全てのDeep Learningのフレームワークに対応していません。  \n",
    "現在のフォーマット対応状況は[公式のGitHubページ](https://github.com/onnx/tutorials)から確認することができます。  \n",
    "\n",
    "2019年1月現在では下記のようになっています。  \n",
    "\n",
    "\n",
    "| Framework / tool                                             | Installation                                                 | Exporting to ONNX (frontend)                                 | Importing ONNX models (backend)                              |\n",
    "| ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |\n",
    "| [Caffe2](http://caffe2.ai/)                                  | [part of caffe2 package](https://github.com/pytorch/pytorch/tree/master/caffe2/python/onnx) | [Exporting](https://github.com/onnx/tutorials/blob/master/tutorials/Caffe2OnnxExport.ipynb) | [Importing](https://github.com/onnx/tutorials/blob/master/tutorials/OnnxCaffe2Import.ipynb) |\n",
    "| [PyTorch](http://pytorch.org/)                               | [part of pytorch package](http://pytorch.org/docs/master/onnx.html) | [Exporting](https://github.com/onnx/tutorials/blob/master/tutorials/PytorchOnnxExport.ipynb), [Extending support](https://github.com/onnx/tutorials/blob/master/tutorials/PytorchAddExportSupport.md) | coming soon                                                  |\n",
    "| [Cognitive Toolkit (CNTK)](https://www.microsoft.com/en-us/cognitive-toolkit/) | [built-in](https://docs.microsoft.com/en-us/cognitive-toolkit/setup-cntk-on-your-machine) | [Exporting](https://github.com/onnx/tutorials/blob/master/tutorials/CntkOnnxExport.ipynb) | [Importing](https://github.com/onnx/tutorials/blob/master/tutorials/OnnxCntkImport.ipynb) |\n",
    "| [Apache MXNet](http://mxnet.incubator.apache.org/)           | part of mxnet package [docs](http://mxnet.incubator.apache.org/api/python/contrib/onnx.html) [github](https://github.com/apache/incubator-mxnet/tree/master/python/mxnet/contrib/onnx) | [Exporting](https://github.com/onnx/tutorials/blob/master/tutorials/MXNetONNXExport.ipynb) | [Importing](https://github.com/onnx/tutorials/blob/master/tutorials/OnnxMxnetImport.ipynb) |\n",
    "| [Chainer](https://chainer.org/)                              | [chainer/onnx-chainer](https://github.com/chainer/onnx-chainer) | [Exporting](https://github.com/onnx/tutorials/blob/master/tutorials/ChainerOnnxExport.ipynb) | coming soon                                                  |\n",
    "| [TensorFlow](https://www.tensorflow.org/)                    | [onnx/onnx-tensorflow](https://github.com/onnx/onnx-tensorflow) and [onnx/tensorflow-onnx](https://github.com/onnx/tensorflow-onnx) | [Exporting](https://github.com/onnx/tutorials/blob/master/tutorials/OnnxTensorflowExport.ipynb) | [Importing](https://github.com/onnx/tutorials/blob/master/tutorials/OnnxTensorflowImport.ipynb) [experimental] |\n",
    "| [Apple CoreML](https://developer.apple.com/documentation/coreml) | [onnx/onnx-coreml](https://github.com/onnx/onnx-coreml) and [onnx/onnxmltools](https://github.com/onnx/onnxmltools) | [Exporting](https://github.com/onnx/onnxmltools)             | [Importing](https://github.com/onnx/tutorials/blob/master/tutorials/OnnxCoremlImport.ipynb) |\n",
    "| [SciKit-Learn](http://scikit-learn.org/)                     | [onnx/onnxmltools](https://github.com/onnx/onnxmltools)      | [Exporting](https://github.com/onnx/onnxmltools)             | n/a                                                          |\n",
    "| [ML.NET](https://github.com/dotnet/machinelearning/)         | [built-in](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.models.onnxconverter.convert?view=ml-dotnet#definition) | [Exporting](https://github.com/dotnet/machinelearning/blob/master/test/Microsoft.ML.Tests/OnnxTests.cs) | [Importing](https://github.com/dotnet/machinelearning/blob/master/test/Microsoft.ML.OnnxTransformTest/OnnxTransformTests.cs#L186) |\n",
    "| [Menoh](https://github.com/pfnet-research/menoh)             | [pfnet-research/menoh](https://github.com/pfnet-research/menoh) | n/a                                                          | [Importing](https://github.com/onnx/tutorials/blob/master/tutorials/OnnxMenohHaskellImport.ipynb) |\n",
    "| [MATLAB](https://www.mathworks.com/)                         | [onnx converter on matlab central file exchange](https://www.mathworks.com/matlabcentral/fileexchange/67296) | [Exporting](https://www.mathworks.com/help/deeplearning/ref/exportonnxnetwork.html) | [Importing](https://www.mathworks.com/help/deeplearning/ref/importonnxnetwork.html) |\n",
    "| [TensorRT](https://developer.nvidia.com/tensorrt)            | [onnx/onnx-tensorrt](https://github.com/onnx/onnx-tensorrt)  | n/a                                                          | [Importing](https://github.com/onnx/onnx-tensorrt/blob/master/README.md) |\n",
    "\n",
    "Chainerでは現在 `Exporting` （Chainerの学習済みモデルをONNXのフォーマットに変換すること）のみが可能です。　 \n",
    "しかし、 `Importing` も開発中のためゆくゆくは利用可能となる予定です。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NXbVwHf10Bed"
   },
   "source": [
    "### ONNXの使用上の注意点\n",
    "\n",
    "ONNXを使用する上ではいくつか注意するポイントがあります。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BawSJN6k0Dtl"
   },
   "source": [
    "#### Deep Learningフレームワーク間でのExport/Importのフォーマット対応\n",
    "\n",
    "前項でも解説したように、ONNXでは対応しているフォーマットに違いがあります。  \n",
    "そのため、全てのフレームワークに相互互換がないと言うことに注意しましょう。  \n",
    "\n",
    "例えば、ChainerからExportは実行することができますが、ExportしたものはPyTorchにはImportを行うことができません。  \n",
    "（上記は将来的には解消される予定です。）\n",
    "\n",
    "\n",
    "#### Deep Learningフレームワークのパーツレベルでの対応\n",
    "\n",
    "こちらの問題点はあまり気にする必要はありませんが、稀にONNX側でサポートしていない関数などが存在する場合があります。  \n",
    "\n",
    "サポートしている関数などを確認するには[公式のドキュメント](https://github.com/onnx/onnx/blob/master/docs/Operators.md)を確認してください。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kTE1H_ED0IBE"
   },
   "source": [
    "## ONNXの使用方法\n",
    "\n",
    "Chainerの学習済みモデルをONNXのフォーマットに変換する方法を解説します。  \n",
    "\n",
    "今回はChainerの中で学習済みモデルとして用意されているVGG16のモデルを使用します。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eaJC6WzxeGeN"
   },
   "outputs": [],
   "source": [
    "import chainer\n",
    "import chainer.functions as F\n",
    "import chainer.links as L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 47282,
     "status": "ok",
     "timestamp": 1548311998706,
     "user": {
      "displayName": "西沢衛",
      "photoUrl": "",
      "userId": "12011220225445512117"
     },
     "user_tz": -540
    },
    "id": "yC9WUiiSeltC",
    "outputId": "af0c02b6-b1cc-40e8-c5ce-16306c998f11"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.robots.ox.ac.uk/%7Evgg/software/very_deep/caffe/VGG_ILSVRC_16_layers.caffemodel...\n",
      "Now loading caffemodel (usually it may take few minutes)\n"
     ]
    }
   ],
   "source": [
    "# VGG16モデルの読み込み\n",
    "model = L.VGG16Layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 47256,
     "status": "ok",
     "timestamp": 1548311998706,
     "user": {
      "displayName": "西沢衛",
      "photoUrl": "",
      "userId": "12011220225445512117"
     },
     "user_tz": -540
    },
    "id": "wMd8QwycepcN",
    "outputId": "64eb1600-ffff-4a5f-b561-38334e35e335"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['conv1_1',\n",
       " 'conv1_2',\n",
       " 'pool1',\n",
       " 'conv2_1',\n",
       " 'conv2_2',\n",
       " 'pool2',\n",
       " 'conv3_1',\n",
       " 'conv3_2',\n",
       " 'conv3_3',\n",
       " 'pool3',\n",
       " 'conv4_1',\n",
       " 'conv4_2',\n",
       " 'conv4_3',\n",
       " 'pool4',\n",
       " 'conv5_1',\n",
       " 'conv5_2',\n",
       " 'conv5_3',\n",
       " 'pool5',\n",
       " 'fc6',\n",
       " 'fc7',\n",
       " 'fc8',\n",
       " 'prob']"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# VGG16のアーキテクチャーの確認\n",
    "model.available_layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LNRb5jV5WvP8"
   },
   "source": [
    "### ONNXのフォーマットに変換\n",
    "\n",
    "ONNXのフォーマットに変換する際には `onnx-chainer` を使用します。  \n",
    "Google Colabratory内にはデフォルトで用意されていないので `pip` を使用してインストールしましょう。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 445
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 55618,
     "status": "ok",
     "timestamp": 1548312007078,
     "user": {
      "displayName": "西沢衛",
      "photoUrl": "",
      "userId": "12011220225445512117"
     },
     "user_tz": -540
    },
    "id": "sjeTaX3RXjyf",
    "outputId": "deb1ae02-fddc-4070-dbf2-aca042d71907"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting onnx-chainer\n",
      "  Downloading https://files.pythonhosted.org/packages/88/7a/dbd770f51d82a8a37ee4f3bb3a1bbf83be456edb4f69fab6475971a22712/onnx-chainer-1.3.0a1.tar.gz\n",
      "Requirement already satisfied: chainer>=3.2.0 in /usr/local/lib/python3.6/dist-packages (from onnx-chainer) (5.0.0)\n",
      "Collecting onnx>=1.3.0 (from onnx-chainer)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/26/753bca1bc4e7e254d34da82f5b2e213ca9b32cbeb2d9e305fec4abcfebf7/onnx-1.4.1-cp36-cp36m-manylinux1_x86_64.whl (6.9MB)\n",
      "\u001b[K    100% |████████████████████████████████| 6.9MB 4.4MB/s \n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from chainer>=3.2.0->onnx-chainer) (3.0.10)\n",
      "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from chainer>=3.2.0->onnx-chainer) (1.14.6)\n",
      "Requirement already satisfied: protobuf>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from chainer>=3.2.0->onnx-chainer) (3.6.1)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from chainer>=3.2.0->onnx-chainer) (1.11.0)\n",
      "Collecting typing-extensions>=3.6.2.1 (from onnx>=1.3.0->onnx-chainer)\n",
      "  Downloading https://files.pythonhosted.org/packages/0f/62/c66e553258c37c33f9939abb2dd8d2481803d860ff68e635466f12aa7efa/typing_extensions-3.7.2-py3-none-any.whl\n",
      "Collecting typing>=3.6.4 (from onnx>=1.3.0->onnx-chainer)\n",
      "  Downloading https://files.pythonhosted.org/packages/4a/bd/eee1157fc2d8514970b345d69cb9975dcd1e42cd7e61146ed841f6e68309/typing-3.6.6-py3-none-any.whl\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.0.0->chainer>=3.2.0->onnx-chainer) (40.6.3)\n",
      "Building wheels for collected packages: onnx-chainer\n",
      "  Running setup.py bdist_wheel for onnx-chainer ... \u001b[?25l-\b \b\\\b \bdone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/3a/84/32/0a820425f2bf08d95db68e35c4d3bc19fea44f10a229c83c70\n",
      "Successfully built onnx-chainer\n",
      "Installing collected packages: typing-extensions, typing, onnx, onnx-chainer\n",
      "Successfully installed onnx-1.4.1 onnx-chainer-1.3.0a1 typing-3.6.6 typing-extensions-3.7.2\n",
      "\u001b[0;31;1mWARNING: The following packages were previously imported in this runtime:\n",
      "  [typing]\n",
      "You must restart the runtime in order to use newly installed versions.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install onnx-chainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0ls46NvyWvVM"
   },
   "outputs": [],
   "source": [
    "import onnx_chainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qliA5FHxlM0h"
   },
   "source": [
    "Chainerは **Define-by-Run** というスタイルを採用しているため、ネットワーク構造は実際にデータを渡してフォワード計算を行うまで決定されていません。  \n",
    "そのため、 `ONNX-Chainer` ではダミーの入力変数を準備して、ONNXの形式に変換時にその値を渡してあげる必要があります。  \n",
    "\n",
    "推論の際にはバッチサイズ、行、列の `shape` の入力変数を用いたのと同様の形かつ、データ型も `float32型`  のダミーの変数 `x` を渡します。  \n",
    "\n",
    "VGG16モデルは224×224の3チャネルのインプットを想定しています。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 55823,
     "status": "ok",
     "timestamp": 1548312007297,
     "user": {
      "displayName": "西沢衛",
      "photoUrl": "",
      "userId": "12011220225445512117"
     },
     "user_tz": -540
    },
    "id": "vmym_1HqiuPK",
    "outputId": "9fa27d15-8adb-4973-e074-999452ede276"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3, 224, 224)"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ダミー変数の準備\n",
    "import numpy as np\n",
    "_x = np.zeros((1, 3, 224, 224), dtype=np.float32)\n",
    "_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VJXz95jfWvaJ"
   },
   "outputs": [],
   "source": [
    "# 推論モードに切り替え\n",
    "chainer.config.train = False\n",
    "\n",
    "# ONNXのフォーマットに変換\n",
    "onnx_model = onnx_chainer.export(model, _x, filename='convnet.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 66022,
     "status": "ok",
     "timestamp": 1548312017506,
     "user": {
      "displayName": "西沢衛",
      "photoUrl": "",
      "userId": "12011220225445512117"
     },
     "user_tz": -540
    },
    "id": "emlaV9PtWvkH",
    "outputId": "ccb32699-025d-4dcf-c21b-48d6dbe69fd2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convnet.onnx  sample_data\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oG7DLMBXQFJ7"
   },
   "source": [
    "このようにして学習済みモデルをONNXのフォーマットに変換することができました。  \n",
    "\n",
    "続いてはこちらを他のフレームワークのフォーマットにImportします。  \n",
    "\n",
    "### Caffe2で推論\n",
    "\n",
    "先ほどChainerで作成し、ONNXの形式で保存したモデルを読み込みCaffe2で推論を行います。  \n",
    "\n",
    "その前に`pytorch` をインストールしておく必要があります。  \n",
    "（pytorchは `caffe2` のモジュールをインポートするために必要になります。）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 377
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 165297,
     "status": "ok",
     "timestamp": 1548312116791,
     "user": {
      "displayName": "西沢衛",
      "photoUrl": "",
      "userId": "12011220225445512117"
     },
     "user_tz": -540
    },
    "id": "fAyfxVuyqGXq",
    "outputId": "5794c166-6e3f-4dd9-ba8a-63cd1fa3d494"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/60/66415660aa46b23b5e1b72bc762e816736ce8d7260213e22365af51e8f9c/torch-1.0.0-cp36-cp36m-manylinux1_x86_64.whl (591.8MB)\n",
      "\u001b[K    100% |████████████████████████████████| 591.8MB 27kB/s \n",
      "tcmalloc: large alloc 1073750016 bytes == 0x61c20000 @  0x7f5061f862a4 0x591a07 0x5b5d56 0x502e9a 0x506859 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x504c28 0x502540 0x502f3d 0x507641\n",
      "\u001b[?25hCollecting torchvision\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/0d/f00b2885711e08bd71242ebe7b96561e6f6d01fdb4b9dcf4d37e2e13c5e1/torchvision-0.2.1-py2.py3-none-any.whl (54kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 22.8MB/s \n",
      "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.14.6)\n",
      "Collecting pillow>=4.1.1 (from torchvision)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/5e/e91792f198bbc5a0d7d3055ad552bc4062942d27eaf75c3e2783cf64eae5/Pillow-5.4.1-cp36-cp36m-manylinux1_x86_64.whl (2.0MB)\n",
      "\u001b[K    100% |████████████████████████████████| 2.0MB 5.2MB/s \n",
      "\u001b[?25hInstalling collected packages: torch, pillow, torchvision\n",
      "  Found existing installation: Pillow 4.0.0\n",
      "    Uninstalling Pillow-4.0.0:\n",
      "      Successfully uninstalled Pillow-4.0.0\n",
      "Successfully installed pillow-5.4.1 torch-1.0.0 torchvision-0.2.1\n",
      "\u001b[0;31;1mWARNING: The following packages were previously imported in this runtime:\n",
      "  [PIL]\n",
      "You must restart the runtime in order to use newly installed versions.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2QzKAy7BHAtl"
   },
   "outputs": [],
   "source": [
    "# Caffe2のパッケージの中にONNXを使用するモジュールがあります\n",
    "import caffe2\n",
    "from caffe2.python.onnx import backend\n",
    "from caffe2.python.onnx.helper import save_caffe2_net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1rq_9V_RwomQ"
   },
   "source": [
    "#### 推論用のデータの準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7ghONkv-lKbq"
   },
   "outputs": [],
   "source": [
    "# ダミーの変数を用意\n",
    "x = np.random.randn(1, 3, 224, 224).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 165898,
     "status": "ok",
     "timestamp": 1548312117394,
     "user": {
      "displayName": "西沢衛",
      "photoUrl": "",
      "userId": "12011220225445512117"
     },
     "user_tz": -540
    },
    "id": "q80GZx31H92W",
    "outputId": "c5feffd1-1813-4c19-dfb5-79be8c484ea8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3, 224, 224)"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Glbk0VW6wwDP"
   },
   "source": [
    "#### Caffe2モデルで推論の実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kkSrkmm54zpy"
   },
   "outputs": [],
   "source": [
    "# 保存済みONNXモデルの読み込み\n",
    "import onnx\n",
    "onnx_model = onnx.load(\"convnet.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-OC5BCce40C9"
   },
   "outputs": [],
   "source": [
    "# Caffe2で推論できる状態に準備\n",
    "prepared_backend = backend.prepare(onnx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hI3lfFzp5LM-"
   },
   "outputs": [],
   "source": [
    "# Caffe2での推論の実行\n",
    "caffe_output = prepared_backend.run(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n7-6as8LwOas"
   },
   "source": [
    "### ONNX出力したChainerのモデルをCaffe2形式で保存\n",
    "\n",
    "先ほどはChainerのモデルをONNXのフォーマットに変換し、そしてCaffe2を使用して推論を行いました。  \n",
    "\n",
    "本項ではそのONNXのモデルをCaffe2のフォーマットで保存します。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cUGNW0SBwOiN"
   },
   "outputs": [],
   "source": [
    "# ONNXモデルをCaffe2モデルに変換\n",
    "init_net, predict_net = backend.Caffe2Backend.onnx_graph_to_caffe2_net(onnx_model, device='CPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CToOjVjPwOoi"
   },
   "outputs": [],
   "source": [
    "# Caffe2モデルの保存\n",
    "save_caffe2_net(init_net , 'caffemodel_init.pb', output_txt=False)\n",
    "save_caffe2_net(predict_net , 'caffemodel_predict.pb', output_txt=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 228901,
     "status": "ok",
     "timestamp": 1548312180404,
     "user": {
      "displayName": "西沢衛",
      "photoUrl": "",
      "userId": "12011220225445512117"
     },
     "user_tz": -540
    },
    "id": "UIZA-7u8yVqc",
    "outputId": "9c160999-427a-4862-8e9f-52a8c3a93e2f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caffemodel_init.pb  caffemodel_predict.pb  convnet.onnx  sample_data\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bF7zbqUyyVjY"
   },
   "source": [
    "Caffe2の特徴の1つとしてモバイル対応が強化されているという点があります。  \n",
    "\n",
    "このようにChainerで作成したモデルをCaffe2モデルに変換することによって、モバイルにも対応させることが可能になりました。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nT5zUn43b-h1"
   },
   "source": [
    "## Menohで他言語で推論\n",
    "\n",
    "前節では異なるフレームワークを使用しての推論方法をお伝えしました。  \n",
    "本節では`Menoh`（メノウ）を使用しての他言語での推論方法を解説します。  \n",
    "\n",
    "Menohは学習済みのディープラーニングのモデルをONNX形式から読み込んで動作させる推論専用のライブラリです。  \n",
    "本章では`Ruby`言語を使用しての推論方法を紹介します。  \n",
    "（本章はRubyの使用経験がある方を対象にしているため、Ruby言語についての解説は最少となっています。）  \n",
    "\n",
    "Menohは`Ruby`のみならずその他の言語もサポートしています。  \n",
    "`C#`, `Go`, `Haskell`, `Node.js`, `Rust`などです。  \n",
    "その他の使用方法には関しては[こちらのGitHubのページ](https://github.com/pfnet-research/menoh)を参照してください。　　"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1iA7xKvXb-h2"
   },
   "source": [
    "### Ruby-Menohの環境構築\n",
    "\n",
    "まずは環境構築の方法を確認します。  \n",
    "\n",
    "#### Rubyのインストール\n",
    "\n",
    "もし、RubyをこちらのチュートリアルにRuby未経験で試される方はこちらの節に従い、環境を整えてください。\n",
    "\n",
    "**Windowsの場合**  \n",
    "\n",
    "[こちら](https://rubyinstaller.org/downloads/)からダウンロード\n",
    "\n",
    "\n",
    "**Macの場合**  \n",
    "\n",
    "初期状態でインストール済み\n",
    "\n",
    "\n",
    "#### Menohのインストール\n",
    "\n",
    "Menohをインストールして環境を構築しましょう。  \n",
    "\n",
    "```bash\n",
    "gem install bundler\n",
    "gem install rake-compiler\n",
    "```\n",
    "\n",
    "```bash\n",
    "gem install menoh\n",
    "```\n",
    "\n",
    "しかし、現状ではWindowsでもMacでも下記のエラーが出てしまい、インストールがうまくいきません。  \n",
    "\n",
    "```bash\n",
    "menoh_ruby.h:4:10: fatal error: menoh/menoh.h: No such file or directory\n",
    " #include <menoh/menoh.h>\n",
    "          ^~~~~~~~~~~~~~~\n",
    "compilation terminated.\n",
    "make: *** [Makefile:244: menoh_ruby.o] エラー 1\n",
    "\n",
    "make failed, exit code 2\n",
    "```\n",
    "\n",
    "そのため、Dockerを使用した環境構築が一番無難でしょう。  \n",
    "（Dockerはコンテナ型の仮想技術を提供するオープンソフトウェアです。詳しくは[公式のドキュメント](https://docs.docker.com/)を確認してください。）  \n",
    "\n",
    "今回はこちらの方法でお伝えします。  \n",
    "\n",
    "```bash\n",
    "export IMAGE_VERSION=0.0.0 # please specify version\n",
    "sudo -E docker build -t menoh-ruby:$IMAGE_VERSION `pwd`\n",
    "```\n",
    "\n",
    "ビルドには30分程度かかりました。\n",
    "これで`menoh-ruby`という名前のdocker imageが完成します。\n",
    "\n",
    "作業用のディレクトリに移動したあと、  \n",
    "\n",
    "```Bash\n",
    "sudo -E docker run -it --name menoh-ruby-test -v $(pwd):/opt/menoh-ruby --entrypoint /bin/bash menoh-ruby:$IMAGE_VERSION\n",
    "```\n",
    "\n",
    "上記のコマンドでdockerコンテナを立ち上げます。\n",
    "コンテナから抜けるには下記のコマンドを使用します。\n",
    "\n",
    "```bash\n",
    "exit\n",
    "```\n",
    "\n",
    "しかし、コンテナを抜けると同時にコンテナが停止してしまうため、  \n",
    "再度コンテナに入るためには下記のコマンドを使用します。  \n",
    "\n",
    "```bash\n",
    "sudo -E docker start -i menoh-ruby-test\n",
    "```\n",
    "\n",
    "正しく、menohがインストールされているかを確認してみましょう。\n",
    "\n",
    "```ruby\n",
    "root@1d042df46a8f:/opt/menoh-ruby# irb\n",
    "irb(main):001:0> require 'menoh'\n",
    "=> true\n",
    "irb(main):002:0> exit\n",
    "```\n",
    "\n",
    "### Rubyで推論\n",
    "\n",
    "menohの環境構築ができると、まずはうまく動作するか確認します。  \n",
    "\n",
    "[こちら](https://github.com/pfnet-research/menoh-ruby/blob/63019b80bcea44fcb30c8ec46ae6315d5a2101a7/example/example_vgg16.rb)のスクリプトを`example_vgg16.rb`という名前で保存して、実行してみましょう。\n",
    "\n",
    "```bash\n",
    "ruby example_vgg16.rb\n",
    "```\n",
    "\n",
    "使用するonnxの学習済みモデル（VGG16）とテスト用の画像２枚が`data`フォルダにダウンロードされ、推論結果が以下のように表示されると成功です。  \n",
    "\n",
    "```bash\n",
    "=== Result for ./data/Light_sussex_hen.jpg ===\n",
    "n01514859 hen : 0.9506610035896301\n",
    "n01514668 cock : 0.04745088890194893\n",
    "n01807496 partridge : 0.0012374237412586808\n",
    "n01797886 ruffed grouse, partridge, Bonasa umbellus : 0.00024278569617308676\n",
    "n01847000 drake : 6.84420665493235e-05\n",
    "=== Result for ./data/honda_nsx.jpg ===\n",
    "n04285008 sports car, sport car : 0.5454844236373901\n",
    "n04037443 racer, race car, racing car : 0.4156607687473297\n",
    "n03100240 convertible : 0.020360812544822693\n",
    "n02974003 car wheel : 0.012692754156887531\n",
    "n03444034 go-kart : 0.003139265812933445\n",
    "```\n",
    "\n",
    "このようにRubyを使用して、推論することができました。  \n",
    "\n",
    "Rubyで推論する際はこのスクリプトを参考に進めればよいのですが、主要部分の確認を行っておきます。  \n",
    "（モデルや画像のデータセットのダウンロードは省略します。）  \n",
    "\n",
    "Rubyでの画像を扱うライブラリとして[RMagick](https://github.com/rmagick/rmagick)を使用し、またMenohの読み込みも行っています。\n",
    "\n",
    "```ruby\n",
    "require 'rmagick'\n",
    "require 'menoh'\n",
    "```\n",
    "\n",
    "前半では画像の読み込みやモデルに関する情報の設定を行います。  \n",
    "\n",
    "データセットはRubyの配列（Array）形式で指定します。  \n",
    "\n",
    "```ruby\n",
    "# load dataset\n",
    "image_list = [\n",
    "  './data/Light_sussex_hen.jpg',\n",
    "  './data/honda_nsx.jpg'\n",
    "]\n",
    "```\n",
    "\n",
    "画像サイズもVGG16で使用されているサイズを指定しています。\n",
    "\n",
    "```ruby\n",
    "input_shape = {\n",
    "  channel_num: 3,\n",
    "  width: 224,\n",
    "  height: 224\n",
    "}\n",
    "```\n",
    "\n",
    "データセットの準備では以下の処理を行っています。\n",
    "\n",
    "1. `image_list` から順番に画像を読み込み、`image_filepath` に格納\n",
    "2. RMagickで画像の読み込み。画像の読み込み後にArrayの形式となるため、`.first` で要素として取得\n",
    "3. 読み込んだ画像を上記で指定したサイズに変更\n",
    "4. 各RGBごと（`'RGB'.split('')`）に繰り返し\n",
    "5. 画像の各要素ごとに繰り返し\n",
    "6. 要素が16bitで扱われているため、256で割って8bitの値に補正し、offsetの値を引く正規化処理\n",
    "\n",
    "```ruby\n",
    "# prepare dataset\n",
    "image_set = [\n",
    "  {\n",
    "    name: CONV1_1_IN_NAME,\n",
    "    # 1\n",
    "    data: image_list.map do |image_filepath|\n",
    "      # 2\n",
    "      image = Magick::Image.read(image_filepath).first\n",
    "      # 3\n",
    "      image = image.resize_to_fill(input_shape[:width], input_shape[:height])\n",
    "      # 4\n",
    "      'RGB'.split('').map do |color|\n",
    "        # 5\n",
    "        image.export_pixels(0, 0, image.columns, image.rows, color).map do |pix|\n",
    "          # 6\n",
    "          pix / 256 - rgb_offset[color.to_sym]\n",
    "        end\n",
    "      end.flatten\n",
    "    end.flatten\n",
    "  }\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RHUbc6Zeb-h3"
   },
   "source": [
    "本章では様々なフレームワーク、言語での推論方法を解説しました。  \n",
    "これで環境に左右されることを抑え、学習済みモデルを使用することができます。  "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "10_ONNXの活用.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
