{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "colab_type": "text",
                "id": "7SnBhGPFEnW7"
            },
            "source": [
                "# 転移学習\n",
                "\n",
                "本章では、前回取り扱った犬猫の分類問題に対して、さらに精度を向上する方法として転移学習について解説します。\n",
                "\n",
                "コンピュータビジョン（画像認識）に特化したライブラリである ChainerCV の使用方法も確認します。  \n",
                "\n",
                "\n",
                "## 転移学習\n",
                "\n",
                "深層学習の学習は、通常、非常に多くの学習データを必要とします。\n",
                "そのようなデータを使って学習するのも、非常に時間がかかります。\n",
                "この問題を解決するためによく行われる方法のひとつとして転移学習（transfer learning）があります。\n",
                "これは、モデルを一から構築して学習させるのではなく、既存の学習済みモデル（ソースモデル）をベースにして学習させるというものです。\n",
                "これによって少ないデータでの学習が可能になり、短い学習時間で高い精度を得ることができます。\n",
                "\n",
                "画像認識の領域では、[ImageNet](http://www.image-net.org/) と呼ばれる 1000 クラス一般物体認識のタスクで優秀な成績を収めたモデルが公開されており、これらをソースモデルとして使うことが一般的です。\n",
                "\n",
                "なお、「転移学習」という言葉は、本章で扱うものよりももう少し広い意味を持ちます。本章では画像認識タスクで学習したものを画像認識タスクで再学習していますが、例えば、音声認識で学習したモデルを動画認識に使うといったようにドメインをまたぐ学習も転移学習とよびます。\n",
                "\n",
                "## ネットワークアーキテクチャ\n",
                "\n",
                "画像認識の代表的なモデルには下記が挙げられます。\n",
                "\n",
                "- VGG16（2014）\n",
                "- Google Net（2014）\n",
                "- ResNet（2015）\n",
                "\n",
                "今回は、比較的構造のシンプルな VGG16 をソースモデルとして使用した実装方法についてお伝えします。  \n",
                "\n",
                "その他のモデルについては下記の公式ドキュメントを確認してください。  \n",
                "\n",
                "- [GoogLeNet](https://docs.chainer.org/en/stable/reference/generated/chainer.links.GoogLeNet.html)\n",
                "- [ResNet152](https://docs.chainer.org/en/stable/reference/generated/chainer.links.ResNet152Layers.html)\n",
                "- [VGG16](https://docs.chainer.org/en/stable/reference/generated/chainer.links.VGG16Layers.html)\n",
                "- [学習済みモデル一覧](https://docs.chainer.org/en/stable/reference/links.html#pre-trained-models)\n",
                "\n",
                "下の図は、今回学習するネットワークの模式図です。\n",
                "\n",
                "![ネットワークの構造](images/13/02.png)\n",
                "\n",
                "図のようにソースモデルの途中の出力を取り出し、そこから新しく計算をつなげ、新しいモデル（ターゲットモデル）を組みます。\n",
                "\n",
                "ソースモデルから、損失関数を計算する 1 つ前の層の出力を「特徴量」として取り出すことが最も一般的です。\n",
                "このように得られた特徴量は、もとの入力変数よりも学習しやすい表現になっており、新しいモデルの学習が効率的になります。\n",
                "\n",
                "今回は、そこに新しく全結合層を追加し、目的の 2 クラス（犬・猫）分類タスクに即した識別を行います。"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## データの読み込み\n",
                "\n",
                "### 必要なライブラリのインポート"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### データのダウンロードとディレクトリ構成の確認\n",
                "\n",
                "今回使うデータをダウンロードし解凍します。"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "!wget https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zip\n",
                "!unzip -q -o kagglecatsanddogs_3367a.zip"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "解凍ができたら中身の確認をします。"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "!ls -al ./PetImages/"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "`PetImages` というディレクトリの中に、`Cat` と `Dog` というディレクトリがあります。\n",
                "それぞれのディレクトリの中がどのようになっているのか確認します。"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Catの中のファイル5行だけを表示\n",
                "!ls -l ./PetImages/Cat/ | head -5\n",
                "\n",
                "# Dogの中のファイル5行だけを表示\n",
                "!ls -l ./PetImages/Dog/ | head -5"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "`Cat` と `Dog` どちらのディレクトリもJPEGファイルが入っていることが確認できました。"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "colab_type": "text",
                "id": "HBHBOe5ziidz"
            },
            "source": [
                "### 画像データの読み込みと前処理\n",
                "\n",
                "画像データを読み込み、Chainer および VGG16 モデルに適した形に変換します。  \n",
                "画像の変換は、`chainer.links.model.vision.vgg.prepare()` という関数を使用すると簡単に行うことができます。  \n",
                "この関数は単に画像を Chainer の形に合わせるだけではなく、いくつかの特殊な前処理を実施します。  \n",
                "\n",
                "**VGG16 の前処理**\n",
                "\n",
                "- (高さ、幅、チャンネル) の順になっている shape を (チャンネル、高さ、幅) の順に並び替える\n",
                "- カラーチャンネルの順番を RGB から BGR に変換する\n",
                "- 各画素の値から平均値を引く（中心化）\n",
                "- 画像サイズを 224×224 に変換する\n",
                "\n",
                "VGG16 に限らず、ネットワークによって最適な前処理を行う場合がほとんどです。  \n",
                "前処理についてはデータオーグメンテーションの章で詳細をお伝えします。  "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {
                "colab": {},
                "colab_type": "code",
                "id": "uUQECPz9iiX4"
            },
            "outputs": [],
            "source": [
                "from glob import glob"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {
                "colab": {},
                "colab_type": "code",
                "id": "X3l4-AJuYyak"
            },
            "outputs": [],
            "source": [
                "# ファイルパスの取得\n",
                "dog_filepaths = glob('./PetImages/Dog/*')\n",
                "cat_filepaths = glob('./PetImages/Cat/*')\n",
                "dog_filepaths = dog_filepaths[:1000]\n",
                "cat_filepaths = cat_filepaths[:1000]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {
                "colab": {},
                "colab_type": "code",
                "id": "CxnHYzHKjh2Z"
            },
            "outputs": [],
            "source": [
                "import chainer\n",
                "import chainer.links as L\n",
                "import chainer.functions as F"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {
                "colab": {},
                "colab_type": "code",
                "id": "Sq037UuCkYtX"
            },
            "outputs": [],
            "source": [
                "import cv2"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "`L.model.vision.vgg.prepare()` を使用する際の注意点として、入力する画像は下記の要件を満たす必要があります。  \n",
                "\n",
                "- shape が (高さ、幅、チャンネル) の順になっていること\n",
                "- カラーチャンネルの順番が RGB になっていること\n",
                "\n",
                "今回 shape は問題ありませんが、チャンネルの順番が BGR になっているため RGB に変換しておきます。  "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {
                "colab": {},
                "colab_type": "code",
                "id": "B1vJOAeCYyOK"
            },
            "outputs": [],
            "source": [
                "# 画像の読み込みと BGR → RGB の変換\n",
                "img = cv2.cvtColor(cv2.imread(dog_filepaths[0]), cv2.COLOR_BGR2RGB)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {
                "colab": {},
                "colab_type": "code",
                "id": "kiaBYEDEmd_y"
            },
            "outputs": [],
            "source": [
                "# VGG16 の前処理の適応\n",
                "img = L.model.vision.vgg.prepare(img)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "colab_type": "text",
                "id": "rx3Gbg_VmlSQ"
            },
            "source": [
                "画像がどのように変換されているのか確認します。\n",
                "\n",
                "ChainerCV には NumPy 形式の画像データを簡単に表示する機能があります。ChainerCV は Google Colaboratoryで デフォルトで準備されていないため、 `pip` を使用してインストールを実行します。"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/",
                    "height": 190
                },
                "colab_type": "code",
                "id": "fNwNPH2xYyHA",
                "outputId": "1a088a10-9df8-4024-cfc3-ad1a42fdc92a",
                "scrolled": true
            },
            "outputs": [],
            "source": [
                "!pip install chainercv"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {
                "colab": {},
                "colab_type": "code",
                "id": "2DJK2eyLYx-u"
            },
            "outputs": [],
            "source": [
                "import chainercv"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "colab_type": "text",
                "id": "gKHBcGdRnGy_"
            },
            "source": [
                "画像の表示には `chainercv.visualizations.vis_image()` という関数を使用します。"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/",
                    "height": 367
                },
                "colab_type": "code",
                "id": "F4wGXfxjk_77",
                "outputId": "6c7000fc-33cd-4b10-89fc-50ca22ba8974"
            },
            "outputs": [],
            "source": [
                "# 前処理済みの画像を表示する\n",
                "chainercv.visualizations.vis_image(img)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "colab_type": "text",
                "id": "XP9Yp0OUlADp"
            },
            "source": [
                "画像全体から平均値が引かれているため、目や口のように暗い部分は反転してしまっていますが、前処理が施されていることが確認できます。"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/",
                    "height": 34
                },
                "colab_type": "code",
                "id": "t8rF5LspnpT1",
                "outputId": "f385309f-4573-4dc3-ccaf-a53b11a026fa"
            },
            "outputs": [],
            "source": [
                "type(img)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/",
                    "height": 34
                },
                "colab_type": "code",
                "id": "G4Slv8r3lAGH",
                "outputId": "1c455941-013c-4385-c94e-1f1ca8193748"
            },
            "outputs": [],
            "source": [
                "img.dtype"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/",
                    "height": 34
                },
                "colab_type": "code",
                "id": "k9vo8yRBlAIQ",
                "outputId": "c73767b3-2ee6-4e5d-a673-542343d95c26"
            },
            "outputs": [],
            "source": [
                "img.shape"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "colab_type": "text",
                "id": "pzkRGqlpnrbX"
            },
            "source": [
                "### データセットの作成\n",
                "\n",
                "` L.model.vision.vgg.prepare()` の挙動を確認したところで、全ての画像に対して、処理を加えるプログラムを作成します。  "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {
                "colab": {},
                "colab_type": "code",
                "id": "1jUP7jFZnrVI"
            },
            "outputs": [],
            "source": [
                "imgs = []\n",
                "labels = []\n",
                "for dog_filepath in dog_filepaths:\n",
                "  img = cv2.imread(dog_filepath)\n",
                "  if img is None:\n",
                "    continue\n",
                "  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
                "  img = L.model.vision.vgg.prepare(img)\n",
                "  imgs.append(img)\n",
                "  labels.append(0)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {
                "colab": {},
                "colab_type": "code",
                "id": "b1WyZ97DqWqR"
            },
            "outputs": [],
            "source": [
                "for cat_filepath in cat_filepaths:\n",
                "  img = cv2.imread(cat_filepath)\n",
                "  if img is None:\n",
                "    continue\n",
                "  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
                "  img = L.model.vision.vgg.prepare(img)\n",
                "  imgs.append(img)\n",
                "  labels.append(1)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {
                "colab": {},
                "colab_type": "code",
                "id": "2L_B6Tw5qbE6"
            },
            "outputs": [],
            "source": [
                "import numpy as np"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "metadata": {
                "colab": {},
                "colab_type": "code",
                "id": "kzLhUq1ZnrPi"
            },
            "outputs": [],
            "source": [
                "x = np.array(imgs)\n",
                "t = np.array(labels, np.int32)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "metadata": {
                "colab": {},
                "colab_type": "code",
                "id": "PFNt2qb4k_-J"
            },
            "outputs": [],
            "source": [
                "# データセットの作成\n",
                "from chainer.datasets import TupleDataset\n",
                "dataset = TupleDataset(x, t)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "metadata": {
                "colab": {},
                "colab_type": "code",
                "id": "SC5ohA3PoPx8"
            },
            "outputs": [],
            "source": [
                "# 訓練と検証データへ分割\n",
                "from chainer.datasets import split_dataset_random\n",
                "n_train = int(len(dataset)*0.7)\n",
                "train, test = split_dataset_random(dataset, n_train, seed=1)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/",
                    "height": 34
                },
                "colab_type": "code",
                "id": "hwazNVCgoP4v",
                "outputId": "1fd400e8-76a7-4eba-d53b-561bdb807fbe"
            },
            "outputs": [],
            "source": [
                "len(train)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/",
                    "height": 34
                },
                "colab_type": "code",
                "id": "YsS7JlyIoP-8",
                "outputId": "fdc94bd5-c4bf-43d3-932c-1126b1df6edb"
            },
            "outputs": [],
            "source": [
                "len(test)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "colab_type": "text",
                "id": "jZuwkUpvoQE8"
            },
            "source": [
                "### ネットワークの定義\n",
                "\n",
                "繰り返しになりますが、今回学習するネットワークは次のようになります。\n",
                "\n",
                "![ネットワークの構造](images/13/02.png)\n",
                "\n",
                "Chainer には、ソースモデルである VGG16 は `L.VGG16Layers` として定義されています。"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "metadata": {
                "colab": {},
                "colab_type": "code",
                "id": "Hb2uCdtMoQKt"
            },
            "outputs": [],
            "source": [
                "vgg16 = L.VGG16Layers()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "colab_type": "text",
                "id": "KPzdkpWZq1fx"
            },
            "source": [
                "`available_layers` 属性で VGG16 の中の構造を確認することができます。"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 26,
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/",
                    "height": 391
                },
                "colab_type": "code",
                "id": "j1TiGuCdoQQu",
                "outputId": "077b5280-c325-4864-a9f2-286f6ada033a",
                "scrolled": true
            },
            "outputs": [],
            "source": [
                "# 構造の確認\n",
                "vgg16.available_layers"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "VGG16 は、1000 クラスの一般物体認識タスクで学習されたモデルです。\n",
                "`prob` は 1000 クラスの確率分布、その手前の `fc8` は 1000 クラスの確率化前の表現を出力します。\n",
                "この 2 つの層は、1000 クラスの一般物体認識に特化した層ということです。\n",
                "\n",
                "今回は、そのひとつ前の層、`fc7` の出力を特徴量として利用します。\n",
                "\n",
                "モデルのクラスは次のように記述します。"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 27,
            "metadata": {
                "colab": {},
                "colab_type": "code",
                "id": "rCTkjf1GoQWu"
            },
            "outputs": [],
            "source": [
                "class VGG16(chainer.Chain):\n",
                "\n",
                "    def __init__(self, n_out=9):\n",
                "        super().__init__()\n",
                "        with self.init_scope():\n",
                "            self.base = L.VGG16Layers()\n",
                "            self.fc = L.Linear(None, n_out)\n",
                "\n",
                "    def forward(self, x):\n",
                "        h = self.base(x, layers=['fc7'])\n",
                "        h = self.fc(h['fc7'])\n",
                "        return h"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "`__init__()` メソッドで、ソースモデルである `L.VGG16Layers` をインスタンス化し、`self.base` として定義します。\n",
                "\n",
                "そして、新しい部分である全結合層 `fc` も定義します。  \n",
                "\n",
                "順伝播の記述（`forward()`）は、ソースモデルの `fc7` 層までの計算を `self.base(x, layers=['fc7'])` と記述します。\n",
                "この結果は `dict` になっており、`h['fc7']` のように、層の名前をキーにしてその層の出力を取り出すことができます。\n",
                "そして、その出力を全結合層 `fc` に流すという計算の流れになっています。"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 28,
            "metadata": {
                "colab": {},
                "colab_type": "code",
                "id": "ByvbYInZoQcu"
            },
            "outputs": [],
            "source": [
                "# 乱数のシード固定用の関数\n",
                "import random\n",
                "\n",
                "def reset_seed(seed=0):\n",
                "    random.seed(seed)\n",
                "    np.random.seed(seed)\n",
                "    if chainer.cuda.available:\n",
                "        chainer.cuda.cupy.random.seed(seed)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 29,
            "metadata": {
                "colab": {},
                "colab_type": "code",
                "id": "VbZStYV9pda1"
            },
            "outputs": [],
            "source": [
                "# CPUとGPU関連のシードをすべて固定\n",
                "reset_seed(0)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 30,
            "metadata": {
                "colab": {},
                "colab_type": "code",
                "id": "kTfQmTtGpdhC"
            },
            "outputs": [],
            "source": [
                "# インスタンス化\n",
                "vgg16 = VGG16()\n",
                "model = L.Classifier(vgg16)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 31,
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/",
                    "height": 34
                },
                "colab_type": "code",
                "id": "OwFXPwTlpdmf",
                "outputId": "065ef596-2dab-4333-dbb5-e94a38ca3c58"
            },
            "outputs": [],
            "source": [
                "gpu_id = 0 \n",
                "model.to_gpu(gpu_id)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 32,
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/",
                    "height": 34
                },
                "colab_type": "code",
                "id": "7CY6dha9pdsP",
                "outputId": "eb435cbf-88d2-4267-fd06-af8da992a724"
            },
            "outputs": [],
            "source": [
                "# Optimizer の定義と model との紐づけ\n",
                "optimizer = chainer.optimizers.Adam()\n",
                "optimizer.setup(model)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "colab_type": "text",
                "id": "5FJooSlCqoOi"
            },
            "source": [
                "ここまでは今までの実装と同じです。\n",
                "\n",
                "## パラメータを固定する\n",
                "\n",
                "定義したモデルをこれまで通り学習すると、ソースモデル部分のパラメータも学習が行われ、更新されます[<sup>*1</sup>]。\n",
                "しかし、少ない学習データですべてのパラメータを学習すると、計算時間がかかるうえ、過学習によって汎化性能が低下してしまいます。\n",
                "そこで、ソースモデルの入力側のパラメータを固定し、その一部だけを再学習することができます。\n",
                "\n",
                "今回は、ソースモデル部分は、最後の層（`fc7`）のみを学習します。\n",
                "\n",
                "デフォルトでは、すべてのパラメータを学習するような設定になっています。\n",
                "\n",
                "下記の 1 行によって、一度ソースモデル部分を学習しないように設定します。"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 33,
            "metadata": {
                "colab": {},
                "colab_type": "code",
                "id": "KxrXP7B0pdyA"
            },
            "outputs": [],
            "source": [
                "model.predictor.base.disable_update()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "さらに、`fc7` 層だけ学習するように設定し直します。"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 34,
            "metadata": {},
            "outputs": [],
            "source": [
                "model.predictor.base.fc7.enable_update()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "これで、ソースモデル部分のうち `fc7` 層だけを再学習し、それ以外はパラメータを固定して使う、という設定になりました。\n",
                "\n",
                "### 学習率を調整する\n",
                "学習の内容にもよりますが、ファインチューニングでは基本的に学習済みのパラメータの更新は小さく、それ以外の部分の学習は大きくすることが一般的です\n",
                "（学習済みモデルはある程度学習が進んでいるため、微調整を加えるだけで問題ないためです）。\n",
                "\n",
                "そのように二つの異なる部分のパラメータの更新を変更するにはオプティマイザの更新の規則の部分の設定を変更します。\n",
                "\n",
                "[`Adam`](https://docs.chainer.org/en/stable/reference/generated/chainer.optimizers.Adam.html) オプティマイザでは、`alpha` と呼ばれるハイパーパラメータが学習率に相当します。\n",
                "下記では、 `alpha` を `1e-4` と小さめに設定しておき、 `fc` の追加した層の部分のみ `update_rule` を用いて、その 10 倍に設定することで調整を行っています。  "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 35,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Optimizerの定義とmodelとの紐づけ\n",
                "alpha = 1e-4\n",
                "\n",
                "optimizer = chainer.optimizers.Adam(alpha=alpha)\n",
                "optimizer.setup(model)\n",
                "\n",
                "model.predictor['fc'].W.update_rule.hyperparam.alpha = alpha * 10\n",
                "model.predictor['fc'].b.update_rule.hyperparam.alpha = alpha * 10"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 学習\n",
                "\n",
                "これでモデルとオプティマイザの準備ができました。\n",
                "学習してみましょう"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 36,
            "metadata": {
                "colab": {},
                "colab_type": "code",
                "id": "aZybe0nGpd33"
            },
            "outputs": [],
            "source": [
                "batchsize = 64\n",
                "train_iter = chainer.iterators.SerialIterator(train, batchsize)\n",
                "test_iter = chainer.iterators.SerialIterator(test, batchsize, repeat=False, shuffle=False)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 37,
            "metadata": {
                "colab": {},
                "colab_type": "code",
                "id": "RA7vV0owpd9r"
            },
            "outputs": [],
            "source": [
                "from chainer import training\n",
                "from chainer.training import extensions\n",
                "\n",
                "epoch = 20\n",
                "\n",
                "updater = training.StandardUpdater(train_iter, optimizer, device=gpu_id)\n",
                "\n",
                "trainer = training.Trainer(updater, (epoch, 'epoch'), out='drive/My Drive/Colab Notebooks/result')\n",
                "\n",
                "# バリデーション用のデータで評価\n",
                "trainer.extend(extensions.Evaluator(test_iter, model, device=gpu_id))\n",
                "\n",
                "# 学習結果の途中を表示する\n",
                "trainer.extend(extensions.LogReport(trigger=(1, 'epoch'), log_name='dog-cat_transferlearning-vgg16'))\n",
                "\n",
                "# １ エポックごとに結果をログファイルに出力する\n",
                "trainer.extend(extensions.PrintReport(['epoch', 'iteration', 'main/accuracy', 'validation/main/accuracy', 'main/loss', 'validation/main/loss', 'elapsed_time']), trigger=(1, 'epoch'))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 38,
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/",
                    "height": 374
                },
                "colab_type": "code",
                "id": "PS_dwCs4peDa",
                "outputId": "1fc92ca7-2a99-4191-da44-bc6ffe8f2ca9"
            },
            "outputs": [],
            "source": [
                "trainer.run()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 39,
            "metadata": {
                "colab": {},
                "colab_type": "code",
                "id": "XbhxkjyXIgUG"
            },
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import json"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 40,
            "metadata": {
                "colab": {},
                "colab_type": "code",
                "id": "ftUo5qDDEZ86"
            },
            "outputs": [],
            "source": [
                "with open('drive/My Drive/Colab Notebooks/result/dog-cat_transferlearning-vgg16') as f:\n",
                "    result = pd.DataFrame(json.load(f))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 41,
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/",
                    "height": 379
                },
                "colab_type": "code",
                "id": "tt6c9oBYEhIK",
                "outputId": "8270bbf9-c518-44b3-dfce-fe0a4a5d52c8"
            },
            "outputs": [],
            "source": [
                "result.tail(10)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 42,
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/",
                    "height": 364
                },
                "colab_type": "code",
                "id": "0cIP2ZOEEoRN",
                "outputId": "91b0d47f-b08b-42ab-b55e-b2515d86f941"
            },
            "outputs": [],
            "source": [
                "# 精度 (accuracy)\n",
                "result[['main/accuracy', 'validation/main/accuracy']].plot()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "colab_type": "text",
                "id": "oDOCIgJFfI0D"
            },
            "source": [
                "転移学習を行うことによって高い精度を得ることができました。\n",
                "\n",
                "今回はソースモデルの最後の層だけ再学習しましたが、もっと上の層のパラメータまで再学習することも可能です。しかし、学習するパラメータを増やしすぎると過学習しやすくなり、検証用データセットでの認識率が低下します。\n",
                "余力のある読者は試してみるとよいでしょう。"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 脚注\n",
                "<span id=\"fn1\"><sup>*1</sup>: <small>このように既存のモデルを再学習することをファインチューニングといいます。</small></span>"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.6.8"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}