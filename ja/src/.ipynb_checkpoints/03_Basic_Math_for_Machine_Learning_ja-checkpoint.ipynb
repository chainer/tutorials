{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CE_CacxQ7q7t"
   },
   "source": [
    "# 機械学習に使われる数学\n",
    "\n",
    "次章より 3 つの章にわたって、ディープラーニングを含む機械学習に必要な数学のうち、基礎的なものとして「微分」「線形代数」「確率統計」の 3 つについて、要点を絞り、簡潔に紹介していきます。\n",
    "\n",
    "その前に、本章では**機械学習 (machine learning)** の考え方について大枠を掴み、そのどの部分でそれぞれの項目が登場するかを把握しておきましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yfsQqK7V7q7v"
   },
   "source": [
    "## 機械学習の考え方\n",
    "\n",
    "機械学習とは、与えられたデータから、未知のデータに対しても当てはまる規則やパターンを抽出したり、それらを元に未知のデータを分類したり、予測したりするための手法等を研究する学術領域です。\n",
    "機械学習は様々な技術に応用されており、例えば画像認識、音声認識、文書分類、医療診断、迷惑メール検知、商品推薦など、幅広い分野で重要な役割を果たしています。\n",
    "\n",
    "![訓練と推論](images/03/03_01.png)\n",
    "\n",
    "与えられたデータ（**訓練データ (training data)**）から、未知のデータ（**テストデータ (test data)** ）に対しても当てはまる規則やパターンを抽出したり、抽出されたパターンを使って、データを人間にとって意味のあるカテゴリに分類するための関数を得ることを**訓練**と呼びます。\n",
    "訓練によって獲得される関数（**モデル**とも呼ばれます）は多くの場合**パラメータ**と呼ばれる数値の集合によって特徴づけられています。\n",
    "\n",
    "訓練においては、予測のための要因となる**入力変数 (input variable)** $x$ [<sup>*1</sup>](#fn1) と**教師データ (supervised data)** $t$ [<sup>*2</sup>](#fn2)　が必要となります。\n",
    "その与えられた入力変数と教師データに基づいて、その関係性をうまく表すようなモデルを構築します。\n",
    "そして、訓練後のモデルは**訓練済みモデル**と呼ばれ、この訓練済みモデルを用いた予測値を求めることを**推論 (inference)** と呼びます。\n",
    "本チュートリアルでは、主に訓練について扱いますが、実運用を行う際には推論に対するシステム構築のノウハウも重要となります。\n",
    "\n",
    "単純な例として、直線の方程式を考えてみましょう。\n",
    "これは、傾き $a$ と切点 $b$ の２つのパラメータで \n",
    "\n",
    "$$\n",
    "f(x) = ax + b\n",
    "$$\n",
    "\n",
    "と表されます。\n",
    "さらに厳密には、\n",
    "\n",
    "$$\n",
    "f(x; a, b) = ax + b\n",
    "$$\n",
    "\n",
    "と表記されます。\n",
    "これは、「 $;$ 」の後ろに書かれているパラメータ（ここでは $a, b$ ）によって特徴づけられ、一つの入力 $x$ を与えると一つの出力 $y$ を返す関数 $f$ という意味です。\n",
    "機械学習の目標は、訓練データを用いてこれらのパラメータを最適な値へ決定することです。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u704l9iO7q7w"
   },
   "source": [
    "## 目的関数\n",
    "\n",
    "機械学習では訓練データに基づいてパラメータを最適な値へと調整を行います。\n",
    "さて、最適な値というともっともらしく感じますが、「何」に対する最適なのでしょうか。\n",
    "その答えが**目的関数 (objective function)** です。\n",
    "\n",
    "機械学習では、多くの場合、目的関数と呼ばれるものをモデルとは別に用意し、これを**最小化**（もしくは**最大化**）するようにモデルのパラメータを決定することによって、そのモデルが望ましい働きをするように訓練します。\n",
    "そのため、目的関数はモデルの出力値が望ましい場合には小さな値をとり、そうでない場合は大きな値をとるように設計します。\n",
    "\n",
    "例えば、学習データとして2次元空間上の点を $N$ 個集めたデータセット $D = \\left\\{ (x_1, t_1), (x_2, t_2), \\ldots, (x_N, t_N) \\right\\}$ が与えられたとします。\n",
    "ここで、 $x_{n}$ は $n$ 番目の入力変数、 $t_{n}$ は $n$ 番目の教師データに対応しています。\n",
    "これらの点の近くをできる限り通るような直線 \n",
    "$$y = f(x; a, b) = ax + b$$\n",
    "を見つけたいというとき、どのような目的関数を採用すると良いでしょうか。\n",
    "ここで、今後はパラメータを $\\theta$ でまとめて表記することにします。\n",
    "例えば、今考えている直線フィッティングの例では、$\\theta = (a, b)$ となり、これを用いて表される直線の方程式を $y = f(x; \\theta)$ と表記します。\n",
    "\n",
    "教師データと予測値の差が小さいほど望ましいということを表す目的関数を考えてみましょう。\n",
    "例えば、\n",
    "\n",
    "$$\n",
    "t_{n} - y_{n}\n",
    "$$\n",
    "\n",
    "のような単純な差を利用するのはどうでしょうか。\n",
    "さらに、$n$ 番目のサンプルだけに着目するのではなく、データセット内の $N$ 個のサンプル全ての差を足したものを考えてみます。\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "L(\\theta) &= (t_{1} - y_{1}) + (t_{2} - y_{2}) + \\cdots + (t_{N} - y_{N}) \\\\\n",
    "&= \\sum_{n=1}^{N} (t_{n} - y_{n})\n",
    "\\end{aligned}\n",
    "$$\n",
    "のようにすべてのサンプルの総和とします。\n",
    "ここで、$L (\\theta)$ は目的関数を表し、パラメータ $\\theta$ によって目的関数の値に影響があるため、$\\theta$ が変数となっています。\n",
    "ただし、この場合だと、差分が正の値と負の値の両方が取られるため、各サンプル間で打ち消し合ってしまうことが懸念されます。\n",
    "\n",
    "ここで、$L (\\theta)$ は目的関数を表し、その値がパラメータ $\\theta$ によって影響を受けるため、$\\theta$ を引数として取っています。\n",
    "しかし、この目的関数は実際にはうまく働きません。\n",
    "なぜなら、この目的関数は、教師データがどのような値であれ、予測値を無限に大きくしていくことでもその出力を小さくすることができてしまい、教師データと予測値の差が小さいときに**だけ**値が小さくなるような関数になっていないためです。\n",
    "\n",
    "そこで、各サンプルごとの予測値と教師データの間の**差の二乗**を足し合わせていく\n",
    "\n",
    "$$\n",
    "L(\\theta) = \\sum_{n=1}^N (t_n - y_{n})^2\n",
    "$$\n",
    "\n",
    "を目的関数に採用します。\n",
    "この関数は一般に**二乗和誤差 (squared error)** と呼ばれます。\n",
    "二乗ではなく絶対値でも良いように思いますが、数学的な取扱いやすさの観点で二乗することが多いです。\n",
    "\n",
    "さて、この関数を最小化するとはどういうことかを考えてみましょう。\n",
    "上式は、モデルの予測値 $y_{n}$ と教師データ $t_n$ との差の二乗を各データ点（データセット内のひとつのデータ）についてそれぞれ求め、そのデータセット全体に渡る合計値を計算しています。\n",
    "このため、$L(\\theta)$ の値は全てのデータ点に対する予測が対応する教師データと**一致した場合にだけ** $0$ となり、それ以外は予測のはずれ具合に応じた正の値をとります[<sup>*3</sup>](#fn3)。\n",
    "この目的関数を最小化する最適な $\\theta$ を求めることで、データセット $D$ に含まれる点の $x$ の値 $x_n$ $(n=1, 2, \\dots, N)$ から、その教師データの値 $t_n$ $(n=1, 2, \\dots, N)$ を精度良く予測する関数 $y = f(x; \\theta)$ が得られることになります。\n",
    "\n",
    "そして、目的関数の最小化問題を理解するために、**微分**の知識が役に立ちます。\n",
    "また、機械学習では 1 つの変数だけでなく、上の例でパラメータとして 2 つの値が登場したように、複数の変数を扱う必要がある場合が多く、そのようなときに**線形代数**の知識が役に立ちます。\n",
    "さらに、各入力変数ごとの値のスケールを統一したり、外れ値除去などの機械学習でよく行われるデータに対する操作を理解するには、**統計**の知識が役に立ちます。\n",
    "しかし、大学で学ぶような微分、線形代数、統計に関する全ての知識が必要なわけではありません。\n",
    "ここでは、機械学習を学び始める前に必要となる最低限の知識に絞って、微分や線形代数、確率・統計といった分野から、要点のみを解説します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr />\n",
    "<span id=\"fn1\"><sup>*1</sup>: <small>*特徴量変換を施した場合、**特徴量** と呼ぶこともありますが、本チュートリアルでは特徴量も含め、入力変数という呼び名で統一することとします。</small></span>\n",
    "\n",
    "<span id=\"fn2\"><sup>*2</sup>: <small>*厳密には **目標値 (target value)** として観測されたデータを教師データと呼びますが、説明をシンプルにするために、すべて教師データで統一して紹介しています。$t$ は target value から由来しています。また、教師データが必要となるケースは機械学習の中でも教師あり学習に限られますが、本チュートリアルでは教師あり学習を中心に扱うため、機械学習の一般的な考え方を教師あり学習を中心に紹介しています。</small></span>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "03_Basics_of_Math_for_Machine_Learning_ja.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
