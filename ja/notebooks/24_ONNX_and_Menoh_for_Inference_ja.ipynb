{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "colab_type": "text",
                "id": "n3uYk8aaZh8k"
            },
            "source": [
                "# 様々な環境での推論: ONNX と Menoh の活用\n",
                "\n",
                "これまでの章では、Chainer を用いた学習済みモデルの作成方法・推論の実行方法を解説しました。\n",
                "\n",
                "しかし、実務においては Chainer で作成した学習済みモデルをそのまま推論に用いることが難しい場面もあります。\n",
                "例えば、Ruby や Java など Python 以外の言語で実装された既存の Web アプリケーションに推論機能を組み込みたい場合や、モバイルデバイス上で推論を行いたい場合、Chainer（Python）で実装された学習済みモデルを直接実行するのは困難です。\n",
                "\n",
                "そこで本章では、Chainer の学習済みモデルを ONNX（オニキス）と呼ばれる形式に変換することで、異なるフレームワークを使用して推論を実行する方法について解説します。\n",
                "また、Menoh（メノウ）というフレームワークを使用して、ONNX 形式の学習済みモデルを様々なプログラミング言語で推論する方法もご紹介します。"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "colab_type": "text",
                "id": "zTnwNprg0ZLP"
            },
            "source": [
                "## ONNX とは？\n",
                "\n",
                "ONNX は **Open Neural Network eXchange** の略で、深層学習の学習済みモデルを様々なフレームワーク間で相互に交換するためのファイルフォーマット（形式）です。\n",
                "\n",
                "学習済みモデルを ONNX 形式に変換することで、あるフレームワークで訓練したモデルを別のフレームワークでの推論に使用できるようになります。また、代表的な手法の学習済みモデルは [ONNX Model Zoo](https://github.com/onnx/models) で公開されており、ダウンロードしてそのまま使用することも可能です。"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "colab_type": "text",
                "id": "B06Z0MwRZh4C"
            },
            "source": [
                "### ONNX のサポート状況\n",
                "\n",
                "数多くの深層学習フレームワークが ONNX をサポートしています。\n",
                "最新の対応状況は [ONNX の GitHub ページ](https://github.com/onnx/tutorials) から確認することができます。\n",
                "2019年2月現在のサポート状況は下記の通りです。\n",
                "\n",
                "<!--\n",
                "表の作成手順:\n",
                "\n",
                "1. https://raw.githubusercontent.com/onnx/tutorials/989599017f3eb9846a4dd593b85427babf233eef/README.md からテーブルをコピー\n",
                "2. 本章で使用する Chainer, Menoh, Caffe2 を先頭に移動\n",
                "3. ヘッダ行を日本語化\n",
                "   (Framework / tool | Installation | Exporting to ONNX (frontend) | Importing ONNX models (backend))\n",
                "-->\n",
                "\n",
                "| フレームワーク/ツール | インストール方法 | エクスポート | インポート |\n",
                "| --- | --- | --- | --- |\n",
                "| [Chainer](https://chainer.org/) | [chainer/onnx-chainer](https://github.com/chainer/onnx-chainer) | [Exporting](tutorials/ChainerOnnxExport.ipynb) | coming soon |\n",
                "| [Menoh](https://github.com/pfnet-research/menoh) | [pfnet-research/menoh](https://github.com/pfnet-research/menoh) | n/a | [Importing](tutorials/OnnxMenohHaskellImport.ipynb) |\n",
                "| [Caffe2](http://caffe2.ai) | [part of caffe2 package](https://github.com/pytorch/pytorch/tree/master/caffe2/python/onnx) | [Exporting](tutorials/Caffe2OnnxExport.ipynb) | [Importing](tutorials/OnnxCaffe2Import.ipynb) |\n",
                "| [PyTorch](http://pytorch.org/) | [part of pytorch package](http://pytorch.org/docs/master/onnx.html) | [Exporting](tutorials/PytorchOnnxExport.ipynb), [Extending support](tutorials/PytorchAddExportSupport.md) | coming soon |\n",
                "| [Cognitive Toolkit (CNTK)](https://www.microsoft.com/en-us/cognitive-toolkit/) | [built-in](https://docs.microsoft.com/en-us/cognitive-toolkit/setup-cntk-on-your-machine) | [Exporting](tutorials/CntkOnnxExport.ipynb) | [Importing](tutorials/OnnxCntkImport.ipynb) |\n",
                "| [Apache MXNet](http://mxnet.incubator.apache.org/) | part of mxnet package [docs](http://mxnet.incubator.apache.org/api/python/contrib/onnx.html) [github](https://github.com/apache/incubator-mxnet/tree/master/python/mxnet/contrib/onnx) | [Exporting](tutorials/MXNetONNXExport.ipynb) | [Importing](tutorials/OnnxMxnetImport.ipynb) |\n",
                "| [TensorFlow](https://www.tensorflow.org/) | [onnx/onnx-tensorflow](https://github.com/onnx/onnx-tensorflow) and [onnx/tensorflow-onnx](https://github.com/onnx/tensorflow-onnx) | [Exporting](tutorials/OnnxTensorflowExport.ipynb) | [Importing](tutorials/OnnxTensorflowImport.ipynb) [experimental] |\n",
                "| [Apple CoreML](https://developer.apple.com/documentation/coreml) | [onnx/onnx-coreml](https://github.com/onnx/onnx-coreml) and [onnx/onnxmltools](https://github.com/onnx/onnxmltools) | [Exporting](https://github.com/onnx/onnxmltools) | [Importing](tutorials/OnnxCoremlImport.ipynb) |\n",
                "| [SciKit-Learn](http://scikit-learn.org/) | [onnx/onnxmltools](https://github.com/onnx/onnxmltools) | [Exporting](https://github.com/onnx/onnxmltools) | n/a |\n",
                "| [ML.NET](https://github.com/dotnet/machinelearning/) | [built-in](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.models.onnxconverter.convert?view=ml-dotnet#definition) | [Exporting](https://github.com/dotnet/machinelearning/blob/master/test/Microsoft.ML.Tests/OnnxTests.cs) | [Importing](https://github.com/dotnet/machinelearning/blob/master/test/Microsoft.ML.OnnxTransformTest/OnnxTransformTests.cs#L186) |\n",
                "| [MATLAB](https://www.mathworks.com/) | [onnx converter on matlab central file exchange](https://www.mathworks.com/matlabcentral/fileexchange/67296) | [Exporting](https://www.mathworks.com/help/deeplearning/ref/exportonnxnetwork.html) | [Importing](https://www.mathworks.com/help/deeplearning/ref/importonnxnetwork.html) |\n",
                "| [TensorRT](https://developer.nvidia.com/tensorrt) | [onnx/onnx-tensorrt](https://github.com/onnx/onnx-tensorrt) | n/a | [Importing](https://github.com/onnx/onnx-tensorrt/blob/master/README.md) |\n",
                "\n",
                "エクスポートとは、そのフレームワークで作成した学習済みモデルを ONNX 形式に変換できることを表します。\n",
                "また、インポートとは、そのフレームワークが ONNX 形式の学習済みモデルを読み込んで推論を実行できることを表します。\n",
                "\n",
                "Chainer は、現時点ではエクスポートのみに対応しています。\n",
                "インポートについても今後サポートが予定されています。\n",
                "\n",
                "なお、学習済みモデルで使用している関数が ONNX 形式でサポートされていない場合は、エクスポートすることができません。\n",
                "サポートされている関数の一覧は [ONNX の公式ドキュメント](https://github.com/onnx/onnx/blob/master/docs/Operators.md)で確認することができます。\n",
                "また、ONNX 形式でサポートされている関数であっても、フレームワークによってはエクスポート/インポートに制約がある場合があります。\n",
                "詳しくは各フレームワークの ONNX に関するドキュメント（例: [Chainer](https://github.com/chainer/onnx-chainer#supported-functions)、[PyTorch](https://pytorch.org/docs/stable/onnx.html#supported-operators)）を確認してください。"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "colab_type": "text",
                "id": "kTE1H_ED0IBE"
            },
            "source": [
                "## Chainer の学習済みモデルを ONNX 形式に変換する\n",
                "\n",
                "Chainer の学習済みモデルを ONNX 形式に変換する方法を解説します。\n",
                "\n",
                "今回は Chainer にデフォルトで用意されている、VGG16 の学習済みモデルを使用します。"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {
                "colab": {},
                "colab_type": "code",
                "id": "eaJC6WzxeGeN"
            },
            "outputs": [],
            "source": [
                "import chainer\n",
                "import chainer.functions as F\n",
                "import chainer.links as L"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/",
                    "height": 71
                },
                "colab_type": "code",
                "executionInfo": {
                    "elapsed": 47282,
                    "status": "ok",
                    "timestamp": 1548311998706,
                    "user": {
                        "displayName": "西沢衛",
                        "photoUrl": "",
                        "userId": "12011220225445512117"
                    },
                    "user_tz": -540
                },
                "id": "yC9WUiiSeltC",
                "outputId": "af0c02b6-b1cc-40e8-c5ce-16306c998f11"
            },
            "outputs": [],
            "source": [
                "# VGG16 モデルの読み込み\n",
                "model = L.VGG16Layers()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/",
                    "height": 391
                },
                "colab_type": "code",
                "executionInfo": {
                    "elapsed": 47256,
                    "status": "ok",
                    "timestamp": 1548311998706,
                    "user": {
                        "displayName": "西沢衛",
                        "photoUrl": "",
                        "userId": "12011220225445512117"
                    },
                    "user_tz": -540
                },
                "id": "wMd8QwycepcN",
                "outputId": "64eb1600-ffff-4a5f-b561-38334e35e335"
            },
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "['conv1_1',\n",
                            " 'conv1_2',\n",
                            " 'pool1',\n",
                            " 'conv2_1',\n",
                            " 'conv2_2',\n",
                            " 'pool2',\n",
                            " 'conv3_1',\n",
                            " 'conv3_2',\n",
                            " 'conv3_3',\n",
                            " 'pool3',\n",
                            " 'conv4_1',\n",
                            " 'conv4_2',\n",
                            " 'conv4_3',\n",
                            " 'pool4',\n",
                            " 'conv5_1',\n",
                            " 'conv5_2',\n",
                            " 'conv5_3',\n",
                            " 'pool5',\n",
                            " 'fc6',\n",
                            " 'fc7',\n",
                            " 'fc8',\n",
                            " 'prob']"
                        ]
                    },
                    "execution_count": 21,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# VGG16 のアーキテクチャーの確認\n",
                "model.available_layers"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "colab_type": "text",
                "id": "LNRb5jV5WvP8"
            },
            "source": [
                "ONNX 形式への変換には `onnx-chainer` パッケージを使用します。  \n",
                "`onnx-chainer` は `pip` を使用してインストールすることができます。"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/",
                    "height": 445
                },
                "colab_type": "code",
                "executionInfo": {
                    "elapsed": 55618,
                    "status": "ok",
                    "timestamp": 1548312007078,
                    "user": {
                        "displayName": "西沢衛",
                        "photoUrl": "",
                        "userId": "12011220225445512117"
                    },
                    "user_tz": -540
                },
                "id": "sjeTaX3RXjyf",
                "outputId": "deb1ae02-fddc-4070-dbf2-aca042d71907"
            },
            "outputs": [],
            "source": [
                "!pip install onnx-chainer"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {
                "colab": {},
                "colab_type": "code",
                "id": "0ls46NvyWvVM"
            },
            "outputs": [],
            "source": [
                "import onnx_chainer"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "colab_type": "text",
                "id": "qliA5FHxlM0h"
            },
            "source": [
                "Chainer は **Define-by-Run** というスタイルを採用しているため、ネットワーク構造は実際にデータを渡してフォワード（順伝播）計算を行うことで確定します。\n",
                "（Define-by-Run は Chainer のコアコンセプトの１つであり、ネットワーク構造をフォワード計算をしながら定義することを指します。\n",
                "このコンセプトによって、複雑なモデルをより少ないコード量で構築できる、デバックが容易になる、といったメリットがあります。）\n",
                "\n",
                "ONNX 形式へ変換するためにはネットワーク構造が確定している必要があるため、ダミーの入力データを用意してフォワード計算を行います。\n",
                "ダミーデータには、実際の推論に用いるデータと同じ `shape` の入力変数を使用します。\n",
                "VGG16 モデルは 224×224 の3チャンネルの画像を入力データとして想定しているため、以下のようにダミーデータを作成します。"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/",
                    "height": 34
                },
                "colab_type": "code",
                "executionInfo": {
                    "elapsed": 55823,
                    "status": "ok",
                    "timestamp": 1548312007297,
                    "user": {
                        "displayName": "西沢衛",
                        "photoUrl": "",
                        "userId": "12011220225445512117"
                    },
                    "user_tz": -540
                },
                "id": "vmym_1HqiuPK",
                "outputId": "9fa27d15-8adb-4973-e074-999452ede276"
            },
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "(1, 3, 224, 224)"
                        ]
                    },
                    "execution_count": 24,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# ダミーデータの準備\n",
                "import numpy as np\n",
                "x = np.zeros((1, 3, 224, 224), dtype=np.float32)\n",
                "x.shape"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Chainer を推論モードに切り替え、学習済みモデル `model` に対してダミーデータ `x` を渡してネットワーク構造を確定させた後、ONNX 形式のファイルとして出力します。"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {
                "colab": {},
                "colab_type": "code",
                "id": "VJXz95jfWvaJ"
            },
            "outputs": [],
            "source": [
                "# 推論モードに切り替え\n",
                "chainer.config.train = False\n",
                "\n",
                "# ONNX 形式に変換する\n",
                "onnx_model = onnx_chainer.export(model, x, filename='convnet.onnx')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/",
                    "height": 34
                },
                "colab_type": "code",
                "executionInfo": {
                    "elapsed": 66022,
                    "status": "ok",
                    "timestamp": 1548312017506,
                    "user": {
                        "displayName": "西沢衛",
                        "photoUrl": "",
                        "userId": "12011220225445512117"
                    },
                    "user_tz": -540
                },
                "id": "emlaV9PtWvkH",
                "outputId": "ccb32699-025d-4dcf-c21b-48d6dbe69fd2",
                "scrolled": true
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "convnet.onnx\r\n"
                    ]
                }
            ],
            "source": [
                "# 出力されたファイルの確認\n",
                "!ls convnet.onnx"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "colab_type": "text",
                "id": "oG7DLMBXQFJ7"
            },
            "source": [
                "これで、学習済みモデルを ONNX 形式のファイルに変換することができました。  "
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "colab_type": "text",
                "id": "oG7DLMBXQFJ8"
            },
            "source": [
                "## ONNX 形式のモデルを Caffe2 で推論する\n",
                "\n",
                "続けて、先ほど変換した ONNX 形式の学習済みモデルファイルを [Caffe2](https://caffe2.ai/) フレームワークで読み込み、推論を行います。\n",
                "\n",
                "まず、Caffe2 とその依存モジュールをインストールします。"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/",
                    "height": 377
                },
                "colab_type": "code",
                "executionInfo": {
                    "elapsed": 165297,
                    "status": "ok",
                    "timestamp": 1548312116791,
                    "user": {
                        "displayName": "西沢衛",
                        "photoUrl": "",
                        "userId": "12011220225445512117"
                    },
                    "user_tz": -540
                },
                "id": "fAyfxVuyqGXq",
                "outputId": "5794c166-6e3f-4dd9-ba8a-63cd1fa3d494"
            },
            "outputs": [],
            "source": [
                "# Caffe2 (PyTorch の一部) のインストール\n",
                "!pip install torch\n",
                "\n",
                "# Caffe2 の依存モジュールのインストール\n",
                "!pip install onnx future"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "colab_type": "text",
                "id": "Glbk0VW6wwDP"
            },
            "source": [
                "### Caffe2 に ONNX モデルを読み込む\n",
                "\n",
                "Caffe2 に ONNX モデルを読み込みます。"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {
                "colab": {},
                "colab_type": "code",
                "id": "kkSrkmm54zpy"
            },
            "outputs": [],
            "source": [
                "# 保存された ONNX モデルの読み込み\n",
                "import onnx\n",
                "onnx_model = onnx.load('convnet.onnx')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "colab_type": "text",
                "id": "1rq_9V_RwomQ"
            },
            "source": [
                "### 読み込んだ ONNX モデルを使用して推論する\n",
                "\n",
                "ここでは乱数データを入力にして推論を行います（実際には、入力として 224×224 の3チャンネル画像を使用します）。"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {
                "colab": {},
                "colab_type": "code",
                "id": "-OC5BCce40C9"
            },
            "outputs": [],
            "source": [
                "# 推論の準備を行う\n",
                "from caffe2.python.onnx import backend\n",
                "prepared_backend = backend.prepare(onnx_model)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {
                "colab": {},
                "colab_type": "code",
                "id": "7ghONkv-lKbq"
            },
            "outputs": [],
            "source": [
                "# ダミーの入力データを用意\n",
                "x = np.random.randn(1, 3, 224, 224).astype(np.float32)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/",
                    "height": 34
                },
                "colab_type": "code",
                "executionInfo": {
                    "elapsed": 165898,
                    "status": "ok",
                    "timestamp": 1548312117394,
                    "user": {
                        "displayName": "西沢衛",
                        "photoUrl": "",
                        "userId": "12011220225445512117"
                    },
                    "user_tz": -540
                },
                "id": "q80GZx31H92W",
                "outputId": "c5feffd1-1813-4c19-dfb5-79be8c484ea8"
            },
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "(1, 3, 224, 224)"
                        ]
                    },
                    "execution_count": 31,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "x.shape"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {
                "colab": {},
                "colab_type": "code",
                "id": "hI3lfFzp5LM-"
            },
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "Outputs(Softmax_0=array([[2.14816275e-04, 1.08164025e-03, 4.11246932e-04, 8.18778411e-04,\n",
                            "        1.71566370e-03, 1.44439552e-03, 5.13035618e-03, 1.90243445e-04,\n",
                            "        1.06249157e-04, 1.54615147e-04, 4.11179295e-04, 2.20485352e-04,\n",
                            "        4.23722464e-04, 9.20125283e-04, 2.28955381e-04, 1.86870879e-04,\n",
                            "        3.95452895e-04, 1.71444262e-04, 4.76445537e-04, 4.93705564e-04,\n",
                            "        5.74271311e-04, 8.71971250e-04, 5.73325728e-04, 3.74813128e-04,\n",
                            "        1.26666389e-04, 8.78053252e-05, 6.43608335e-04, 3.97719909e-04,\n",
                            "        6.98198928e-05, 1.76480913e-03, 1.18460186e-04, 2.65453738e-04,\n",
                            "        1.50202672e-04, 1.38622615e-03, 2.58962763e-03, 3.39274702e-04,\n",
                            "        7.36668706e-04, 1.87365469e-04, 1.46729185e-03, 3.18095059e-04,\n",
                            "        7.21398508e-04, 3.76959128e-04, 4.75917652e-04, 3.02988483e-04,\n",
                            "        3.80057172e-04, 1.58852024e-03, 5.70400036e-04, 6.88131899e-04,\n",
                            "        8.37533094e-04, 7.47749116e-04, 1.19529001e-03, 2.85340007e-04,\n",
                            "        8.71164957e-04, 1.51232968e-03, 6.65602158e-04, 2.81423825e-04,\n",
                            "        5.79039857e-04, 1.45970611e-04, 5.86787611e-03, 3.61611135e-04,\n",
                            "        1.43792958e-03, 7.10567576e-04, 7.78600923e-04, 5.47229603e-04,\n",
                            "        1.32967916e-03, 1.23114802e-03, 1.86032755e-03, 1.28275470e-03,\n",
                            "        1.32651080e-03, 2.59720813e-03, 1.04598084e-03, 2.07768334e-03,\n",
                            "        6.17296202e-04, 1.79666700e-03, 8.01361341e-04, 3.26533173e-03,\n",
                            "        2.00592494e-03, 2.24487716e-03, 3.59052420e-03, 3.06862826e-03,\n",
                            "        8.35053565e-04, 1.00972608e-03, 6.24692126e-04, 8.96983664e-04,\n",
                            "        1.75330279e-04, 1.57310208e-03, 1.03183673e-03, 1.94269035e-03,\n",
                            "        1.64769677e-04, 6.24805631e-04, 4.80240014e-05, 1.92994034e-04,\n",
                            "        5.36365318e-04, 3.17703059e-04, 6.04177709e-04, 5.28337114e-05,\n",
                            "        3.87105421e-04, 1.38645162e-04, 9.83703183e-04, 5.11445745e-04,\n",
                            "        2.59576453e-04, 4.83172102e-04, 2.78937398e-04, 1.01427373e-03,\n",
                            "        4.92590945e-04, 1.37420153e-04, 4.90972889e-04, 3.63669562e-04,\n",
                            "        3.63063475e-04, 2.36490116e-04, 4.84008924e-05, 1.27091829e-03,\n",
                            "        7.81077077e-04, 3.55530210e-04, 3.52347881e-04, 1.76401736e-05,\n",
                            "        8.70111326e-05, 1.05786661e-03, 3.76932498e-04, 2.10816594e-04,\n",
                            "        1.05515518e-03, 5.06510951e-05, 1.19413417e-04, 1.25749590e-04,\n",
                            "        1.01732241e-03, 1.33490190e-03, 8.91477510e-04, 7.13645015e-04,\n",
                            "        7.70700222e-04, 3.80892976e-04, 1.64688463e-04, 5.26275835e-04,\n",
                            "        9.69035784e-04, 4.44398582e-04, 5.07477263e-04, 8.68993448e-05,\n",
                            "        2.40759211e-04, 1.60738477e-03, 2.07179901e-03, 4.30585409e-04,\n",
                            "        1.38523371e-03, 2.38477835e-03, 1.58889533e-03, 6.35211356e-04,\n",
                            "        3.13778233e-04, 4.55656234e-04, 8.58216838e-04, 1.02839876e-04,\n",
                            "        2.60519329e-04, 8.71828641e-04, 3.81170947e-04, 8.95630161e-04,\n",
                            "        1.34385147e-04, 2.49051559e-03, 7.14911323e-04, 5.62168483e-04,\n",
                            "        3.74261435e-04, 4.57183400e-04, 4.40864125e-04, 4.72339219e-04,\n",
                            "        1.92229709e-04, 7.31121341e-04, 9.12459509e-04, 4.24294034e-04,\n",
                            "        3.59804108e-04, 1.25566192e-04, 3.98291158e-04, 1.30377739e-04,\n",
                            "        4.65802121e-04, 2.11863357e-04, 5.71802258e-04, 1.75155094e-03,\n",
                            "        2.14496604e-03, 4.93748172e-04, 3.98617587e-04, 1.13371789e-04,\n",
                            "        1.95347777e-04, 3.13030003e-04, 1.52678788e-03, 7.43641518e-04,\n",
                            "        6.55228563e-04, 3.29224305e-04, 7.76938279e-04, 1.43901882e-04,\n",
                            "        5.73503959e-04, 2.74890743e-04, 3.50347487e-04, 3.75469623e-04,\n",
                            "        1.69159321e-04, 2.86146620e-04, 3.44399828e-04, 2.95936741e-04,\n",
                            "        1.04402227e-03, 1.95252782e-04, 1.17750365e-04, 6.02545333e-04,\n",
                            "        4.11416026e-04, 1.63129458e-04, 1.43568366e-04, 6.02396729e-04,\n",
                            "        1.59146613e-04, 1.56067021e-04, 1.01558585e-03, 3.36071895e-03,\n",
                            "        1.73949928e-03, 9.42767219e-05, 1.15901988e-04, 3.23744025e-04,\n",
                            "        3.65389889e-04, 1.94013899e-03, 1.58222203e-04, 5.14693675e-04,\n",
                            "        4.34540241e-04, 1.18452386e-04, 9.66589359e-05, 5.17826760e-04,\n",
                            "        9.14476186e-05, 4.23179299e-04, 2.49373348e-04, 1.41778670e-04,\n",
                            "        8.24966410e-05, 1.69498599e-04, 6.37774123e-04, 4.56058391e-04,\n",
                            "        1.02445338e-04, 4.73120512e-04, 2.34172883e-04, 2.83013796e-04,\n",
                            "        2.32994920e-04, 7.58262991e-04, 9.76182986e-04, 3.76830809e-04,\n",
                            "        1.74031127e-04, 2.50658253e-04, 3.04691144e-04, 1.95782617e-04,\n",
                            "        4.22688434e-04, 1.16875232e-03, 6.54741074e-04, 3.82447761e-04,\n",
                            "        1.55051181e-04, 2.48426601e-04, 7.10512337e-04, 3.12341755e-04,\n",
                            "        5.61625930e-05, 1.12351275e-03, 3.58099700e-04, 1.77550944e-04,\n",
                            "        2.91620265e-04, 3.39094346e-04, 6.03158143e-04, 4.82092786e-04,\n",
                            "        1.21044992e-04, 5.76492806e-04, 7.21119228e-04, 4.93631887e-05,\n",
                            "        1.39100346e-04, 9.05711029e-04, 3.23746982e-03, 7.86908902e-04,\n",
                            "        2.45201227e-04, 2.23271345e-04, 6.14232558e-05, 9.29901318e-04,\n",
                            "        6.21424115e-04, 1.12974225e-03, 4.43216239e-04, 1.64352547e-04,\n",
                            "        4.89648664e-04, 1.49313899e-04, 4.65759018e-04, 1.81807569e-04,\n",
                            "        6.85841485e-04, 1.16714719e-03, 2.59147055e-04, 3.07785405e-04,\n",
                            "        1.55997020e-03, 4.16582770e-04, 3.60322971e-04, 1.71888142e-03,\n",
                            "        5.35062340e-04, 8.64531845e-04, 6.42197556e-04, 1.44681183e-03,\n",
                            "        2.27450812e-03, 9.06150788e-04, 4.89010534e-04, 6.76374708e-04,\n",
                            "        1.96544002e-04, 2.18993620e-04, 7.64983051e-05, 5.42179041e-04,\n",
                            "        9.80383120e-05, 3.51342082e-04, 1.20028359e-04, 1.04827865e-04,\n",
                            "        5.59179520e-04, 2.66739720e-04, 9.64292209e-04, 9.07048234e-04,\n",
                            "        1.21633355e-04, 5.92368655e-04, 2.14218497e-04, 3.70102847e-04,\n",
                            "        1.31539287e-04, 8.12694489e-04, 3.52554431e-04, 3.17755330e-04,\n",
                            "        2.40641675e-04, 4.62216194e-05, 1.85671542e-03, 7.71202787e-04,\n",
                            "        1.40598102e-03, 2.44777743e-03, 5.14258025e-03, 1.51319464e-03,\n",
                            "        7.28428306e-04, 2.16137909e-04, 1.66851189e-03, 1.69851235e-03,\n",
                            "        3.01834283e-04, 5.92037723e-05, 1.94124936e-04, 6.33022792e-05,\n",
                            "        1.71044070e-04, 9.92752975e-05, 1.79632814e-04, 8.67696654e-04,\n",
                            "        3.33962642e-04, 2.32003353e-04, 1.52532419e-03, 9.03096749e-04,\n",
                            "        7.68092519e-04, 9.52813367e-04, 3.01622233e-04, 1.01739177e-04,\n",
                            "        1.23303733e-04, 2.81877903e-04, 3.10424890e-04, 6.34679018e-05,\n",
                            "        2.76521721e-04, 1.69010324e-04, 1.93986416e-04, 4.69783059e-04,\n",
                            "        5.89127303e-04, 1.11783658e-04, 5.75544953e-04, 2.31128273e-04,\n",
                            "        1.20918659e-04, 3.14404431e-04, 7.83406838e-04, 4.92400955e-04,\n",
                            "        2.73513433e-04, 6.20787905e-04, 5.99549443e-04, 9.66482476e-05,\n",
                            "        6.33823220e-04, 1.87732832e-04, 6.85165869e-04, 1.12881593e-03,\n",
                            "        2.88129057e-04, 6.66295644e-04, 5.89113799e-04, 2.65039434e-03,\n",
                            "        1.15639938e-04, 1.75158959e-04, 1.03989973e-04, 3.16526945e-04,\n",
                            "        8.17829787e-05, 7.45510406e-05, 1.99282847e-04, 2.80932843e-04,\n",
                            "        1.17065955e-03, 2.53520324e-04, 8.02753784e-04, 7.87837707e-05,\n",
                            "        1.94579421e-04, 5.40436013e-04, 2.62923306e-04, 7.07062354e-05,\n",
                            "        2.49809906e-04, 1.09487410e-04, 5.09168662e-04, 5.08956728e-04,\n",
                            "        2.82328256e-05, 5.65855706e-04, 1.03020936e-03, 7.22854747e-05,\n",
                            "        8.82065069e-05, 3.51417315e-04, 3.47668654e-04, 6.48530899e-04,\n",
                            "        7.40404721e-05, 1.39809883e-04, 3.36707802e-04, 1.45108276e-03,\n",
                            "        1.74430752e-04, 3.25324654e-04, 1.74211556e-04, 8.71967117e-04,\n",
                            "        6.68642897e-05, 2.14647327e-04, 2.36367210e-04, 1.65075529e-04,\n",
                            "        8.67298688e-04, 3.20445816e-03, 2.13643856e-04, 2.26501084e-04,\n",
                            "        9.55965297e-05, 6.89457811e-04, 9.86886735e-05, 7.77898764e-04,\n",
                            "        8.42808571e-04, 5.48048760e-04, 6.86327287e-04, 2.64903065e-04,\n",
                            "        5.65994123e-04, 2.99426005e-03, 3.37559567e-03, 8.50456394e-03,\n",
                            "        5.09355858e-04, 8.79385276e-04, 2.43351082e-04, 2.11725797e-04,\n",
                            "        2.37848202e-04, 1.37367926e-04, 9.47506982e-04, 2.96043989e-04,\n",
                            "        1.85224082e-04, 1.33332133e-03, 5.17203356e-04, 3.54236946e-03,\n",
                            "        3.25871166e-04, 9.09648312e-04, 4.66863345e-03, 3.31079145e-03,\n",
                            "        1.91280793e-04, 6.17106969e-04, 8.83053232e-04, 7.48594612e-05,\n",
                            "        2.97945633e-04, 7.11703557e-04, 4.61660471e-04, 2.60237395e-03,\n",
                            "        1.11682260e-04, 3.25524365e-04, 1.01043051e-02, 4.87664802e-04,\n",
                            "        5.09860809e-04, 9.51822512e-05, 6.74258394e-04, 2.33359053e-04,\n",
                            "        1.13012700e-03, 9.54323856e-04, 1.89842729e-04, 1.31313049e-03,\n",
                            "        8.08267505e-04, 4.77273919e-04, 1.61424268e-03, 1.89425645e-03,\n",
                            "        4.05765983e-04, 4.92028950e-04, 2.31156661e-03, 7.45097175e-04,\n",
                            "        3.48539121e-04, 1.69106096e-03, 4.33547015e-04, 3.32134441e-05,\n",
                            "        1.01391975e-04, 2.49777833e-04, 1.42642320e-03, 2.28584613e-04,\n",
                            "        9.19478771e-05, 9.78062511e-04, 1.13434892e-03, 1.08971668e-03,\n",
                            "        5.47202690e-05, 1.68997431e-04, 1.05372071e-02, 2.41512913e-04,\n",
                            "        4.65651788e-03, 1.50254683e-03, 1.90008912e-04, 6.61419472e-05,\n",
                            "        2.93859106e-04, 1.59929867e-03, 7.86286619e-05, 2.57003121e-03,\n",
                            "        2.31531551e-04, 4.17501316e-04, 3.42199404e-04, 2.24219184e-04,\n",
                            "        2.23490479e-03, 2.80975568e-04, 5.76247112e-04, 9.52336879e-04,\n",
                            "        4.56292881e-04, 1.54438370e-04, 3.17474973e-04, 2.11440586e-03,\n",
                            "        5.23917959e-04, 3.79327161e-04, 7.84998294e-04, 3.65843705e-04,\n",
                            "        1.51790061e-03, 7.03990809e-04, 3.49263952e-04, 3.62231891e-04,\n",
                            "        6.05989655e-04, 4.41717166e-05, 9.01905994e-04, 9.99491167e-05,\n",
                            "        3.88920453e-04, 1.32742003e-04, 1.69827617e-04, 1.34122733e-03,\n",
                            "        1.85900915e-03, 2.72066478e-04, 4.57226968e-04, 1.79466931e-03,\n",
                            "        4.59739752e-03, 6.76050026e-04, 1.54776470e-04, 7.03768572e-04,\n",
                            "        2.68624077e-04, 7.95167929e-04, 9.76887415e-04, 2.90399941e-04,\n",
                            "        4.46880556e-04, 2.24352628e-03, 5.03932300e-04, 3.40159953e-04,\n",
                            "        1.39658432e-03, 7.37652183e-04, 4.63205995e-03, 2.96016340e-04,\n",
                            "        5.54245125e-05, 1.89512328e-04, 2.70949071e-03, 3.12369899e-03,\n",
                            "        3.67459841e-04, 1.96531080e-04, 1.14474620e-03, 4.70440544e-04,\n",
                            "        1.49846557e-04, 9.40424297e-03, 1.32793604e-04, 2.40175777e-05,\n",
                            "        1.75355774e-04, 2.59218868e-02, 1.54480862e-04, 2.28076125e-03,\n",
                            "        5.38718559e-05, 2.01688381e-03, 1.26911968e-03, 8.55158796e-05,\n",
                            "        9.44718625e-03, 5.35433937e-04, 7.62003532e-04, 1.04343623e-03,\n",
                            "        2.58358137e-04, 2.92713317e-04, 1.06617263e-04, 1.30076951e-03,\n",
                            "        5.49311400e-04, 5.02015988e-04, 9.77975724e-05, 3.76891898e-04,\n",
                            "        2.03226809e-04, 1.62917553e-04, 9.82078840e-04, 1.64896934e-04,\n",
                            "        9.28154972e-04, 4.27107676e-04, 7.75376800e-04, 1.08859749e-04,\n",
                            "        7.37171504e-05, 8.80609732e-04, 2.69645097e-04, 2.61795387e-04,\n",
                            "        1.10577785e-04, 3.50612718e-05, 4.22174162e-05, 1.35543989e-03,\n",
                            "        4.71886073e-04, 8.02901632e-04, 2.88372481e-04, 8.38251901e-04,\n",
                            "        4.57394402e-03, 2.72675720e-03, 2.07882476e-04, 6.16972800e-03,\n",
                            "        6.68637513e-04, 4.89025377e-04, 2.88972340e-04, 1.22800717e-04,\n",
                            "        1.01862522e-03, 4.56738431e-04, 3.17133818e-04, 2.40173162e-04,\n",
                            "        1.68389990e-03, 1.73523778e-03, 2.51651421e-04, 1.91114217e-04,\n",
                            "        1.79738761e-03, 3.82843451e-03, 2.03609816e-03, 2.28335150e-04,\n",
                            "        2.25016702e-04, 1.95240966e-04, 5.33248903e-03, 5.05947566e-04,\n",
                            "        8.05918316e-05, 7.99975765e-04, 1.34038084e-04, 1.03072193e-03,\n",
                            "        6.39802136e-04, 4.12544614e-04, 2.17934046e-03, 3.13642714e-03,\n",
                            "        5.54495770e-03, 1.03200691e-04, 2.37394264e-03, 1.66409742e-03,\n",
                            "        2.33853425e-04, 2.54020793e-04, 1.33809471e-03, 1.16605501e-04,\n",
                            "        9.38270416e-04, 6.96782430e-04, 1.05498941e-03, 2.12147413e-03,\n",
                            "        1.33556209e-03, 6.40805112e-04, 1.05517480e-04, 4.70841595e-04,\n",
                            "        1.26203673e-03, 3.88371904e-04, 3.52130213e-04, 3.12019023e-04,\n",
                            "        1.51869620e-03, 3.65674146e-04, 9.57881275e-05, 2.82527442e-04,\n",
                            "        1.82955211e-03, 6.48388959e-05, 2.39461660e-03, 3.58054368e-03,\n",
                            "        1.75958348e-03, 2.85079150e-04, 7.78243062e-04, 2.01250310e-03,\n",
                            "        6.59287791e-04, 9.28709283e-04, 1.31174689e-04, 7.00485543e-04,\n",
                            "        3.25100118e-04, 1.25126226e-03, 2.41314454e-04, 2.59176712e-03,\n",
                            "        1.72605447e-04, 3.99880155e-05, 6.30655186e-03, 2.86059047e-04,\n",
                            "        5.23957948e-04, 1.81454016e-04, 1.39201549e-03, 1.93793472e-04,\n",
                            "        1.00208819e-03, 5.68458177e-02, 2.21734110e-04, 1.71587148e-04,\n",
                            "        5.37344255e-04, 1.61761302e-03, 2.64955894e-03, 3.30031122e-04,\n",
                            "        2.65255861e-04, 9.52629431e-04, 8.46717856e-04, 2.07887730e-04,\n",
                            "        2.38739164e-03, 2.08104099e-03, 6.53768948e-04, 3.90413799e-04,\n",
                            "        6.77371048e-04, 5.07983670e-04, 7.20085693e-04, 2.32756502e-04,\n",
                            "        6.17353013e-04, 4.05340164e-04, 9.75458970e-05, 1.07624591e-03,\n",
                            "        2.11533462e-03, 4.52652166e-04, 2.14148633e-04, 1.95762157e-04,\n",
                            "        9.13940079e-04, 2.96474725e-04, 1.02398262e-04, 1.83269847e-04,\n",
                            "        5.93708269e-03, 1.65959680e-03, 2.41882866e-04, 6.55932890e-05,\n",
                            "        8.29725352e-04, 6.65604020e-05, 5.32142294e-04, 3.36098572e-04,\n",
                            "        9.97936237e-04, 1.67972816e-03, 9.96339601e-04, 1.20338227e-03,\n",
                            "        1.03848483e-02, 1.00171631e-02, 1.02906895e-03, 4.94893000e-04,\n",
                            "        8.01724032e-04, 3.72124960e-05, 4.13038040e-04, 1.36432226e-03,\n",
                            "        1.43871689e-03, 2.46792589e-03, 2.02242937e-03, 3.89350753e-04,\n",
                            "        1.45368947e-04, 1.21815386e-03, 2.63304828e-04, 1.33860169e-03,\n",
                            "        2.27413280e-03, 1.05433841e-03, 1.96631474e-04, 3.13204317e-03,\n",
                            "        3.78054829e-04, 5.16090367e-04, 1.25131890e-04, 1.57897850e-03,\n",
                            "        1.38232586e-04, 4.23182122e-04, 7.06224644e-04, 7.22948869e-04,\n",
                            "        4.41018055e-04, 9.36989440e-04, 9.71797330e-04, 2.73629150e-04,\n",
                            "        5.03415184e-04, 2.61850469e-03, 1.60022406e-03, 4.19995427e-04,\n",
                            "        2.11239816e-03, 1.43698917e-03, 3.50457476e-03, 5.51029167e-04,\n",
                            "        2.67499895e-03, 3.49418819e-03, 3.20708117e-04, 2.12598965e-03,\n",
                            "        4.60392475e-04, 3.70941707e-04, 2.27192926e-04, 1.53328903e-04,\n",
                            "        3.88772204e-03, 1.50511111e-03, 5.57112617e-05, 5.79306274e-04,\n",
                            "        1.01827655e-03, 1.01541146e-03, 6.54077012e-05, 2.26267474e-03,\n",
                            "        9.41183942e-04, 2.98461528e-03, 8.92565586e-04, 1.90930231e-03,\n",
                            "        2.41923705e-03, 1.05419173e-03, 1.90393743e-03, 1.98735681e-04,\n",
                            "        2.05273638e-04, 7.99031113e-04, 1.13510154e-03, 9.05224442e-05,\n",
                            "        5.33208891e-04, 1.63612538e-04, 7.05424638e-04, 1.60631246e-03,\n",
                            "        1.75805332e-03, 8.53639620e-04, 1.00225734e-03, 7.74376269e-04,\n",
                            "        3.36833065e-04, 2.53674272e-03, 2.98243976e-04, 4.66056721e-04,\n",
                            "        1.02103676e-03, 3.14234337e-03, 1.36874188e-02, 2.16628629e-04,\n",
                            "        3.08968505e-04, 6.73270843e-04, 7.70853134e-04, 1.74234330e-03,\n",
                            "        4.01375364e-05, 3.29241127e-04, 1.74137633e-04, 5.44199371e-04,\n",
                            "        2.82886229e-03, 6.52745017e-04, 2.35938060e-04, 3.36886238e-04,\n",
                            "        5.12107799e-04, 4.66753962e-04, 6.09937531e-04, 1.44324638e-03,\n",
                            "        2.02567666e-03, 2.81799887e-03, 3.05070396e-04, 1.50417478e-03,\n",
                            "        1.33967446e-03, 5.69641961e-05, 9.12415155e-04, 6.12527074e-05,\n",
                            "        4.15769282e-05, 1.29568391e-04, 7.10480817e-05, 3.68243549e-04,\n",
                            "        4.14259383e-04, 6.11893920e-05, 4.12837020e-04, 3.03211040e-04,\n",
                            "        2.13580625e-03, 3.77164070e-05, 2.77470332e-04, 1.19053246e-03,\n",
                            "        5.49450517e-04, 5.17037406e-04, 5.71882701e-04, 4.49239073e-04,\n",
                            "        4.20599681e-04, 6.80830737e-04, 1.29818125e-03, 1.88739024e-04,\n",
                            "        1.45626278e-03, 9.28370515e-04, 9.07409936e-04, 2.22824863e-04,\n",
                            "        4.69702063e-03, 2.77900160e-03, 1.37076259e-03, 2.13174659e-04,\n",
                            "        5.62861038e-04, 2.07874319e-03, 5.21397800e-04, 1.20574411e-03,\n",
                            "        6.52210205e-04, 1.89708080e-04, 1.49322237e-04, 1.23539800e-03,\n",
                            "        4.04357525e-05, 1.78355956e-04, 3.18920356e-04, 3.15998239e-03,\n",
                            "        4.71762287e-05, 8.13260116e-03, 4.61962627e-04, 1.90600753e-04,\n",
                            "        5.70315970e-05, 5.13935120e-05, 2.55209394e-04, 2.52917089e-04,\n",
                            "        1.09679997e-02, 3.85843246e-04, 4.23857040e-04, 2.36470252e-04,\n",
                            "        1.09124393e-03, 2.71152239e-04, 3.27000598e-05, 2.82443681e-04,\n",
                            "        3.46886832e-03, 3.90921399e-04, 6.34904281e-05, 3.20987456e-04,\n",
                            "        6.70035137e-04, 1.81723066e-04, 1.34564552e-03, 3.36707500e-03,\n",
                            "        9.81146842e-03, 6.98141987e-04, 1.87429090e-04, 2.02963696e-04,\n",
                            "        1.71242296e-04, 1.17814438e-04, 3.77878401e-04, 4.44683683e-04,\n",
                            "        7.53342547e-03, 2.87887012e-03, 1.71743776e-03, 9.46901331e-04,\n",
                            "        4.20331443e-03, 4.27456619e-03, 1.18784071e-03, 1.88802846e-03,\n",
                            "        1.54456939e-03, 3.60542466e-03, 6.93561102e-04, 2.92098703e-04,\n",
                            "        4.43232851e-03, 1.47996179e-03, 5.98433195e-04, 3.41425068e-04,\n",
                            "        4.51280316e-03, 3.31008428e-04, 2.50790967e-03, 2.81208986e-03,\n",
                            "        1.46770530e-04, 8.53380363e-04, 3.23709624e-04, 5.69380529e-04,\n",
                            "        1.06412983e-04, 1.38782736e-04, 2.32607056e-03, 6.76852476e-04,\n",
                            "        3.15377285e-04, 1.16295051e-02, 2.79390533e-03, 1.81433687e-04,\n",
                            "        4.55630798e-05, 4.25954873e-04, 2.13802032e-05, 2.09299935e-04,\n",
                            "        3.37263773e-04, 3.93146707e-04, 8.17437540e-05, 3.05567315e-04,\n",
                            "        1.79687297e-04, 1.11627640e-04, 1.20815210e-04, 1.24485698e-04,\n",
                            "        9.10652598e-05, 8.58012572e-05, 9.87179956e-05, 1.01323007e-04,\n",
                            "        2.20108981e-04, 1.61448814e-04, 3.32607684e-04, 7.02712932e-05,\n",
                            "        6.95205672e-05, 7.39425304e-05, 2.95391419e-05, 1.07868480e-04,\n",
                            "        4.72691376e-04, 4.21110381e-05, 1.30277185e-04, 2.01610979e-04,\n",
                            "        3.09892028e-04, 9.22772088e-05, 3.34206707e-04, 9.85710503e-05,\n",
                            "        9.42963743e-05, 1.69678213e-04, 2.33319210e-04, 1.07884269e-04,\n",
                            "        1.54778827e-04, 3.07124644e-03, 4.49575236e-05, 5.89085175e-05,\n",
                            "        8.77828425e-05, 2.14784115e-04, 5.20019268e-04, 5.21923881e-04,\n",
                            "        7.60558061e-04, 2.73707061e-04, 2.66448857e-04, 1.07699540e-03,\n",
                            "        1.88703474e-04, 5.66835915e-05, 3.05671943e-04, 4.97582194e-04,\n",
                            "        2.61588633e-04, 6.21295068e-03, 7.44056888e-04, 9.10402960e-05,\n",
                            "        7.12998386e-04, 3.82972969e-04, 2.46325188e-04, 1.20614321e-04,\n",
                            "        1.50384847e-04, 1.29202483e-04, 1.03674392e-04, 2.21076276e-04,\n",
                            "        3.69326270e-04, 1.34613452e-04, 5.03405790e-05, 4.57294118e-05,\n",
                            "        7.83778960e-05, 1.18863782e-05, 3.32679192e-05, 8.75391561e-05,\n",
                            "        6.16038524e-05, 8.49567878e-05, 1.83294149e-04, 1.53452046e-02]],\n",
                            "      dtype=float32))"
                        ]
                    },
                    "execution_count": 32,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# 推論の実行\n",
                "prepared_backend.run(x)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "colab_type": "text",
                "id": "n7-6as8LwOas"
            },
            "source": [
                "### ONNX 形式のモデルを Caffe2 形式に変換する\n",
                "\n",
                "前節では Chainer の学習済みモデルを ONNX 形式に変換し、Caffe2 を使用してそのモデルで推論を行いました。\n",
                "本節では、ONNX 形式のモデルを Caffe2 形式に変換する方法を説明します。\n",
                "Caffe2 はモバイル環境に対応しているため、Chainer で作成した学習済みモデルを ONNX 形式を経由して Caffe2 形式に変換することで、モバイルアプリへの組み込みが可能になります。"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {
                "colab": {},
                "colab_type": "code",
                "id": "cUGNW0SBwOiN"
            },
            "outputs": [],
            "source": [
                "# ONNX モデルを Caffe2 モデルに変換\n",
                "init_net, predict_net = backend.Caffe2Backend.onnx_graph_to_caffe2_net(onnx_model, device='CPU')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {
                "colab": {},
                "colab_type": "code",
                "id": "CToOjVjPwOoi"
            },
            "outputs": [],
            "source": [
                "# Caffe2 モデルの保存\n",
                "from caffe2.python.onnx.helper import save_caffe2_net\n",
                "save_caffe2_net(init_net , 'caffemodel_init.pb', output_txt=False)\n",
                "save_caffe2_net(predict_net , 'caffemodel_predict.pb', output_txt=False)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/",
                    "height": 34
                },
                "colab_type": "code",
                "executionInfo": {
                    "elapsed": 228901,
                    "status": "ok",
                    "timestamp": 1548312180404,
                    "user": {
                        "displayName": "西沢衛",
                        "photoUrl": "",
                        "userId": "12011220225445512117"
                    },
                    "user_tz": -540
                },
                "id": "UIZA-7u8yVqc",
                "outputId": "9c160999-427a-4862-8e9f-52a8c3a93e2f"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "caffemodel_init.pb  caffemodel_predict.pb\r\n"
                    ]
                }
            ],
            "source": [
                "# 出力されたファイルの確認\n",
                "!ls *.pb"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "colab_type": "text",
                "id": "nT5zUn43b-h1"
            },
            "source": [
                "## Menoh を使用した他言語での推論\n",
                "\n",
                "前節では、Chainer で学習したモデルを、ONNX を介して異なるフレームワークで推論する方法をお伝えしました。\n",
                "本節では ONNX 形式のモデルを読み込んで推論を行う [Menoh](https://github.com/pfnet-research/menoh)（メノウ）フレームワークの方法を解説します。\n",
                "\n",
                "Menoh は ONNX 形式で保存された学習済みモデルを読み込むことのできる、推論専用の深層学習フレームワークです。\n",
                "Menoh は、C/C++ で実装された Menoh 本体（コアライブラリ）と各言語向けのバインディングから構成されており、様々なプログラミング言語から呼び出せるように設計されていることが大きな特徴の一つです。\n",
                "2019年2月現在、C, C++, C#, Ruby, Java, Go, Node.js, Haskell, Rust から Menoh を利用することができます。\n",
                "\n",
                "ここでは、Ruby から Menoh を使用して推論を行う方法を紹介します。"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "colab_type": "text",
                "id": "1iA7xKvXb-h2"
            },
            "source": [
                "### Menoh-Ruby の環境構築"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "colab_type": "text",
                "id": "1iA7xKvXb-h3"
            },
            "source": [
                "#### Ruby のインストール"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {},
            "outputs": [],
            "source": [
                "!apt install ruby ruby-dev"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "colab_type": "text",
                "id": "1iA7xKvXb-h4"
            },
            "source": [
                "#### Menoh のインストール\n",
                "\n",
                "[Menoh](https://github.com/pfnet-research/menoh) 本体のインストールを行います。\n",
                "なお、この環境構築の手順は Ubuntu 18.04（Google Colaboratory 環境）を想定しています。\n",
                "それ以外の環境でのセットアップ手順は [README](https://github.com/pfnet-research/menoh#installation-using-package-manager-or-binary-packages) を参照してください。"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {},
            "outputs": [],
            "source": [
                "!curl -LO \"https://github.com/pfnet-research/menoh/releases/download/v1.1.1/ubuntu1804_mkl-dnn_0.16-1_amd64.deb\"\n",
                "!curl -LO \"https://github.com/pfnet-research/menoh/releases/download/v1.1.1/ubuntu1804_menoh_1.1.1-1_amd64.deb\"\n",
                "!curl -LO \"https://github.com/pfnet-research/menoh/releases/download/v1.1.1/ubuntu1804_menoh-dev_1.1.1-1_amd64.deb\"\n",
                "!apt install ./ubuntu1804_*_amd64.deb"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Menoh-Ruby のインストール\n",
                "\n",
                "Menoh の [Ruby バインディング](https://github.com/pfnet-research/menoh-ruby)のインストールを行います。"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "metadata": {},
            "outputs": [],
            "source": [
                "!gem install menoh"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "###  Ruby で推論を行う\n",
                "\n",
                "Menoh-Ruby の[サンプルスクリプト](https://github.com/pfnet-research/menoh-ruby/blob/3e0a972dcfcf3c4af7a681b6400ae47f85cbd383/example/example_vgg16.rb)を `example_vgg16.rb` という名前で保存して、実行してみましょう。\n",
                "ONNX 形式の学習済みモデルファイル（VGG16）とテスト用の画像2枚が `data` ディレクトリにダウンロードされた後、推論が実行されます。"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "metadata": {},
            "outputs": [],
            "source": [
                "# サンプルスクリプトで使用するライブラリのインストール\n",
                "!apt install libmagickwand-dev\n",
                "!gem install rmagick"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "metadata": {},
            "outputs": [],
            "source": [
                "# サンプルスクリプトのダウンロードと実行\n",
                "!curl -LO \"https://raw.githubusercontent.com/pfnet-research/menoh-ruby/3e0a972dcfcf3c4af7a681b6400ae47f85cbd383/example/example_vgg16.rb\"\n",
                "!mkdir -p data/\n",
                "!ruby \"example_vgg16.rb\""
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "colab_type": "text",
                "id": "1iA7xKvXb-h5"
            },
            "source": [
                "推論結果が以下のように表示されれば成功です。\n",
                "\n",
                "```\n",
                "=== Result for ./data/Light_sussex_hen.jpg ===\n",
                "n01514859 hen : 0.9339964389801025\n",
                "n01514668 cock : 0.05969797447323799\n",
                "n01807496 partridge : 0.002985152183100581\n",
                "n01797886 ruffed grouse, partridge, Bonasa umbellus : 0.0008867944125086069\n",
                "n01847000 drake : 0.0005284951184876263\n",
                "\n",
                "=== Result for ./data/honda_nsx.jpg ===\n",
                "n04285008 sports car, sport car : 0.6823536157608032\n",
                "n04037443 racer, race car, racing car : 0.1251951903104782\n",
                "n03100240 convertible : 0.11076415330171585\n",
                "n02974003 car wheel : 0.047828804701566696\n",
                "n03459775 grille, radiator grille : 0.009155559353530407\n",
                "```"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "colab_type": "text",
                "id": "1iA7xKvXb-h6"
            },
            "source": [
                "#### サンプルスクリプトの内容について"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "colab_type": "text",
                "id": "1iA7xKvXb-h7"
            },
            "source": [
                "ここでは、[サンプルスクリプト](https://github.com/pfnet-research/menoh-ruby/blob/3e0a972dcfcf3c4af7a681b6400ae47f85cbd383/example/example_vgg16.rb)の概要について説明します。\n",
                "（モデルや画像のデータセットのダウンロードは省略します。）  \n",
                "\n",
                "最初に、サンプルスクリプトで使用する各ライブラリの読み込みを行います。\n",
                "Ruby で画像を扱うライブラリとして [RMagick](https://github.com/rmagick/rmagick) を使用しています。\n",
                "\n",
                "```ruby\n",
                "require 'open-uri'\n",
                "require 'rmagick'\n",
                "require 'menoh'\n",
                "```\n",
                "\n",
                "ONNX 形式のモデルデータと推論に使うサンプルデータをダウンロードします。\n",
                "\n",
                "```ruby\n",
                "# download dependencies\n",
                "...\n",
                "```\n",
                "\n",
                "推論に使うサンプルデータのファイル名と、学習モデル（VGG16）の入力データ形式を定義します。\n",
                "`rgb_offset` は学習済みの\n",
                "\n",
                "```ruby\n",
                "# load dataset\n",
                "image_list = [\n",
                "  './data/Light_sussex_hen.jpg',\n",
                "  './data/honda_nsx.jpg'\n",
                "]\n",
                "input_shape = {\n",
                "  channel_num: 3,\n",
                "  width: 224,\n",
                "  height: 224\n",
                "}\n",
                "rgb_offset = {\n",
                "  R: 123.68,\n",
                "  G: 116.779,\n",
                "  B: 103.939\n",
                "}\n",
                "```\n",
                "\n",
                "Menoh を使用して ONNX 形式のモデルデータを読み込みます。\n",
                "\n",
                "```ruby\n",
                "# load ONNX file\n",
                "onnx_obj = Menoh::Menoh.new './data/VGG16.onnx'\n",
                "```\n",
                "\n",
                "ONNX 形式のモデルでは、ニューラルネットワークの各部分（ノード）にユニークな ID が振られています。\n",
                "Menoh ではネットワークの任意の部分に対してデータを入出力することができるため、データの入出力対象となる ID を指定する必要があります。\n",
                "ネットワークの各部分に設定された ID は、モデルファイルを [Netron](https://github.com/lutzroeder/Netron) などの可視化ツールで読み込むことで確認できます。\n",
                "\n",
                "* `CONV1_1_IN_NAME` は入力層（最初の畳み込み層）の ID で、この層にデータを入力します。\n",
                "* `FC6_OUT_NAME` は全結合層（1番目）の ID です。本スクリプトでは、この層の出力結果は使用しません（複数の出力を指定するサンプルコードを示す目的で定義されています）。\n",
                "* `SOFTMAX_OUT_NAME` は出力層（最終層の出力に Softmax 関数を適用したもの）の ID で、推論の結果（各分類クラスに対するスコア）を得ることができます。\n",
                "\n",
                "```ruby\n",
                "# onnx variable name\n",
                "CONV1_1_IN_NAME = 'Input_0'.freeze\n",
                "FC6_OUT_NAME = 'Gemm_0'.freeze\n",
                "SOFTMAX_OUT_NAME = 'Softmax_0'.freeze\n",
                "```\n",
                "\n",
                "読み込んだ ONNX 形式のモデルをどのように実行するかを定義し、「Menoh モデル」を作成します。\n",
                "ここではバックエンドとして `mkldnn` （Intel CPU 向けのハードウェアアクセラレーション）を使用します。\n",
                "また、入力層の ID とそのデータ形式、出力層の ID を定義します。\n",
                "\n",
                "```ruby\n",
                "# model options for model\n",
                "model_opt = {\n",
                "  backend: 'mkldnn',\n",
                "  input_layers: [\n",
                "    {\n",
                "      name: CONV1_1_IN_NAME,\n",
                "      dims: [\n",
                "        image_list.length,\n",
                "        input_shape[:channel_num],\n",
                "        input_shape[:height],\n",
                "        input_shape[:width],\n",
                "      ]\n",
                "    }\n",
                "  ],\n",
                "  output_layers: [FC6_OUT_NAME, SOFTMAX_OUT_NAME]\n",
                "}\n",
                "\n",
                "# make model for inference under 'model_opt'\n",
                "model = onnx_obj.make_model model_opt\n",
                "```\n",
                "\n",
                "推論対象の画像を読み込み、データセットの準備を行います。\n",
                "\n",
                "1. `image_list` から順番に画像ファイルのパスを読み込み、`image_filepath` に格納します。\n",
                "2. RMagick で画像を読み込みます（画像の読み込み後に Array の形式となるため、`.first` で最初の要素を取得します）。\n",
                "3. 読み込んだ画像を VGG16 の入力サイズにあわせてリサイズします。\n",
                "4. RGB の各ピクセル値を 16-bit から 8-bit に変換（256 で割る）し、中間画像の offset の値を引く正規化を行います。\n",
                "\n",
                "```ruby\n",
                "# prepare dataset\n",
                "image_set = [\n",
                "  {\n",
                "    name: CONV1_1_IN_NAME,\n",
                "    data: image_list.map do |image_filepath|  # 1\n",
                "      image = Magick::Image.read(image_filepath).first  # 2\n",
                "      image = image.resize_to_fill(input_shape[:width], input_shape[:height])  # 3\n",
                "      'RGB'.split('').map do |color|\n",
                "        image.export_pixels(0, 0, image.columns, image.rows, color).map do |pix|\n",
                "          pix / 256 - rgb_offset[color.to_sym]  # 4\n",
                "        end\n",
                "      end.flatten\n",
                "    end.flatten\n",
                "  }\n",
                "]\n",
                "```\n",
                "\n",
                "推論を実行します。\n",
                "\n",
                "```ruby\n",
                "# execute inference\n",
                "inferenced_results = model.run image_set\n",
                "```\n",
                "\n",
                "推論結果を、対応するカテゴリ名と共に出力します。\n",
                "\n",
                "```ruby\n",
                "# load category definition\n",
                "categories = File.read('./data/synset_words.txt').split(\"\\n\")\n",
                "TOP_K = 5\n",
                "layer_result = inferenced_results.find { |x| x[:name] == SOFTMAX_OUT_NAME }\n",
                "layer_result[:data].zip(image_list).each do |image_result, image_filepath|\n",
                "  puts \"=== Result for #{image_filepath} ===\"\n",
                "\n",
                "  # sort by score\n",
                "  sorted_result = image_result.zip(categories).sort_by { |x| -x[0] }\n",
                "\n",
                "  # display result\n",
                "  sorted_result[0, TOP_K].each do |score, category|\n",
                "    puts \"#{category} : #{score}\"\n",
                "  end\n",
                "end\n",
                "```"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "colab_type": "text",
                "id": "RHUbc6Zeb-h3"
            },
            "source": [
                "本章では、Chainer で作成した学習済みモデルを、様々なフレームワークや言語で推論する方法を解説しました。\n",
                "これにより、学習済みモデルを様々な環境で使用したり、アプリケーションに組み込むことが可能となります。"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.6.8"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}